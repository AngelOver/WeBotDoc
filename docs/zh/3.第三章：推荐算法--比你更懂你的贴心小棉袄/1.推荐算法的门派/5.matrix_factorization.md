---
title: çŸ©é˜µåˆ†è§£ (MF)ï¼šSVD, ALS, FunkSVD ç­‰éšè¯­ä¹‰æ¨¡å‹
createTime: 2025/06/05 09:34:56

---

çŸ©é˜µåˆ†è§£ï¼ˆMatrix Factorization, MFï¼‰æ˜¯æ¨èç³»ç»Ÿä¸­çš„é‡è¦çªç ´ï¼Œç‰¹åˆ«æ˜¯åœ¨Netflix Prizeç«èµ›ä¸­å¤§æ”¾å¼‚å½©ã€‚å®ƒé€šè¿‡å°†ç¨€ç–çš„ç”¨æˆ·-ç‰©å“è¯„åˆ†çŸ©é˜µåˆ†è§£ä¸ºä¸¤ä¸ªä½ç»´ç¨ å¯†çŸ©é˜µçš„ä¹˜ç§¯ï¼ŒæŒ–æ˜å‡ºéšè—åœ¨æ•°æ®èƒŒåçš„æ½œåœ¨å› å­ï¼Œä»è€Œå®ç°é«˜è´¨é‡çš„æ¨èã€‚

## ğŸ§  çŸ©é˜µåˆ†è§£çš„æ ¸å¿ƒæ€æƒ³

::: tip ğŸ­ é™ç»´çš„é­”åŠ›
çŸ©é˜µåˆ†è§£çš„æ ¸å¿ƒæ˜¯"é™ç»´"ï¼šå°†é«˜ç»´ç¨€ç–çš„ç”¨æˆ·-ç‰©å“äº¤äº’æ•°æ®æ˜ å°„åˆ°ä½ç»´ç¨ å¯†çš„éšè¯­ä¹‰ç©ºé—´ã€‚
:::

### åŸºæœ¬æ€æƒ³

æƒ³è±¡ä¸€ä¸ªç”µå½±æ¨èåœºæ™¯ï¼š
- **ç”¨æˆ·åå¥½**ï¼šå¯èƒ½ç”±å‡ ä¸ªæ½œåœ¨å› å­å†³å®šâ€”â€”å–œå‰§åå¥½ã€åŠ¨ä½œåå¥½ã€ç§‘å¹»åå¥½ç­‰
- **ç”µå½±å±æ€§**ï¼šä¹Ÿå¯ä»¥ç”¨è¿™äº›å› å­æ¥æè¿°â€”â€”è¿™éƒ¨ç”µå½±æœ‰å¤šå°‘å–œå‰§æˆåˆ†ã€åŠ¨ä½œæˆåˆ†ç­‰  
- **è¯„åˆ†é¢„æµ‹**ï¼šç”¨æˆ·å¯¹ç”µå½±çš„è¯„åˆ† = ç”¨æˆ·åœ¨å„ä¸ªå› å­ä¸Šçš„åå¥½ Ã— ç”µå½±åœ¨å„ä¸ªå› å­ä¸Šçš„å±æ€§

```mermaid
flowchart LR
    A["ğŸ“Š ç”¨æˆ·-ç‰©å“è¯„åˆ†çŸ©é˜µ<br/>R(mÃ—n)<br/>ğŸ•³ï¸ ç¨€ç–ã€é«˜ç»´"] --> B["âš¡ çŸ©é˜µåˆ†è§£"]
    
    B --> C["ğŸ‘¤ ç”¨æˆ·å› å­çŸ©é˜µ<br/>U(mÃ—k)<br/>ğŸ¯ ç”¨æˆ·åå¥½"]
    B --> D["ğŸ¥ ç‰©å“å› å­çŸ©é˜µ<br/>V(nÃ—k)<br/>ğŸ·ï¸ ç‰©å“å±æ€§"]
    
    C --> E["ğŸ”® è¯„åˆ†é¢„æµ‹<br/>RÌ‚ = U Ã— V^T"]
    D --> E
    
    E --> F["ğŸ“ˆ æ¨èç”Ÿæˆ<br/>Top-Næ¨è"]
    
    G["ğŸ¨ æ½œåœ¨å› å­<br/>ğŸ“š ç±»å‹åå¥½<br/>ğŸ­ é£æ ¼åå¥½<br/>â° æ—¶é—´åå¥½"] --> C
    G --> D
```

### æ•°å­¦è¡¨ç¤º

ç»™å®šç”¨æˆ·-ç‰©å“è¯„åˆ†çŸ©é˜µ $R_{m \times n}$ï¼ŒçŸ©é˜µåˆ†è§£çš„ç›®æ ‡æ˜¯æ‰¾åˆ°ä¸¤ä¸ªä½ç»´çŸ©é˜µï¼š

$$R \approx UV^T$$

å…¶ä¸­ï¼š
- $U_{m \times k}$ï¼šç”¨æˆ·æ½œåœ¨å› å­çŸ©é˜µï¼Œæ¯è¡Œè¡¨ç¤ºä¸€ä¸ªç”¨æˆ·åœ¨ $k$ ä¸ªæ½œåœ¨å› å­ä¸Šçš„åå¥½
- $V_{n \times k}$ï¼šç‰©å“æ½œåœ¨å› å­çŸ©é˜µï¼Œæ¯è¡Œè¡¨ç¤ºä¸€ä¸ªç‰©å“åœ¨ $k$ ä¸ªæ½œåœ¨å› å­ä¸Šçš„å±æ€§
- $k \ll \min(m,n)$ï¼šæ½œåœ¨å› å­çš„ç»´åº¦

**é¢„æµ‹è¯„åˆ†å…¬å¼**ï¼š
$$\hat{r}_{ui} = u_i^T v_j = \sum_{f=1}^{k} u_{if} \cdot v_{jf}$$

## ğŸ­ ä¸»è¦ç®—æ³•å®¶æ—

```mermaid
flowchart TD
    A["ğŸ¯ çŸ©é˜µåˆ†è§£ç®—æ³•å®¶æ—"] --> B["ğŸ“Š åŸºç¡€MF<br/>Basic Matrix Factorization"]
    A --> C["ğŸ“ˆ FunkSVD<br/>Netflix Prizeç»å…¸"]
    A --> D["ğŸ”„ ALS<br/>Alternating Least Squares"]
    A --> E["â• NMF<br/>Non-negative MF"]
    
    B --> F["ğŸ² éšæœºæ¢¯åº¦ä¸‹é™<br/>SGDä¼˜åŒ–"]
    C --> G["âš–ï¸ åç½®é¡¹å¤„ç†<br/>Bias Terms"]
    D --> H["ğŸš€ å¹¶è¡ŒåŒ–è®­ç»ƒ<br/>Scalable"]
    E --> I["ğŸ” å¯è§£é‡Šæ€§<br/>Interpretable"]
    
    F --> J["âš¡ é€‚åˆåœ¨çº¿å­¦ä¹ "]
    G --> K["ğŸ¯ å¤„ç†ç³»ç»Ÿåå·®"]
    H --> L["ğŸ’¾ å¤§è§„æ¨¡æ•°æ®"]
    I --> M["ğŸ‘ï¸ å› å­å«ä¹‰æ¸…æ™°"]
```

### åŸºç¡€çŸ©é˜µåˆ†è§£ (Basic MF)

::: tip ğŸ’¡ æ ¸å¿ƒæ€æƒ³
æœ€æœ´ç´ çš„çŸ©é˜µåˆ†è§£æ–¹æ³•ï¼Œé€šè¿‡æœ€å°åŒ–è§‚æµ‹è¯„åˆ†çš„é‡æ„è¯¯å·®æ¥å­¦ä¹ ç”¨æˆ·å’Œç‰©å“çš„æ½œåœ¨è¡¨ç¤ºã€‚
:::

**ä¼˜åŒ–ç›®æ ‡**ï¼š
$$\min_{U,V} \sum_{(u,i) \in \Omega} (r_{ui} - u_u^T v_i)^2 + \lambda(||U||_F^2 + ||V||_F^2)$$

å…¶ä¸­ $\Omega$ æ˜¯è§‚æµ‹åˆ°çš„è¯„åˆ†é›†åˆï¼Œ$\lambda$ æ˜¯æ­£åˆ™åŒ–å‚æ•°ã€‚

**è®­ç»ƒæµç¨‹**ï¼š
1. **åˆå§‹åŒ–**ï¼šéšæœºåˆå§‹åŒ–ç”¨æˆ·å’Œç‰©å“å› å­çŸ©é˜µ
2. **è¿­ä»£ä¼˜åŒ–**ï¼šä½¿ç”¨éšæœºæ¢¯åº¦ä¸‹é™æ›´æ–°å‚æ•°
3. **æ­£åˆ™åŒ–**ï¼šé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œæé«˜æ³›åŒ–èƒ½åŠ›
4. **æ”¶æ•›æ£€æµ‹**ï¼šç›‘æ§æŸå¤±å‡½æ•°æˆ–éªŒè¯é›†æ€§èƒ½

::: details ğŸ’» åŸºç¡€MFä»£ç å®ç°
```python
import numpy as np
from sklearn.metrics import mean_squared_error

class BasicMF:
    def __init__(self, n_factors=50, learning_rate=0.01, 
                 reg_lambda=0.01, n_epochs=100):
        self.n_factors = n_factors
        self.learning_rate = learning_rate
        self.reg_lambda = reg_lambda
        self.n_epochs = n_epochs
        
    def fit(self, rating_matrix):
        """è®­ç»ƒçŸ©é˜µåˆ†è§£æ¨¡å‹"""
        self.n_users, self.n_items = rating_matrix.shape
        
        # åˆå§‹åŒ–ç”¨æˆ·å’Œç‰©å“å› å­çŸ©é˜µ
        self.user_factors = np.random.normal(0, 0.1, (self.n_users, self.n_factors))
        self.item_factors = np.random.normal(0, 0.1, (self.n_items, self.n_factors))
        
        # æ‰¾åˆ°éé›¶è¯„åˆ†çš„ä½ç½®
        self.train_set = []
        for u in range(self.n_users):
            for i in range(self.n_items):
                if rating_matrix[u, i] > 0:
                    self.train_set.append((u, i, rating_matrix[u, i]))
        
        # æ¢¯åº¦ä¸‹é™è®­ç»ƒ
        for epoch in range(self.n_epochs):
            self._sgd_step()
            
            if epoch % 10 == 0:
                train_rmse = self._compute_rmse()
                print(f"Epoch {epoch}: RMSE = {train_rmse:.4f}")
                
    def _sgd_step(self):
        """éšæœºæ¢¯åº¦ä¸‹é™ä¸€æ­¥"""
        np.random.shuffle(self.train_set)
        
        for u, i, r in self.train_set:
            # é¢„æµ‹è¯„åˆ†
            prediction = np.dot(self.user_factors[u], self.item_factors[i])
            error = r - prediction
            
            # ä¿å­˜æ—§çš„å› å­å€¼
            user_factor = self.user_factors[u].copy()
            
            # æ›´æ–°å› å­
            self.user_factors[u] += self.learning_rate * (
                error * self.item_factors[i] - self.reg_lambda * self.user_factors[u]
            )
            self.item_factors[i] += self.learning_rate * (
                error * user_factor - self.reg_lambda * self.item_factors[i]
            )
            
    def predict(self, user_id, item_id):
        """é¢„æµ‹ç”¨æˆ·å¯¹ç‰©å“çš„è¯„åˆ†"""
        return np.dot(self.user_factors[user_id], self.item_factors[item_id])
        
    def _compute_rmse(self):
        """è®¡ç®—RMSE"""
        predictions = []
        actuals = []
        
        for u, i, r in self.train_set:
            pred = self.predict(u, i)
            predictions.append(pred)
            actuals.append(r)
            
        return np.sqrt(mean_squared_error(actuals, predictions))
```
:::

### FunkSVD (Netflix Prizeç»å…¸)

::: info ğŸ† Netflix Prizeä¼ å¥‡
FunkSVDç”±Simon Funkåœ¨Netflix Prizeç«èµ›ä¸­æå‡ºï¼Œæ˜¯æ¨èç³»ç»Ÿå†å²ä¸Šçš„é‡è¦é‡Œç¨‹ç¢‘ã€‚
:::

**ä¼ ç»ŸSVDçš„å±€é™**ï¼š
- éœ€è¦å®Œæ•´çš„çŸ©é˜µï¼ˆæ— ç¼ºå¤±å€¼ï¼‰
- è®¡ç®—å¤æ‚åº¦é«˜ï¼š$O(mn^2)$
- å¯¹ç¨€ç–æ•°æ®æ•ˆæœä¸ä½³

**FunkSVDçš„åˆ›æ–°**ï¼š
- åªå¯¹è§‚æµ‹åˆ°çš„è¯„åˆ†è¿›è¡Œå»ºæ¨¡
- ä½¿ç”¨éšæœºæ¢¯åº¦ä¸‹é™ä¼˜åŒ–  
- åŠ å…¥åç½®é¡¹å¤„ç†ç³»ç»Ÿæ€§åå·®

**å®Œæ•´æ¨¡å‹**ï¼š
$$\hat{r}_{ui} = \mu + b_u + b_i + u_u^T v_i$$

å…¶ä¸­ï¼š
- $\mu$ï¼šå…¨å±€å¹³å‡è¯„åˆ†
- $b_u$ï¼šç”¨æˆ·åç½®ï¼ˆæŸäº›ç”¨æˆ·æ€»æ˜¯ç»™é«˜åˆ†/ä½åˆ†ï¼‰
- $b_i$ï¼šç‰©å“åç½®ï¼ˆæŸäº›ç‰©å“æ™®éå—æ¬¢è¿/ä¸å—æ¬¢è¿ï¼‰

::: details ğŸ’» FunkSVDä»£ç å®ç°
```python
class FunkSVD:
    def __init__(self, n_factors=50, learning_rate=0.01, 
                 reg_lambda=0.01, n_epochs=100, use_bias=True):
        self.n_factors = n_factors
        self.learning_rate = learning_rate
        self.reg_lambda = reg_lambda
        self.n_epochs = n_epochs
        self.use_bias = use_bias
        
    def fit(self, rating_matrix):
        """FunkSVDè®­ç»ƒ"""
        self.n_users, self.n_items = rating_matrix.shape
        self.global_mean = np.mean(rating_matrix[rating_matrix > 0])
        
        # åˆå§‹åŒ–å› å­çŸ©é˜µ
        self.user_factors = np.random.normal(0, 0.1, (self.n_users, self.n_factors))
        self.item_factors = np.random.normal(0, 0.1, (self.n_items, self.n_factors))
        
        if self.use_bias:
            # åˆå§‹åŒ–åç½®
            self.user_bias = np.zeros(self.n_users)
            self.item_bias = np.zeros(self.n_items)
        
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        self.train_set = []
        for u in range(self.n_users):
            for i in range(self.n_items):
                if rating_matrix[u, i] > 0:
                    self.train_set.append((u, i, rating_matrix[u, i]))
        
        # è®­ç»ƒ
        for epoch in range(self.n_epochs):
            self._funksvd_step()
            
    def _funksvd_step(self):
        """FunkSVDçš„SGDæ­¥éª¤"""
        np.random.shuffle(self.train_set)
        
        for u, i, r in self.train_set:
            # é¢„æµ‹è¯„åˆ†
            if self.use_bias:
                prediction = (self.global_mean + self.user_bias[u] + 
                            self.item_bias[i] + 
                            np.dot(self.user_factors[u], self.item_factors[i]))
            else:
                prediction = np.dot(self.user_factors[u], self.item_factors[i])
                
            error = r - prediction
            
            # ä¿å­˜æ—§å€¼
            user_factor = self.user_factors[u].copy()
            
            # æ›´æ–°å› å­
            self.user_factors[u] += self.learning_rate * (
                error * self.item_factors[i] - self.reg_lambda * self.user_factors[u]
            )
            self.item_factors[i] += self.learning_rate * (
                error * user_factor - self.reg_lambda * self.item_factors[i]
            )
            
            if self.use_bias:
                # æ›´æ–°åç½®
                self.user_bias[u] += self.learning_rate * (
                    error - self.reg_lambda * self.user_bias[u]
                )
                self.item_bias[i] += self.learning_rate * (
                    error - self.reg_lambda * self.item_bias[i]
                )
                
    def predict(self, user_id, item_id):
        """é¢„æµ‹è¯„åˆ†ï¼ˆå¸¦åç½®ï¼‰"""
        prediction = np.dot(self.user_factors[user_id], self.item_factors[item_id])
        
        if self.use_bias:
            prediction += (self.global_mean + self.user_bias[user_id] + 
                         self.item_bias[item_id])
            
        return prediction
```
:::

### ALS (Alternating Least Squares)

::: tip ğŸš€ å¹¶è¡ŒåŒ–ä¼˜åŠ¿
ALSé€šè¿‡äº¤æ›¿å›ºå®šä¸€ä¸ªçŸ©é˜µæ¥ä¼˜åŒ–å¦ä¸€ä¸ªçŸ©é˜µï¼Œä¾¿äºå¹¶è¡ŒåŒ–å¤„ç†å¤§è§„æ¨¡æ•°æ®ï¼Œæ˜¯å·¥ä¸šç•Œçš„ä¸»æµé€‰æ‹©ã€‚
:::

**æ ¸å¿ƒæ€æƒ³**ï¼š
1. **å›ºå®šVï¼Œä¼˜åŒ–U**ï¼šå°†ç”¨æˆ·ä¼˜åŒ–é—®é¢˜è½¬åŒ–ä¸ºçº¿æ€§å›å½’
2. **å›ºå®šUï¼Œä¼˜åŒ–V**ï¼šå°†ç‰©å“ä¼˜åŒ–é—®é¢˜è½¬åŒ–ä¸ºçº¿æ€§å›å½’  
3. **é‡å¤è¿­ä»£**ï¼šç›´åˆ°æ”¶æ•›

**ä¼˜åŒ–å­é—®é¢˜**ï¼š
å¯¹äºç”¨æˆ· $u$ï¼š
$$\min_{u_u} \sum_{i \in I_u} (r_{ui} - u_u^T v_i)^2 + \lambda ||u_u||^2$$

è¿™æ˜¯ä¸€ä¸ªçº¿æ€§å›å½’é—®é¢˜ï¼Œæœ‰é—­å¼è§£ï¼š
$$u_u = (V_{I_u}^T V_{I_u} + \lambda I)^{-1} V_{I_u}^T r_u$$

**ALS vs SGDå¯¹æ¯”**ï¼š

| ç‰¹æ€§ | ALS | SGD |
|------|-----|-----|
| **å¹¶è¡ŒåŒ–** | å¤©ç„¶æ”¯æŒ | éš¾ä»¥å¹¶è¡Œ |
| **æ”¶æ•›æ€§** | è¾ƒæ…¢ä½†ç¨³å®š | å¿«é€Ÿä½†å¯èƒ½éœ‡è¡ |
| **å†…å­˜éœ€æ±‚** | è¾ƒé«˜ | è¾ƒä½ |
| **é€‚ç”¨åœºæ™¯** | ç¦»çº¿å¤§è§„æ¨¡ | åœ¨çº¿å®æ—¶ |

::: details ğŸ’» ALSä»£ç å®ç°
```python
import numpy as np
from scipy.sparse import coo_matrix

class ALS:
    def __init__(self, n_factors=50, reg_lambda=0.01, n_iterations=10):
        self.n_factors = n_factors
        self.reg_lambda = reg_lambda
        self.n_iterations = n_iterations
        
    def fit(self, rating_matrix):
        """ALSè®­ç»ƒ"""
        self.n_users, self.n_items = rating_matrix.shape
        
        # è½¬æ¢ä¸ºç¨€ç–çŸ©é˜µæ ¼å¼
        if not isinstance(rating_matrix, coo_matrix):
            rating_matrix = coo_matrix(rating_matrix)
            
        self.train_matrix = rating_matrix.tocsr()
        
        # åˆå§‹åŒ–å› å­çŸ©é˜µ
        self.user_factors = np.random.normal(0, 0.1, (self.n_users, self.n_factors))
        self.item_factors = np.random.normal(0, 0.1, (self.n_items, self.n_factors))
        
        # é¢„è®¡ç®—æ­£åˆ™åŒ–é¡¹
        self.reg_eye = self.reg_lambda * np.eye(self.n_factors)
        
        # è¿­ä»£ä¼˜åŒ–
        for iteration in range(self.n_iterations):
            # å›ºå®šç‰©å“å› å­ï¼Œä¼˜åŒ–ç”¨æˆ·å› å­
            self._update_user_factors()
            
            # å›ºå®šç”¨æˆ·å› å­ï¼Œä¼˜åŒ–ç‰©å“å› å­
            self._update_item_factors()
            
            if iteration % 2 == 0:
                rmse = self._compute_rmse()
                print(f"Iteration {iteration}: RMSE = {rmse:.4f}")
                
    def _update_user_factors(self):
        """æ›´æ–°ç”¨æˆ·å› å­çŸ©é˜µ"""
        for u in range(self.n_users):
            # è·å–ç”¨æˆ·uè¯„åˆ†è¿‡çš„ç‰©å“
            items = self.train_matrix[u].indices
            ratings = self.train_matrix[u].data
            
            if len(items) == 0:
                continue
                
            # è·å–å¯¹åº”çš„ç‰©å“å› å­
            item_vecs = self.item_factors[items]
            
            # ALSé—­å¼è§£
            A = item_vecs.T.dot(item_vecs) + self.reg_eye
            b = item_vecs.T.dot(ratings)
            self.user_factors[u] = np.linalg.solve(A, b)
            
    def _update_item_factors(self):
        """æ›´æ–°ç‰©å“å› å­çŸ©é˜µ"""
        # è½¬ç½®çŸ©é˜µä»¥ä¾¿æŒ‰ç‰©å“è®¿é—®
        train_matrix_T = self.train_matrix.T.tocsr()
        
        for i in range(self.n_items):
            # è·å–è¯„åˆ†è¿‡ç‰©å“içš„ç”¨æˆ·
            users = train_matrix_T[i].indices
            ratings = train_matrix_T[i].data
            
            if len(users) == 0:
                continue
                
            # è·å–å¯¹åº”çš„ç”¨æˆ·å› å­
            user_vecs = self.user_factors[users]
            
            # ALSé—­å¼è§£
            A = user_vecs.T.dot(user_vecs) + self.reg_eye
            b = user_vecs.T.dot(ratings)
            self.item_factors[i] = np.linalg.solve(A, b)
            
    def predict(self, user_id, item_id):
        """é¢„æµ‹è¯„åˆ†"""
        return np.dot(self.user_factors[user_id], self.item_factors[item_id])
        
    def _compute_rmse(self):
        """è®¡ç®—RMSE"""
        predictions = []
        actuals = []
        
        for u in range(self.n_users):
            items = self.train_matrix[u].indices
            ratings = self.train_matrix[u].data
            
            for i, rating in zip(items, ratings):
                pred = self.predict(u, i)
                predictions.append(pred)
                actuals.append(rating)
                
        return np.sqrt(np.mean((np.array(predictions) - np.array(actuals)) ** 2))
```
:::

### NMF (Non-negative Matrix Factorization)

::: info ğŸ” å¯è§£é‡Šæ€§ä¼˜åŠ¿
NMFè¦æ±‚åˆ†è§£åçš„çŸ©é˜µå…ƒç´ éè´Ÿï¼Œä½¿å¾—æ½œåœ¨å› å­å…·æœ‰æ›´å¥½çš„å¯è§£é‡Šæ€§ï¼Œç‰¹åˆ«é€‚ç”¨äºéœ€è¦ç†è§£æ¨èåŸå› çš„åœºæ™¯ã€‚
:::

**ğŸ¯ æ ¸å¿ƒçº¦æŸ**ï¼š
$$U \geq 0, V \geq 0$$

**ğŸŒŸ ä¼˜åŠ¿ç‰¹ç‚¹**ï¼š
- **å¯è§£é‡Šæ€§å¼º**ï¼šå› å­å¯ä»¥ç†è§£ä¸º"æˆåˆ†"æˆ–"ä¸»é¢˜"
- **ç¨€ç–æ€§å¥½**ï¼šè‡ªç„¶äº§ç”Ÿç¨€ç–çš„è¡¨ç¤º
- **ç¬¦åˆç›´è§‰**ï¼šéè´Ÿçº¦æŸç¬¦åˆç°å®ä¸–ç•Œçš„åŠ æ€§æ¨¡å‹

**ğŸ”„ æ›´æ–°è§„åˆ™**ï¼š
$$U_{uf} \leftarrow U_{uf} \frac{(RV)_{uf}}{(UVV^T)_{uf}}$$
$$V_{if} \leftarrow V_{if} \frac{(R^TU)_{if}}{(VU^TU)_{if}}$$

::: details ğŸ’» NMFä»£ç å®ç°
```python
class NMF:
    def __init__(self, n_factors=50, max_iter=100, tol=1e-4):
        self.n_factors = n_factors
        self.max_iter = max_iter
        self.tol = tol
        
    def fit(self, rating_matrix):
        """NMFè®­ç»ƒ"""
        # å°†è¯„åˆ†çŸ©é˜µè½¬æ¢ä¸ºéè´Ÿ
        R = np.maximum(rating_matrix, 0)
        self.n_users, self.n_items = R.shape
        
        # åˆå§‹åŒ–éè´Ÿå› å­çŸ©é˜µ
        self.user_factors = np.random.uniform(0, 1, (self.n_users, self.n_factors))
        self.item_factors = np.random.uniform(0, 1, (self.n_items, self.n_factors))
        
        # åˆ›å»ºæ©ç ï¼ˆåªè€ƒè™‘è§‚æµ‹åˆ°çš„è¯„åˆ†ï¼‰
        mask = (rating_matrix > 0).astype(float)
        
        prev_error = float('inf')
        
        for iteration in range(self.max_iter):
            # æ›´æ–°ç”¨æˆ·å› å­
            numerator = (R * mask).dot(self.item_factors)
            denominator = mask.dot(self.item_factors) * \
                         (self.user_factors.dot(self.item_factors.T).dot(self.item_factors))
            self.user_factors *= numerator / (denominator + 1e-10)
            
            # æ›´æ–°ç‰©å“å› å­
            numerator = (R * mask).T.dot(self.user_factors)
            denominator = mask.T.dot(self.user_factors) * \
                         (self.item_factors.dot(self.user_factors.T).dot(self.user_factors))
            self.item_factors *= numerator / (denominator + 1e-10)
            
            # æ£€æŸ¥æ”¶æ•›
            if iteration % 10 == 0:
                error = self._compute_error(R, mask)
                if abs(prev_error - error) < self.tol:
                    break
                prev_error = error
                
    def _compute_error(self, R, mask):
        """è®¡ç®—é‡æ„è¯¯å·®"""
        R_hat = self.user_factors.dot(self.item_factors.T)
        error = np.sum(mask * (R - R_hat) ** 2)
        return error
        
    def predict(self, user_id, item_id):
        """é¢„æµ‹è¯„åˆ†"""
        return np.dot(self.user_factors[user_id], self.item_factors[item_id])
```
:::

## ğŸš€ é«˜çº§çŸ©é˜µåˆ†è§£æŠ€æœ¯

### ğŸ”¥ SVD++ï¼šèåˆéšå¼åé¦ˆ

ä¼ ç»ŸçŸ©é˜µåˆ†è§£åªåˆ©ç”¨æ˜¾å¼è¯„åˆ†ï¼ŒSVD++è¿›ä¸€æ­¥èåˆéšå¼åé¦ˆä¿¡æ¯ï¼š

$$\hat{r}_{ui} = \mu + b_u + b_i + q_i^T(p_u + |N(u)|^{-1/2} \sum_{j \in N(u)} y_j)$$

å…¶ä¸­ $N(u)$ æ˜¯ç”¨æˆ· $u$ æœ‰è¿‡éšå¼åé¦ˆçš„ç‰©å“é›†åˆã€‚

### â° æ—¶é—´æ„ŸçŸ¥çŸ©é˜µåˆ†è§£

è€ƒè™‘æ—¶é—´å› ç´ çš„åŠ¨æ€æ¨èæ¨¡å‹ï¼š
- **æ—¶é—´åç½®**ï¼š$b_{ui}(t) = b_u + b_i + b_{u,time}(t)$ 
- **æ¦‚å¿µæ¼‚ç§»**ï¼šç”¨æˆ·åå¥½å’Œç‰©å“æµè¡Œåº¦éšæ—¶é—´å˜åŒ–
- **å­£èŠ‚æ€§æ¨¡å¼**ï¼šèŠ‚å‡æ—¥ã€ä¿ƒé”€ç­‰å‘¨æœŸæ€§å½±å“

### ğŸ¯ æ­£åˆ™åŒ–æŠ€æœ¯

| æ­£åˆ™åŒ–ç±»å‹ | å…¬å¼ | ç‰¹ç‚¹ |
|------------|------|------|
| **L2æ­£åˆ™åŒ–** | $\lambda_2(\\|U\\|_F^2 + \\|V\\|_F^2)$ | å¹³æ»‘æ€§ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ |
| **L1æ­£åˆ™åŒ–** | $\lambda_1(\\|U\\|_1 + \\|V\\|_1)$ | ç¨€ç–æ€§ï¼Œç‰¹å¾é€‰æ‹© |
| **å¼¹æ€§ç½‘ç»œ** | $\lambda_1(\\|U\\|_1 + \\|V\\|_1) + \lambda_2(\\|U\\|_F^2 + \\|V\\|_F^2)$ | å…¼é¡¾ç¨€ç–æ€§å’Œå¹³æ»‘æ€§ |

## âš™ï¸ å‚æ•°è°ƒä¼˜ä¸å®è·µæŠ€å·§

### ğŸ›ï¸ è¶…å‚æ•°é€‰æ‹©æŒ‡å—

| å‚æ•° | å…¸å‹èŒƒå›´ | é€‰æ‹©å»ºè®® | å½±å“å› ç´  |
|------|----------|----------|----------|
| **å› å­æ•°k** | 10-200 | ä»å°å¼€å§‹ï¼Œè§‚å¯Ÿè¿‡æ‹Ÿåˆ | æ•°æ®ç¨€ç–æ€§ã€è®¡ç®—èµ„æº |
| **å­¦ä¹ ç‡** | 0.001-0.1 | Adam: 0.001, SGD: 0.01 | ä¼˜åŒ–ç®—æ³•ã€æ•°æ®è§„æ¨¡ |
| **æ­£åˆ™åŒ–Î»** | 0.001-0.1 | ç½‘æ ¼æœç´¢æˆ–è´å¶æ–¯ä¼˜åŒ– | è¿‡æ‹Ÿåˆç¨‹åº¦ |
| **è¿­ä»£æ¬¡æ•°** | 50-500 | æ—©åœæ³•é˜²æ­¢è¿‡æ‹Ÿåˆ | æ”¶æ•›é€Ÿåº¦ã€æ—¶é—´é¢„ç®— |

### ğŸ’¡ å®è·µæŠ€å·§

::: details ğŸ”¥ çŸ©é˜µåˆ†è§£æœ€ä½³å®è·µ
**1. æ•°æ®é¢„å¤„ç†**
- è¯„åˆ†æ ‡å‡†åŒ–ï¼šå°†è¯„åˆ†ç¼©æ”¾åˆ°åˆé€‚çš„èŒƒå›´
- å¼‚å¸¸å€¼å¤„ç†ï¼šå»é™¤æˆ–ä¿®æ­£å¼‚å¸¸è¯„åˆ†  
- ç¨€ç–æ€§å¤„ç†ï¼šè€ƒè™‘éšå¼åé¦ˆè¡¥å……æ˜¾å¼è¯„åˆ†

**2. åˆå§‹åŒ–ç­–ç•¥** 
- éšæœºåˆå§‹åŒ–ï¼šä½¿ç”¨å°çš„éšæœºå€¼ï¼ˆå¦‚0.1æ ‡å‡†å·®çš„æ­£æ€åˆ†å¸ƒï¼‰
- é¢„è®­ç»ƒåˆå§‹åŒ–ï¼šä½¿ç”¨PCAæˆ–å…¶ä»–æ–¹æ³•é¢„åˆå§‹åŒ–
- å¯¹ç§°ç ´ç¼ºï¼šç¡®ä¿ç”¨æˆ·å’Œç‰©å“å› å­ä¸å®Œå…¨ç›¸åŒ

**3. è®­ç»ƒæŠ€å·§**
- å­¦ä¹ ç‡è¡°å‡ï¼šéšç€è®­ç»ƒè¿›è¡Œé€æ¸é™ä½å­¦ä¹ ç‡
- æ—©åœæ³•ï¼šåœ¨éªŒè¯é›†ä¸Šç›‘æ§æ€§èƒ½ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
- æ‰¹å¤„ç†ï¼šä½¿ç”¨å°æ‰¹é‡SGDæé«˜è®­ç»ƒæ•ˆç‡

**4. è¯„ä¼°æ–¹æ³•**
- æ—¶é—´åˆ†å‰²ï¼šæŒ‰æ—¶é—´é¡ºåºåˆ†å‰²è®­ç»ƒ/æµ‹è¯•é›†
- ç”¨æˆ·åˆ†å‰²ï¼šæŒ‰ç”¨æˆ·åˆ†å‰²ï¼Œç¡®ä¿å†·å¯åŠ¨æµ‹è¯•
- è´Ÿé‡‡æ ·ï¼šå¯¹äºéšå¼åé¦ˆï¼Œéœ€è¦åˆç†çš„è´Ÿæ ·æœ¬ç­–ç•¥
:::


ğŸ“– **å»¶ä¼¸é˜…è¯»**
1. [Matrix Factorization Techniques for Recommender Systems](https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf) - Korenç­‰äººçš„çŸ©é˜µåˆ†è§£ç»¼è¿°åœ£ç»ï¼ŒNetflix Prizeç»éªŒæ€»ç»“
2. [Netflix Update: Try This at Home](https://sifter.org/~simon/journal/20061211.html) - Simon Funkçš„åŸå§‹åšå®¢ï¼Œæ”¹å˜æ¨èç³»ç»Ÿå†å²çš„FunkSVD
3. [Collaborative Filtering for Implicit Feedback Datasets](http://yifanhu.net/PUB/cf.pdf) - Huç­‰äººå…³äºéšå¼åé¦ˆå¤„ç†çš„å¼€åˆ›æ€§å·¥ä½œ
4. [Alternating Least Squares for Personalized Ranking](https://dl.acm.org/doi/10.1145/2043932.2043987) - ALSç®—æ³•åœ¨ä¸ªæ€§åŒ–æ’åºä¸­çš„åº”ç”¨
5. [Surprise Documentation](https://surprise.readthedocs.io/) - æ˜“äºä½¿ç”¨çš„PythonçŸ©é˜µåˆ†è§£åº“ï¼Œé€‚åˆå¿«é€Ÿå®éªŒ
6. [Torch-RecHub: A Library for Recommender Systems](https://github.com/datawhalechina/torch-rechub) - å®ç°äº†å¤šç§çŸ©é˜µåˆ†è§£å˜ä½“çš„PyTorchæ¨èåº“

> ğŸ§  **æ€è€ƒé¢˜**
> 
> 1. å¦‚ä½•ç¡®å®šæœ€ä¼˜çš„æ½œåœ¨å› å­ç»´åº¦kï¼Ÿè¿‡å¤§æˆ–è¿‡å°çš„kå€¼ä¼šå¸¦æ¥ä»€ä¹ˆé—®é¢˜ï¼Ÿ
> 
> 2. çŸ©é˜µåˆ†è§£å¦‚ä½•å¤„ç†æ–°ç”¨æˆ·å’Œæ–°ç‰©å“çš„å†·å¯åŠ¨é—®é¢˜ï¼Ÿæœ‰å“ªäº›å…·ä½“çš„è§£å†³æ–¹æ¡ˆï¼Ÿ
> 
> 3. éšå¼åé¦ˆå’Œæ˜¾å¼åé¦ˆçš„çŸ©é˜µåˆ†è§£æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿåœ¨æŸå¤±å‡½æ•°è®¾è®¡ä¸Šéœ€è¦æ³¨æ„ä»€ä¹ˆï¼Ÿ
> 
> 4. å½“æœ‰æ–°çš„ç”¨æˆ·è¯„åˆ†äº§ç”Ÿæ—¶ï¼Œå¦‚ä½•é«˜æ•ˆåœ°æ›´æ–°ç”¨æˆ·å’Œç‰©å“çš„æ½œåœ¨å› å­è€Œä¸éœ€è¦é‡æ–°è®­ç»ƒæ•´ä¸ªæ¨¡å‹ï¼Ÿ
> 
> 5. å¦‚ä½•å°†çŸ©é˜µåˆ†è§£æ‰©å±•åˆ°å¤šä»»åŠ¡å­¦ä¹ åœºæ™¯ï¼Ÿæ¯”å¦‚åŒæ—¶é¢„æµ‹è¯„åˆ†å’Œè´­ä¹°æ¦‚ç‡ï¼Ÿ

::: tip ğŸ‰ ç« èŠ‚å°ç»“
çŸ©é˜µåˆ†è§£æ˜¯æ¨èç³»ç»Ÿçš„é‡è¦åŸºçŸ³ï¼Œå®ƒç”¨"é™ç»´"çš„é­”åŠ›å°†ç¨€ç–çš„ç”¨æˆ·-ç‰©å“äº¤äº’æ˜ å°„åˆ°ç¨ å¯†çš„éšè¯­ä¹‰ç©ºé—´ã€‚ä»Netflix Prizeçš„FunkSVDåˆ°å·¥ä¸šç•Œå¹¿æ³›åº”ç”¨çš„ALSï¼Œä»åŸºç¡€çš„äºŒç»´åˆ†è§£åˆ°èåˆæ—¶é—´ã€ä¸Šä¸‹æ–‡çš„é«˜çº§å˜ç§ï¼ŒçŸ©é˜µåˆ†è§£å±•ç°äº†æ•°å­¦ä¹‹ç¾ä¸å·¥ç¨‹å®è·µçš„å®Œç¾ç»“åˆã€‚æŒæ¡å…¶æ ¸å¿ƒæ€æƒ³å’Œä¸»è¦å˜ç§ï¼Œä¸ä»…æ˜¯æ¯ä¸ªæ¨èç³»ç»Ÿå·¥ç¨‹å¸ˆçš„å¿…ä¿®è¯¾ï¼Œæ›´æ˜¯ç†è§£ç°ä»£æ·±åº¦å­¦ä¹ æ¨èæ¨¡å‹çš„é‡è¦åŸºç¡€ã€‚
:::

---

> "çŸ©é˜µåˆ†è§£è™½ç„¶æ•°å­¦å¤æ‚ï¼Œä½†å®ƒæ­ç¤ºäº†æ¨èç³»ç»Ÿçš„æ ¸å¿ƒæ™ºæ…§ï¼šåœ¨é«˜ç»´ç¨€ç–çš„è¡¨è±¡ä¸‹ï¼Œéšè—ç€ä½ç»´ç¨ å¯†çš„æœ¬è´¨è§„å¾‹ã€‚"
