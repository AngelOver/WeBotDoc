---
title: æ··åˆæ¨èæ¨¡å‹ (Hybrid Models)ï¼šå–é•¿è¡¥çŸ­ï¼Œæ•ˆæœæ›´ä½³
createTime: 2025/06/05 09:34:56

---

æ··åˆæ¨èæ¨¡å‹ï¼ˆHybrid Recommender Systemsï¼‰æ˜¯æ¨èç³»ç»Ÿå‘å±•çš„å¿…ç„¶è¶‹åŠ¿ï¼Œé€šè¿‡èåˆå¤šç§æ¨èç®—æ³•çš„ä¼˜åŠ¿ï¼Œå…‹æœå•ä¸€ç®—æ³•çš„å±€é™æ€§ï¼Œå®ç°"1+1>2"çš„æ•ˆæœã€‚æ­£å¦‚ä¸­åŒ»çš„"å›è‡£ä½ä½¿"é…æ–¹ç†å¿µï¼Œæ··åˆæ¨èç³»ç»Ÿå·§å¦™åœ°ç»„åˆä¸åŒç®—æ³•ï¼Œåœ¨å‡†ç¡®æ€§ã€å¤šæ ·æ€§ã€æ–°é¢–æ€§ç­‰å¤šä¸ªç»´åº¦ä¸Šè¾¾åˆ°æœ€ä½³å¹³è¡¡ã€‚

## ğŸ§  æ ¸å¿ƒæ€æƒ³ä¸å¿…è¦æ€§

::: tip ğŸ¯ å–é•¿è¡¥çŸ­çš„æ™ºæ…§
æ··åˆæ¨èçš„ç²¾é«“åœ¨äºç»„åˆä¸åŒç®—æ³•çš„ä¼˜åŠ¿ï¼ŒåŒæ—¶è§„é¿å„è‡ªçš„ç¼ºç‚¹ï¼Œå®ç°æ¨èæ•ˆæœçš„æ•´ä½“ä¼˜åŒ–ã€‚
:::

### ä¸ºä»€ä¹ˆéœ€è¦æ··åˆæ¨èï¼Ÿ

| å•ä¸€ç®—æ³•å±€é™æ€§ | æ··åˆç­–ç•¥è§£å†³æ–¹æ¡ˆ |
|----------------|------------------|
| **ååŒè¿‡æ»¤**ï¼šå†·å¯åŠ¨ã€ç¨€ç–æ€§é—®é¢˜ | ç»“åˆå†…å®¹æ¨èè§£å†³æ–°ç”¨æˆ·/ç‰©å“é—®é¢˜ |
| **å†…å®¹æ¨è**ï¼šè¿‡åº¦ä¸“ä¸šåŒ–ã€ç¼ºä¹æƒŠå–œ | ç»“åˆååŒè¿‡æ»¤å¢åŠ å¤šæ ·æ€§å’Œæ–°é¢–æ€§ |
| **çŸ©é˜µåˆ†è§£**ï¼šå¯è§£é‡Šæ€§å·® | ç»“åˆåŸºäºè§„åˆ™çš„æ–¹æ³•æä¾›è§£é‡Š |
| **æ·±åº¦å­¦ä¹ **ï¼šè®¡ç®—å¤æ‚ã€é»‘ç›’ | ç»“åˆä¼ ç»Ÿæ–¹æ³•å¹³è¡¡æ•ˆæœä¸æ•ˆç‡ |

### æ··åˆçš„ç»´åº¦

```mermaid
flowchart TD
    A["ğŸ­ æ··åˆæ¨èç³»ç»Ÿ"] --> B["ğŸ”§ ç®—æ³•å±‚é¢"]
    A --> C["ğŸ“Š æ•°æ®å±‚é¢"]
    A --> D["ğŸ¬ åœºæ™¯å±‚é¢"]
    
    B --> B1["ğŸ¤ ååŒè¿‡æ»¤ + å†…å®¹æ¨è"]
    B --> B2["ğŸ”¢ çŸ©é˜µåˆ†è§£ + æ·±åº¦å­¦ä¹ "]
    B --> B3["ğŸ“ å¤šç§ç›¸ä¼¼åº¦åº¦é‡"]
    
    C --> C1["ğŸ‘ æ˜¾å¼ + éšå¼åé¦ˆ"]
    C --> C2["ğŸ–¼ï¸ å¤šæ¨¡æ€æ•°æ®èåˆ"]
    C --> C3["â° æ—¶é—´åºåˆ— + é™æ€ç‰¹å¾"]
    
    D --> D1["âš¡ å®æ—¶ + ç¦»çº¿æ¨è"]
    D --> D2["ğŸ‘¤ ä¸ªæ€§åŒ– + æµè¡Œåº¦"]
    D --> D3["ğŸ¯ ç²¾å‡† + å¤šæ ·æ€§"]
```

## ğŸ­ ç»å…¸æ··åˆç­–ç•¥

### åŠ æƒæ··åˆ (Weighted Hybrid)

::: info ğŸ¯ æ°‘ä¸»æŠ•ç¥¨ï¼Œæƒé‡ä¸ºç‹
è¿™å°±åƒä¸€ä¸ªä¸“å®¶è¯„å®¡å›¢ï¼Œæ¯ä¸ªè¯„å§”ï¼ˆç®—æ³•ï¼‰éƒ½å¯¹å€™é€‰é¡¹ç›®ï¼ˆç‰©å“ï¼‰æ‰“åˆ†ï¼Œæœ€åæ ¹æ®è¯„å§”çš„èµ„å†ï¼ˆæƒé‡ï¼‰ç»¼åˆå¾—å‡ºæœ€ç»ˆå¾—åˆ†ã€‚æœ€å¸¸è§ä¹Ÿæœ€ç›´æ¥ï¼Œä½†å¦‚ä½•ç¡®å®šæœ€ä½³æƒé‡æ˜¯å…³é”®ã€‚
:::

**æ•°å­¦è¡¨ç¤º**ï¼š
$$\hat{r}_{ui} = \sum_{k=1}^{K} w_k \cdot \hat{r}_{ui}^{(k)}$$

å…¶ä¸­ $w_k$ æ˜¯ç¬¬ $k$ ä¸ªç®—æ³•çš„æƒé‡ï¼Œä¸” $\sum_{k=1}^{K} w_k = 1$ã€‚

::: details ğŸ’» åŠ æƒæ··åˆå®ç°ä»£ç 
```python
import numpy as np
from abc import ABC, abstractmethod

class BaseRecommender(ABC):
    @abstractmethod
    def predict(self, user_id, item_id):
        pass
    
    @abstractmethod
    def recommend(self, user_id, n_recommendations=10):
        pass

class WeightedHybridRecommender:
    def __init__(self, recommenders, weights=None):
        self.recommenders = recommenders
        if weights is None:
            # é»˜è®¤ç­‰æƒé‡
            weights = [1.0 / len(recommenders)] * len(recommenders)
        self.weights = np.array(weights)
        
        # ç¡®ä¿æƒé‡å½’ä¸€åŒ–
        self.weights = self.weights / np.sum(self.weights)
        
    def predict(self, user_id, item_id):
        """åŠ æƒé¢„æµ‹è¯„åˆ†"""
        predictions = []
        for recommender in self.recommenders:
            try:
                pred = recommender.predict(user_id, item_id)
                predictions.append(pred)
            except:
                predictions.append(3.0)  # é»˜è®¤è¯„åˆ†
                
        return np.dot(self.weights, predictions)
        
    def recommend(self, user_id, n_recommendations=10):
        """åŠ æƒæ¨è"""
        all_recommendations = {}
        
        for i, recommender in enumerate(self.recommenders):
            try:
                recs = recommender.recommend(user_id, n_recommendations * 2)
                for item_id, score in recs:
                    if item_id not in all_recommendations:
                        all_recommendations[item_id] = 0
                    all_recommendations[item_id] += self.weights[i] * score
            except:
                continue
                
        # æŒ‰åˆ†æ•°æ’åº
        sorted_recs = sorted(all_recommendations.items(), 
                           key=lambda x: x[1], reverse=True)
        
        return sorted_recs[:n_recommendations]
        
    def optimize_weights(self, validation_data, method='grid_search'):
        """ä¼˜åŒ–æƒé‡å‚æ•°"""
        if method == 'grid_search':
            return self._grid_search_weights(validation_data)
        else:
            raise ValueError(f"Unknown optimization method: {method}")
            
    def _grid_search_weights(self, validation_data, resolution=0.1):
        """ç½‘æ ¼æœç´¢æœ€ä¼˜æƒé‡"""
        best_weights = self.weights.copy()
        best_rmse = float('inf')
        
        import itertools
        
        weight_values = np.arange(0, 1 + resolution, resolution)
        n_recommenders = len(self.recommenders)
        
        for weight_combo in itertools.product(weight_values, repeat=n_recommenders):
            if abs(sum(weight_combo) - 1.0) < 1e-6:  # æƒé‡å’Œä¸º1
                self.weights = np.array(weight_combo)
                rmse = self._evaluate_rmse(validation_data)
                
                if rmse < best_rmse:
                    best_rmse = rmse
                    best_weights = self.weights.copy()
                    
        self.weights = best_weights
        return best_rmse
        
    def _evaluate_rmse(self, validation_data):
        """è¯„ä¼°RMSE"""
        predictions = []
        actuals = []
        
        for user_id, item_id, rating in validation_data:
            pred = self.predict(user_id, item_id)
            predictions.append(pred)
            actuals.append(rating)
            
        return np.sqrt(np.mean((np.array(predictions) - np.array(actuals)) ** 2))
```
:::

### åˆ‡æ¢æ··åˆ (Switching Hybrid)

::: info ğŸ¯ å› ææ–½æ•™ï¼Œæ‹©ä¼˜è€Œç”¨
è¿™å°±åƒä¸€ä¸ªæ™ºèƒ½çš„è°ƒåº¦å‘˜ï¼Œå®ƒä¼šæ ¹æ®å…·ä½“æƒ…å†µï¼ˆå¦‚ç”¨æˆ·æ˜¯å¦æ˜¯æ–°æ‰‹ã€ç‰©å“æ˜¯å¦å†·é—¨ï¼‰é€‰æ‹©æœ€åˆé€‚çš„ä¸“å®¶ï¼ˆç®—æ³•ï¼‰æ¥è§£å†³é—®é¢˜ã€‚ä¾‹å¦‚ï¼Œå¯¹æ–°ç”¨æˆ·ä½¿ç”¨å†…å®¹æ¨èæ¥è§£å†³å†·å¯åŠ¨é—®é¢˜ï¼Œå¯¹è€ç”¨æˆ·åˆ™ä½¿ç”¨ååŒè¿‡æ»¤ã€‚
:::

::: details ğŸ’» åˆ‡æ¢æ··åˆå®ç°ä»£ç 
```python
class SwitchingHybridRecommender:
    def __init__(self, recommenders, switching_criteria):
        self.recommenders = recommenders
        self.switching_criteria = switching_criteria
        
    def select_recommender(self, user_id, context=None):
        """æ ¹æ®æ¡ä»¶é€‰æ‹©æ¨èå™¨"""
        for criterion, recommender_idx in self.switching_criteria:
            if criterion(user_id, context):
                return self.recommenders[recommender_idx]
                
        # é»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ªæ¨èå™¨
        return self.recommenders[0]
        
    def predict(self, user_id, item_id, context=None):
        """åˆ‡æ¢é¢„æµ‹"""
        selected_recommender = self.select_recommender(user_id, context)
        return selected_recommender.predict(user_id, item_id)
        
    def recommend(self, user_id, n_recommendations=10, context=None):
        """åˆ‡æ¢æ¨è"""
        selected_recommender = self.select_recommender(user_id, context)
        return selected_recommender.recommend(user_id, n_recommendations)

# ç¤ºä¾‹åˆ‡æ¢æ¡ä»¶
def create_switching_criteria():
    """åˆ›å»ºåˆ‡æ¢æ¡ä»¶"""
    criteria = []
    
    # æ–°ç”¨æˆ·ä½¿ç”¨åŸºäºå†…å®¹çš„æ¨è
    def is_new_user(user_id, context):
        user_rating_count = context.get('user_rating_count', {}).get(user_id, 0)
        return user_rating_count < 5
    
    # å†·é—¨ç‰©å“ä½¿ç”¨åŸºäºå†…å®¹çš„æ¨è
    def is_cold_item(user_id, context):
        if context and 'item_id' in context:
            item_rating_count = context.get('item_rating_count', {}).get(context['item_id'], 0)
            return item_rating_count < 10
        return False
    
    # é«˜æ´»è·ƒç”¨æˆ·ä½¿ç”¨ååŒè¿‡æ»¤
    def is_active_user(user_id, context):
        user_rating_count = context.get('user_rating_count', {}).get(user_id, 0)
        return user_rating_count >= 20
    
    criteria.append((is_new_user, 1))      # ä½¿ç”¨å†…å®¹æ¨èå™¨ (ç´¢å¼•1)
    criteria.append((is_active_user, 0))   # ä½¿ç”¨ååŒè¿‡æ»¤å™¨ (ç´¢å¼•0)
    
    return criteria
```
:::

### æ··åˆæ··åˆ (Mixed Hybrid)

::: info ğŸ¯ ç™¾èŠ±é½æ”¾ï¼Œå¤šæ ·å‘ˆç°
è¿™å°±åƒä¸€ä¸ªç¾é£Ÿå¹¿åœºï¼ŒåŒæ—¶ä¸ºä½ å‘ˆç°æ¥è‡ªä¸åŒèœç³»ï¼ˆç®—æ³•ï¼‰çš„æ‹›ç‰Œèœï¼ˆæ¨èç»“æœï¼‰ï¼Œå¹¶å°†å®ƒä»¬ä¸€åŒå±•ç¤ºåœ¨ä½ çš„é¢å‰ã€‚è¿™ç§ç­–ç•¥çš„ä¼˜ç‚¹æ˜¯èƒ½å¤Ÿæ˜¾è‘—å¢åŠ æ¨èç»“æœçš„å¤šæ ·æ€§ã€‚
:::

::: details ğŸ’» æ··åˆæ··åˆå®ç°ä»£ç 
```python
class MixedHybridRecommender:
    def __init__(self, recommenders, mixing_ratios=None):
        self.recommenders = recommenders
        if mixing_ratios is None:
            mixing_ratios = [1.0 / len(recommenders)] * len(recommenders)
        self.mixing_ratios = mixing_ratios
        
    def recommend(self, user_id, n_recommendations=10):
        """æ··åˆæ¨èç»“æœ"""
        all_recommendations = []
        
        for i, recommender in enumerate(self.recommenders):
            # è®¡ç®—æ¯ä¸ªæ¨èå™¨åº”è¯¥è´¡çŒ®çš„æ¨èæ•°é‡
            n_from_this = int(n_recommendations * self.mixing_ratios[i])
            
            try:
                recs = recommender.recommend(user_id, n_from_this * 2)
                # æ ‡è®°æ¨èæ¥æº
                tagged_recs = [(item_id, score, f"algo_{i}") 
                              for item_id, score in recs[:n_from_this]]
                all_recommendations.extend(tagged_recs)
            except:
                continue
                
        # å»é‡å¹¶ä¿ç•™å¤šæ ·æ€§
        unique_recommendations = self._remove_duplicates_preserve_diversity(
            all_recommendations
        )
        
        return unique_recommendations[:n_recommendations]
        
    def _remove_duplicates_preserve_diversity(self, recommendations):
        """å»é‡å¹¶ä¿æŒå¤šæ ·æ€§"""
        seen_items = set()
        unique_recs = []
        
        # æŒ‰ç®—æ³•è½®è¯¢ï¼Œä¿è¯æ¯ä¸ªç®—æ³•éƒ½æœ‰ä»£è¡¨æ€§
        algo_queues = {}
        for item_id, score, algo in recommendations:
            if algo not in algo_queues:
                algo_queues[algo] = []
            algo_queues[algo].append((item_id, score, algo))
            
        # è½®è¯¢é€‰æ‹©
        max_len = max(len(queue) for queue in algo_queues.values()) if algo_queues else 0
        
        for i in range(max_len):
            for algo, queue in algo_queues.items():
                if i < len(queue):
                    item_id, score, algo_name = queue[i]
                    if item_id not in seen_items:
                        unique_recs.append((item_id, score, algo_name))
                        seen_items.add(item_id)
                        
        return unique_recs
```
:::

### ç‰¹å¾ç»„åˆ (Feature Combination)

::: info ğŸ¯ åšé‡‡ä¼—é•¿ï¼Œæ¨¡å‹èåˆ
è¿™ä¸åƒå‰å‡ ç§æ–¹æ³•åœ¨æ¨èç»“æœä¸Šåšæ–‡ç« ï¼Œè€Œæ˜¯ç›´æ¥åœ¨"åŸææ–™"å±‚é¢è¿›è¡Œèåˆã€‚å®ƒå°†ä¸åŒç®—æ³•çš„é¢„æµ‹ç»“æœä½œä¸ºæ–°çš„ç‰¹å¾ï¼Œä¸å…¶ä»–ç‰¹å¾ï¼ˆå¦‚ç”¨æˆ·ç”»åƒã€ç‰©å“å±æ€§ï¼‰ä¸€èµ·ï¼Œå–‚ç»™ä¸€ä¸ªæ›´å¼ºå¤§çš„"å…ƒæ¨¡å‹"è¿›è¡Œå­¦ä¹ ï¼Œä»è€Œåšå‡ºæ›´ç²¾å‡†çš„åˆ¤æ–­ã€‚è¿™ç§æ–¹æ³•æœ¬è´¨ä¸Šæ˜¯æœºå™¨å­¦ä¹ ä¸­çš„ Stacking æ€æƒ³ã€‚
:::

::: details ğŸ’» ç‰¹å¾ç»„åˆå®ç°ä»£ç 
```python
from sklearn.ensemble import RandomForestRegressor
import pandas as pd

class FeatureCombinationRecommender:
    def __init__(self, base_recommenders, meta_model=None):
        self.base_recommenders = base_recommenders
        if meta_model is None:
            meta_model = RandomForestRegressor(n_estimators=100, random_state=42)
        self.meta_model = meta_model
        self.is_trained = False
        
    def _extract_features(self, user_id, item_id):
        """æå–ç‰¹å¾å‘é‡"""
        features = []
        
        # åŸºç¡€æ¨èå™¨çš„é¢„æµ‹ä½œä¸ºç‰¹å¾
        for recommender in self.base_recommenders:
            try:
                pred = recommender.predict(user_id, item_id)
                features.append(pred)
            except:
                features.append(3.0)  # é»˜è®¤å€¼
                
        return np.array(features)
        
    def fit(self, training_data):
        """è®­ç»ƒå…ƒæ¨¡å‹"""
        X = []
        y = []
        
        for user_id, item_id, rating in training_data:
            features = self._extract_features(user_id, item_id)
            X.append(features)
            y.append(rating)
            
        X = np.array(X)
        y = np.array(y)
        
        self.meta_model.fit(X, y)
        self.is_trained = True
        
    def predict(self, user_id, item_id):
        """é¢„æµ‹è¯„åˆ†"""
        if not self.is_trained:
            raise ValueError("Model not trained yet")
            
        features = self._extract_features(user_id, item_id)
        return self.meta_model.predict([features])[0]
        
    def recommend(self, user_id, candidate_items, n_recommendations=10):
        """æ¨èç‰©å“"""
        predictions = []
        
        for item_id in candidate_items:
            pred = self.predict(user_id, item_id)
            predictions.append((item_id, pred))
            
        predictions.sort(key=lambda x: x[1], reverse=True)
        return predictions[:n_recommendations]
```
:::

## ğŸš€ é«˜çº§æ··åˆç­–ç•¥

å½“åŸºç¡€çš„æ··åˆç­–ç•¥æ— æ³•æ»¡è¶³å¤æ‚çš„ä¸šåŠ¡éœ€æ±‚æ—¶ï¼Œæ›´ç²¾å·§ã€æ›´åŠ¨æ€çš„é«˜çº§æ··åˆç­–ç•¥ä¾¿åº”è¿è€Œç”Ÿã€‚å®ƒä»¬é€šå¸¸æ˜¯å¤šé˜¶æ®µã€è‡ªé€‚åº”çš„ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°å¹³è¡¡æ¨èç³»ç»Ÿä¸­çš„å¤šä¸ªç›®æ ‡ã€‚

### ğŸ”„ çº§è”æ··åˆ (Cascade Hybrid)

::: info ğŸ¯ å±‚å±‚ç­›é€‰ï¼Œæ­¥æ­¥ä¸ºè¥
çº§è”æ··åˆå°±åƒä¸€ä¸ªä¸¥è°¨çš„å¤šè½®é¢è¯•æµç¨‹ã€‚å€™é€‰ç‰©å“éœ€è¦ä¾æ¬¡é€šè¿‡ååŒè¿‡æ»¤ã€å†…å®¹åŒ¹é…ã€è´¨é‡è¯„ä¼°ç­‰å¤šé“å…³å¡ï¼Œæ¯ä¸€å…³éƒ½ä¼šæ·˜æ±°æ‰ä¸€éƒ¨åˆ†ä¸åˆé€‚çš„å€™é€‰è€…ï¼Œæœ€ç»ˆåªæœ‰æœ€ä¼˜ç§€çš„æ‰èƒ½è¿›å…¥æœ€ç»ˆæ¨èåˆ—è¡¨ã€‚è¿™ç§æ–¹å¼èƒ½å¤Ÿæœ‰æ•ˆæ§åˆ¶è®¡ç®—å¼€é”€ï¼ŒåŒæ—¶ä¿è¯æœ€ç»ˆç»“æœçš„è´¨é‡ã€‚
:::

å¤šå±‚è¿‡æ»¤é€æ­¥ç²¾ç»†åŒ–ï¼š

```mermaid
flowchart TD
    A["ğŸ¬ æ‰€æœ‰å€™é€‰ç‰©å“"] --> B["ğŸ¤ ååŒè¿‡æ»¤ç²—ç­›"]
    B --> C["ğŸ“Š å†…å®¹åŒ¹é…è¿‡æ»¤"]
    C --> D["â­ è´¨é‡è¯„ä¼°è¿‡æ»¤"]
    D --> E["ğŸ¨ å¤šæ ·æ€§ä¼˜åŒ–"]
    E --> F["ğŸ“‹ æœ€ç»ˆæ¨èåˆ—è¡¨"]
    
    B --> B1["ä¿ç•™é«˜ç›¸å…³æ€§ç‰©å“"]
    C --> C1["ä¿ç•™å†…å®¹åŒ¹é…ç‰©å“"]
    D --> D1["ä¿ç•™é«˜è´¨é‡ç‰©å“"]
    E --> E1["ç¡®ä¿æ¨èå¤šæ ·æ€§"]
```

::: details ğŸ’» çº§è”æ··åˆå®ç°ä»£ç 
```python
class CascadeHybridRecommender:
    def __init__(self, recommender_stages):
        """
        recommender_stages: æ¨èå™¨é˜¶æ®µåˆ—è¡¨
        æ¯ä¸ªé˜¶æ®µåŒ…å« (recommender, filter_function, stage_name)
        """
        self.stages = recommender_stages
        
    def recommend(self, user_id, n_recommendations=10, initial_candidates=None):
        """çº§è”æ¨è"""
        if initial_candidates is None:
            # è·å–å¤§é‡å€™é€‰ç‰©å“
            initial_candidates = self._get_all_candidates(user_id)
            
        current_candidates = initial_candidates
        stage_results = {}
        
        for stage_idx, (recommender, filter_func, stage_name) in enumerate(self.stages):
            print(f"Stage {stage_idx + 1}: {stage_name}")
            print(f"Input candidates: {len(current_candidates)}")
            
            # å½“å‰é˜¶æ®µæ¨è
            stage_recs = recommender.recommend(
                user_id, 
                min(len(current_candidates), n_recommendations * (stage_idx + 2))
            )
            
            # åº”ç”¨è¿‡æ»¤æ¡ä»¶
            filtered_candidates = []
            stage_items = [item_id for item_id, _ in stage_recs]
            
            for item_id in current_candidates:
                if item_id in stage_items and filter_func(user_id, item_id):
                    # è·å–è¯¥ç‰©å“çš„è¯„åˆ†
                    item_score = next((score for iid, score in stage_recs if iid == item_id), 0)
                    filtered_candidates.append((item_id, item_score))
                    
            # æ’åºå¹¶æ›´æ–°å€™é€‰é›†
            filtered_candidates.sort(key=lambda x: x[1], reverse=True)
            current_candidates = [item_id for item_id, _ in filtered_candidates]
            
            stage_results[stage_name] = {
                'candidates': current_candidates.copy(),
                'count': len(current_candidates)
            }
            
            print(f"Output candidates: {len(current_candidates)}")
            
            # å¦‚æœå€™é€‰æ•°é‡å·²ç»æ»¡è¶³éœ€æ±‚ï¼Œå¯ä»¥æå‰ç»“æŸ
            if len(current_candidates) <= n_recommendations:
                break
                
        return current_candidates[:n_recommendations], stage_results
        
    def _get_all_candidates(self, user_id):
        """è·å–æ‰€æœ‰å€™é€‰ç‰©å“"""
        # è¿™é‡Œåº”è¯¥æ ¹æ®å®é™…æƒ…å†µå®ç°
        # å¯ä»¥æ˜¯ç”¨æˆ·æœªè¯„åˆ†çš„æ‰€æœ‰ç‰©å“
        pass
```
:::

### âš¡ åŠ¨æ€æƒé‡æ··åˆ

::: info ğŸ¯ å®æ—¶è°ƒä¼˜ï¼Œä¸æ—¶ä¿±è¿›
é™æ€æƒé‡æ— æ³•é€‚åº”ç”¨æˆ·å…´è¶£çš„å˜åŒ–å’Œç¯å¢ƒçš„å˜è¿ã€‚åŠ¨æ€æƒé‡æ··åˆåˆ™å¼•å…¥äº†å­¦ä¹ æœºåˆ¶ï¼Œå®ƒä¼šæ ¹æ®ç”¨æˆ·çš„å®æ—¶åé¦ˆï¼ˆå¦‚ç‚¹å‡»ã€è´­ä¹°ï¼‰æ¥åŠ¨æ€è°ƒæ•´ä¸åŒç®—æ³•çš„æƒé‡ã€‚è¡¨ç°å¥½çš„ç®—æ³•æƒé‡ä¼šå¢åŠ ï¼Œè¡¨ç°å·®çš„åˆ™ä¼šé™ä½ï¼Œä½¿å¾—æ•´ä¸ªç³»ç»Ÿå…·æœ‰è‡ªé€‚åº”å’ŒæŒç»­ä¼˜åŒ–çš„èƒ½åŠ›ã€‚
:::

::: details ğŸ’» åŠ¨æ€æƒé‡æ··åˆå®ç°ä»£ç 
```python
class DynamicWeightHybridRecommender:
    def __init__(self, base_recommenders, initial_weights=None, learning_rate=0.01):
        self.base_recommenders = base_recommenders
        if initial_weights is None:
            initial_weights = [1.0 / len(base_recommenders)] * len(base_recommenders)
        self.weights = np.array(initial_weights)
        self.learning_rate = learning_rate
        self.performance_history = {i: [] for i in range(len(base_recommenders))}
        
    def predict(self, user_id, item_id):
        """åŠ¨æ€æƒé‡é¢„æµ‹"""
        predictions = []
        for recommender in self.base_recommenders:
            pred = recommender.predict(user_id, item_id)
            predictions.append(pred)
            
        return np.dot(self.weights, predictions)
        
    def update_weights(self, user_id, item_id, actual_rating):
        """æ ¹æ®å®é™…åé¦ˆæ›´æ–°æƒé‡"""
        predictions = []
        errors = []
        
        # è®¡ç®—æ¯ä¸ªæ¨èå™¨çš„é¢„æµ‹å’Œè¯¯å·®
        for i, recommender in enumerate(self.base_recommenders):
            pred = recommender.predict(user_id, item_id)
            error = abs(actual_rating - pred)
            
            predictions.append(pred)
            errors.append(error)
            self.performance_history[i].append(error)
            
        # åŸºäºè¯¯å·®æ›´æ–°æƒé‡
        error_array = np.array(errors)
        
        # è®¡ç®—æƒé‡è°ƒæ•´ï¼ˆè¯¯å·®çš„å€’æ•°ä½œä¸ºæ€§èƒ½æŒ‡æ ‡ï¼‰
        performance = 1.0 / (error_array + 1e-10)  # é¿å…é™¤é›¶
        performance = performance / np.sum(performance)  # å½’ä¸€åŒ–
        
        # æ¢¯åº¦æ›´æ–°
        weight_update = self.learning_rate * (performance - self.weights)
        self.weights += weight_update
        
        # ç¡®ä¿æƒé‡éè´Ÿä¸”å½’ä¸€åŒ–
        self.weights = np.maximum(self.weights, 0.01)  # æœ€å°æƒé‡é˜²æ­¢æŸä¸ªç®—æ³•å®Œå…¨è¢«å¿½ç•¥
        self.weights = self.weights / np.sum(self.weights)
        
    def get_performance_summary(self, window_size=100):
        """è·å–æ€§èƒ½æ‘˜è¦"""
        summary = {}
        for i, history in self.performance_history.items():
            if len(history) > 0:
                recent_performance = history[-window_size:] if len(history) > window_size else history
                summary[f"Algorithm_{i}"] = {
                    'current_weight': self.weights[i],
                    'recent_avg_error': np.mean(recent_performance),
                    'total_predictions': len(history)
                }
        return summary
```
:::

## ğŸ“Š è¯„ä¼°ä¸ä¼˜åŒ–

æ··åˆæ¨èç³»ç»Ÿçš„æˆåŠŸä¸å¦ï¼Œä¸èƒ½ä»…ä»…ä¾èµ–äºç¦»çº¿è¯„ä¼°çš„å‡†ç¡®ç‡ã€‚ä¸€ä¸ªå¥å£®çš„è¯„ä¼°ä½“ç³»éœ€è¦ä»å¤šä¸ªç»´åº¦è€ƒé‡ï¼Œå¹¶ä¸”æœ€ç»ˆè¦é€šè¿‡åœ¨çº¿çš„ A/B æµ‹è¯•æ¥éªŒè¯å…¶çœŸæ­£ä»·å€¼ã€‚

### ğŸ¯ å¤šç›®æ ‡è¯„ä¼°æ¡†æ¶

::: info ğŸ¯ å…¨é¢ä½“æ£€ï¼Œè€Œéå•ç§‘æµ‹è¯•
åªçœ‹å‡†ç¡®ç‡çš„è¯„ä¼°æ˜¯ç‰‡é¢çš„ã€‚ä¸€ä¸ªå¥½çš„æ¨èç³»ç»Ÿè¿˜éœ€è¦è€ƒè™‘å¤šæ ·æ€§ï¼ˆèƒ½å¦æ¨èä¸åŒç±»å‹çš„ç‰©å“ï¼‰ã€æ–°é¢–æ€§ï¼ˆèƒ½å¦æ¨èç”¨æˆ·ä¸çŸ¥é“çš„æ–°ä¸œè¥¿ï¼‰å’Œè¦†ç›–ç‡ï¼ˆæ¨¡å‹èƒ½æ¨èçš„ç‰©å“èŒƒå›´æœ‰å¤šå¹¿ï¼‰ã€‚å¤šç›®æ ‡è¯„ä¼°æ¡†æ¶æ—¨åœ¨å»ºç«‹ä¸€ä¸ªå…¨é¢çš„"ä½“æ£€æŠ¥å‘Š"ï¼Œç³»ç»Ÿæ€§åœ°è¡¡é‡æ··åˆç­–ç•¥çš„ç»¼åˆè¡¨ç°ã€‚
:::

::: details ğŸ’» å¤šç›®æ ‡è¯„ä¼°ä»£ç 
```python
class HybridRecommenderEvaluator:
    def __init__(self):
        self.metrics = {}
        
    def evaluate(self, recommender, test_data, diversity_threshold=0.7):
        """ç»¼åˆè¯„ä¼°æ··åˆæ¨èç³»ç»Ÿ"""
        results = {}
        
        # å‡†ç¡®æ€§æŒ‡æ ‡
        results['accuracy'] = self._evaluate_accuracy(recommender, test_data)
        
        # å¤šæ ·æ€§æŒ‡æ ‡
        results['diversity'] = self._evaluate_diversity(recommender, test_data)
        
        # æ–°é¢–æ€§æŒ‡æ ‡
        results['novelty'] = self._evaluate_novelty(recommender, test_data)
        
        # è¦†ç›–ç‡æŒ‡æ ‡
        results['coverage'] = self._evaluate_coverage(recommender, test_data)
        
        return results
        
    def _evaluate_accuracy(self, recommender, test_data):
        """è¯„ä¼°å‡†ç¡®æ€§"""
        predictions = []
        actuals = []
        
        for user_id, item_id, rating in test_data:
            pred = recommender.predict(user_id, item_id)
            predictions.append(pred)
            actuals.append(rating)
            
        rmse = np.sqrt(np.mean((np.array(predictions) - np.array(actuals)) ** 2))
        mae = np.mean(np.abs(np.array(predictions) - np.array(actuals)))
        
        return {'rmse': rmse, 'mae': mae}
        
    def _evaluate_diversity(self, recommender, test_data):
        """è¯„ä¼°å¤šæ ·æ€§"""
        user_recommendations = {}
        
        # ä¸ºæ¯ä¸ªç”¨æˆ·ç”Ÿæˆæ¨è
        for user_id in set(user for user, _, _ in test_data):
            recs = recommender.recommend(user_id, 10)
            user_recommendations[user_id] = [item_id for item_id, _ in recs]
            
        # è®¡ç®—æ¨èåˆ—è¡¨å†…å¤šæ ·æ€§ï¼ˆILD - Intra-List Diversityï¼‰
        diversity_scores = []
        for user_id, rec_list in user_recommendations.items():
            if len(rec_list) > 1:
                total_similarity = 0
                pair_count = 0
                
                for i in range(len(rec_list)):
                    for j in range(i + 1, len(rec_list)):
                        # è¿™é‡Œéœ€è¦å®ç°ç‰©å“ç›¸ä¼¼åº¦è®¡ç®—
                        similarity = self._compute_item_similarity(rec_list[i], rec_list[j])
                        total_similarity += similarity
                        pair_count += 1
                        
                avg_similarity = total_similarity / pair_count if pair_count > 0 else 0
                diversity = 1 - avg_similarity
                diversity_scores.append(diversity)
                
        return np.mean(diversity_scores) if diversity_scores else 0
        
    def _compute_item_similarity(self, item1, item2):
        """è®¡ç®—ç‰©å“ç›¸ä¼¼åº¦ï¼ˆéœ€è¦æ ¹æ®å®é™…æƒ…å†µå®ç°ï¼‰"""
        # ç®€åŒ–å®ç°ï¼šéšæœºç›¸ä¼¼åº¦
        return np.random.random()
```
:::

### ğŸ”¬ A/Bæµ‹è¯•æ¡†æ¶

::: info ğŸ¯ æ˜¯éª¡å­æ˜¯é©¬æ‹‰å‡ºæ¥é›é›
ç¦»çº¿æŒ‡æ ‡è¡¨ç°å†å¥½ï¼Œä¹Ÿå¯èƒ½åªæ˜¯"å®éªŒå®¤æ•°æ®"ã€‚A/B æµ‹è¯•æ˜¯æ£€éªŒæ¨èç³»ç»ŸçœŸå®æ•ˆæœçš„é»„é‡‘æ ‡å‡†ã€‚é€šè¿‡å°†ç”¨æˆ·éšæœºåˆ†æµåˆ°å¯¹ç…§ç»„ï¼ˆä½¿ç”¨æ—§ç®—æ³•ï¼‰å’Œå®éªŒç»„ï¼ˆä½¿ç”¨æ–°æ··åˆç­–ç•¥ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥æ¯”è¾ƒå®ƒä»¬åœ¨çœŸå®ä¸šåŠ¡æŒ‡æ ‡ï¼ˆå¦‚ç‚¹å‡»ç‡ã€è½¬åŒ–ç‡ï¼‰ä¸Šçš„è¡¨ç°å·®å¼‚ï¼Œä»è€Œåšå‡ºæœ€å¯é çš„å†³ç­–ã€‚
:::

::: details ğŸ’» A/Bæµ‹è¯•æ¡†æ¶ä»£ç 
```python
import time

class ABTestFramework:
    def __init__(self, control_recommender, test_recommender, traffic_split=0.5):
        self.control_recommender = control_recommender
        self.test_recommender = test_recommender
        self.traffic_split = traffic_split
        self.test_results = {'control': [], 'test': []}
        
    def get_recommendation(self, user_id, n_recommendations=10):
        """æ ¹æ®A/Bæµ‹è¯•åˆ†æµè·å–æ¨è"""
        # ç®€å•çš„å“ˆå¸Œåˆ†æµ
        user_hash = hash(str(user_id)) % 100
        
        if user_hash < self.traffic_split * 100:
            group = 'test'
            recommendations = self.test_recommender.recommend(user_id, n_recommendations)
        else:
            group = 'control'
            recommendations = self.control_recommender.recommend(user_id, n_recommendations)
            
        return recommendations, group
        
    def log_interaction(self, user_id, item_id, interaction_type, group):
        """è®°å½•ç”¨æˆ·äº¤äº’"""
        self.test_results[group].append({
            'user_id': user_id,
            'item_id': item_id,
            'interaction_type': interaction_type,  # 'click', 'purchase', 'rating' etc.
            'timestamp': time.time()
        })
        
    def analyze_results(self):
        """åˆ†æA/Bæµ‹è¯•ç»“æœ"""
        control_metrics = self._compute_metrics(self.test_results['control'])
        test_metrics = self._compute_metrics(self.test_results['test'])
        
        return {
            'control': control_metrics,
            'test': test_metrics,
            'improvement': self._compute_improvement(control_metrics, test_metrics)
        }
        
    def _compute_metrics(self, interactions):
        """è®¡ç®—æŒ‡æ ‡"""
        if not interactions:
            return {}
            
        total_interactions = len(interactions)
        click_rate = len([i for i in interactions if i['interaction_type'] == 'click']) / total_interactions
        purchase_rate = len([i for i in interactions if i['interaction_type'] == 'purchase']) / total_interactions
        
        return {
            'total_interactions': total_interactions,
            'click_rate': click_rate,
            'purchase_rate': purchase_rate
        }
        
    def _compute_improvement(self, control, test):
        """è®¡ç®—æ”¹è¿›å¹…åº¦"""
        improvements = {}
        for metric in control:
            if control[metric] > 0:
                improvement = (test[metric] - control[metric]) / control[metric] * 100
                improvements[f"{metric}_improvement"] = improvement
        return improvements
```
:::

## ğŸ“ˆ å®é™…åº”ç”¨æ¡ˆä¾‹

### ğŸ¬ Netflixçš„æ··åˆæ¨èæ¶æ„

```mermaid
flowchart TD
    A["ğŸ‘¤ ç”¨æˆ·ç”»åƒ<br/>è§‚çœ‹å†å²ã€è¯„åˆ†"] --> B["ğŸ¤ ååŒè¿‡æ»¤<br/>ç”¨æˆ·ç›¸ä¼¼åº¦"]
    A --> C["ğŸ“Š å†…å®¹åˆ†æ<br/>ç±»å‹ã€æ¼”å‘˜ã€å¯¼æ¼”"]
    A --> D["ğŸ“º ä¸Šä¸‹æ–‡æ„ŸçŸ¥<br/>æ—¶é—´ã€è®¾å¤‡ã€ä½ç½®"]
    
    B --> E["âš–ï¸ åŠ æƒèåˆ<br/>åŠ¨æ€æƒé‡è°ƒæ•´"]
    C --> E
    D --> E
    
    E --> F["ğŸ¯ ä¸ªæ€§åŒ–æ¨è<br/>å¤šæ ·æ€§ä¼˜åŒ–"]
    
    F --> G["ğŸ“± é¦–é¡µæ¨è"]
    F --> H["ğŸ” æœç´¢æ¨è"]
    F --> I["ğŸ“º è§‚çœ‹å®Œæˆæ¨è"]
```

**ğŸ”‘ å…³é”®æŠ€æœ¯è¦ç‚¹**ï¼š
- **å¤šå±‚æ¬¡èåˆ**ï¼šçŸ©é˜µåˆ†è§£+æ·±åº¦å­¦ä¹ +å†…å®¹åˆ†æ
- **å®æ—¶æƒé‡è°ƒæ•´**ï¼šæ ¹æ®ç”¨æˆ·åé¦ˆåŠ¨æ€ä¼˜åŒ–
- **åœºæ™¯æ„ŸçŸ¥**ï¼šä¸åŒåœºæ™¯ä½¿ç”¨ä¸åŒç­–ç•¥

### ğŸ›’ Amazonçš„å¤šå±‚æ··åˆç­–ç•¥

```mermaid
flowchart LR
    A["ğŸ” æµè§ˆè¡Œä¸º"] --> B["ğŸ“Š å®æ—¶æ¨è"]
    C["ğŸ›’ è´­ä¹°å†å²"] --> D["ğŸ“ˆ é•¿æœŸåå¥½"]
    E["ğŸ”— å…³è”è§„åˆ™"] --> F["ğŸ¯ äº¤å‰é”€å”®"]
    
    B --> G["ğŸ­ æ··åˆå¼•æ“"]
    D --> G
    F --> G
    
    G --> H["ğŸ  é¦–é¡µæ¨è"]
    G --> I["ğŸ“¦ è´­ä¹°é¡µæ¨è"]
    G --> J["ğŸ“§ é‚®ä»¶æ¨è"]
```

## ğŸ“š å»¶ä¼¸é˜…è¯»

### ğŸ›ï¸ ç»å…¸è®ºæ–‡
- **Burke (2002)**: "Hybrid Recommender Systems: Survey and Experiments" - æ··åˆæ¨èç³»ç»Ÿæƒå¨ç»¼è¿°
- **Adomavicius & Tuzhilin (2005)**: "Toward the next generation of recommender systems" - æ¨èç³»ç»Ÿå‘å±•è¶‹åŠ¿å’Œæœªæ¥æ–¹å‘
- **Su & Khoshgoftaar (2009)**: "A survey of collaborative filtering techniques" - ååŒè¿‡æ»¤æŠ€æœ¯å…¨é¢è°ƒç ”

### ğŸ“– æŠ€æœ¯èµ„æº
- **Apache Mahout**: å¤§è§„æ¨¡æ··åˆæ¨èç³»ç»Ÿå®ç°æ¡†æ¶
- **Surprise**: Pythonæ¨èç³»ç»Ÿåº“ï¼Œæ”¯æŒå¤šç§æ··åˆç­–ç•¥
- **TensorFlow Recommenders**: Googleçš„æ·±åº¦å­¦ä¹ æ¨èç³»ç»Ÿæ¡†æ¶

### ğŸ­ å·¥ä¸šå®è·µæ¡ˆä¾‹
- **ğŸ¬ Netflix**: å¤æ‚çš„å¤šå±‚æ··åˆæ¨èç³»ç»Ÿæ¶æ„
- **ğŸ›’ Amazon**: å¤šåœºæ™¯ä¸‹çš„æ··åˆæ¨èç­–ç•¥
- **ğŸµ Spotify**: éŸ³ä¹æ¨èä¸­çš„åˆ›æ–°æ··åˆæ–¹æ³•


> ğŸ§  **æ€è€ƒé¢˜**
> 
> 1. åœ¨åŠ æƒæ··åˆä¸­ï¼Œå¦‚ä½•åŠ¨æ€è°ƒæ•´ä¸åŒç®—æ³•çš„æƒé‡ï¼Ÿè®¾è®¡ä¸€ä¸ªåŸºäºåœ¨çº¿å­¦ä¹ çš„æƒé‡æ›´æ–°ç­–ç•¥ã€‚
> 
> 2. æ··åˆæ¨èç³»ç»Ÿå¦‚ä½•æ›´å¥½åœ°å¤„ç†å†·å¯åŠ¨é—®é¢˜ï¼Ÿä¸åŒçš„æ··åˆç­–ç•¥åœ¨å†·å¯åŠ¨åœºæ™¯ä¸‹æœ‰ä»€ä¹ˆå·®å¼‚ï¼Ÿ
> 
> 3. æ··åˆæ¨èç³»ç»Ÿé€šå¸¸è®¡ç®—å¤æ‚åº¦è¾ƒé«˜ï¼Œå¦‚ä½•åœ¨ä¿è¯æ¨èè´¨é‡çš„å‰æä¸‹ä¼˜åŒ–è®¡ç®—æ•ˆç‡ï¼Ÿ
> 
> 4. å¦‚ä½•åœ¨æ··åˆæ¨èä¸­å¹³è¡¡å‡†ç¡®æ€§å’Œå¤šæ ·æ€§ï¼Ÿè®¾è®¡ä¸€ä¸ªå¤šç›®æ ‡ä¼˜åŒ–çš„æ··åˆç­–ç•¥ã€‚
> 
> 5. å¦‚ä½•è®¾è®¡ä¸€ä¸ªèƒ½å¤Ÿå®æ—¶é€‚åº”ç”¨æˆ·è¡Œä¸ºå˜åŒ–çš„æ··åˆæ¨èç³»ç»Ÿï¼Ÿè€ƒè™‘æ¦‚å¿µæ¼‚ç§»å’Œæ¨¡å‹æ›´æ–°çš„é—®é¢˜ã€‚

::: tip ğŸ‰ ç« èŠ‚å°ç»“
æ··åˆæ¨èæ¨¡å‹ä½“ç°äº†"å–é•¿è¡¥çŸ­"çš„æ™ºæ…§ï¼Œé€šè¿‡å·§å¦™ç»„åˆä¸åŒç®—æ³•çš„ä¼˜åŠ¿ï¼Œåœ¨å‡†ç¡®æ€§ã€å¤šæ ·æ€§ã€æ–°é¢–æ€§ç­‰å¤šä¸ªç»´åº¦ä¸Šå®ç°äº†æ˜¾è‘—æå‡ã€‚ä»ç®€å•çš„åŠ æƒæ··åˆåˆ°å¤æ‚çš„çº§è”ç­–ç•¥ï¼Œä»é™æ€æƒé‡åˆ°åŠ¨æ€è°ƒæ•´ï¼Œæ··åˆæ¨èç³»ç»Ÿå±•ç°äº†æ¨èç®—æ³•çš„é›†å¤§æˆä¹‹ç¾ã€‚æŒæ¡å„ç§æ··åˆç­–ç•¥çš„åŸç†å’Œå®ç°ï¼Œä¸ä»…æ˜¯æ„å»ºé«˜è´¨é‡æ¨èç³»ç»Ÿçš„å¿…å¤‡æŠ€èƒ½ï¼Œæ›´æ˜¯ç†è§£å¦‚ä½•åœ¨å¤æ‚ä¸šåŠ¡åœºæ™¯ä¸­å¹³è¡¡å¤šé‡ç›®æ ‡çš„å…³é”®æ‰€åœ¨ã€‚
:::


> æ··åˆæ¨èçš„æœ¬è´¨ï¼Œå°±æ˜¯ä¸åš"åç§‘ç”Ÿ"ï¼Œè€Œæ˜¯é›†å„å®¶ä¹‹é•¿ï¼Œåƒä¹é˜ŸæŒ‡æŒ¥ä¸€æ ·ï¼Œè®©ä¸åŒä¹å™¨ï¼ˆç®—æ³•ï¼‰åœ¨æœ€åˆé€‚çš„æ—¶æœºå¥å“ï¼Œæœ€ç»ˆåˆå¥å‡ºä¸€æ›²æœ€æ‡‚ä½ çš„ä¸ªæ€§åŒ–ä¹ç« ã€‚

