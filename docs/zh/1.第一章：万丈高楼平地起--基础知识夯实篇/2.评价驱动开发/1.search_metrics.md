---
title: 搜索系统评价指标：让"好结果"有据可依
createTime: 2025/06/16 10:00:00

---

## 🎯 为什么要评价搜索？

> **没有量化，就没有进步。**

搜索引擎的目标是"让用户快速、准确地找到想要的信息"。但什么样的结果才算"好"？如何科学地比较两个算法的优劣？这就需要一套系统的评价指标。

## 🧩 评价体系的三大维度

| 维度 | 代表指标 | 关注点 |
|------|----------|--------|
| **相关性** | Precision, Recall, MAP, NDCG | 结果是否满足用户需求 |
| **效率** | 响应时间、QPS | 系统是否足够快 |
| **用户体验** | 点击率、停留时长 | 用户是否满意、愿意使用 |

本节聚焦**相关性**，即"结果好不好"。

## 🔍 相关性评价的核心指标

### 1. 精确率（Precision）

- **定义**：返回的结果中有多少是相关的？
- **公式**：
  $$
  \text{Precision} = \frac{\text{相关结果数}}{\text{返回结果总数}}
  $$
- **举例**：
  - 返回10条结果，8条相关，Precision=0.8

### 2. 召回率（Recall）

- **定义**：所有相关结果中，有多少被找到了？
- **公式**：
  $$
  \text{Recall} = \frac{\text{相关结果数}}{\text{所有相关结果总数}}
  $$
- **举例**：
  - 实际有20条相关，返回8条，Recall=0.4

### 3. F1分数（F1 Score）

- **定义**：精确率和召回率的调和平均
- **公式**：
  $$
  F1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
  $$
- **意义**：兼顾"查得准"和"查得全"

### 4. 平均精度均值（MAP）

- **定义**：多个查询下，平均每个查询的平均精度
- **公式**：
  $$
  MAP = \frac{1}{Q} \sum_{q=1}^Q AP(q)
  $$
  其中$AP(q)$为第$q$个查询的平均精度
- **适用场景**：学术评测、离线对比

### 5. NDCG（归一化折扣累计增益）

- **定义**：考虑结果排序和相关性等级的指标
- **公式**：
  $$
  DCG@k = \sum_{i=1}^k \frac{2^{rel_i}-1}{\log_2(i+1)}
  $$
  $$
  NDCG@k = \frac{DCG@k}{IDCG@k}
  $$
  其中$rel_i$为第$i$条结果的相关性等级，$IDCG$为理想排序下的$DCG$
- **意义**：排名越靠前的高相关结果，贡献越大

### 6. MRR（Mean Reciprocal Rank）

- **定义**：第一个相关结果出现的位置的倒数，取平均
- **公式**：
  $$
  MRR = \frac{1}{Q} \sum_{q=1}^Q \frac{1}{rank_q}
  $$
  其中$rank_q$为第$q$个查询第一个相关结果的排名
- **适用场景**：问答、导航型搜索

## 🧪 实验设计与评测流程

1. **构建测试集**：人工标注查询-文档对的相关性
2. **离线评测**：用上述指标对比不同算法
3. **在线实验**：A/B测试，观察用户行为指标
4. **多维度分析**：结合相关性、效率、体验综合评估

## 📈 指标的权衡与选择

- 精确率高≠召回率高，二者常常此消彼长
- NDCG适合多等级相关性，MAP适合二分类相关性
- 业务目标决定指标侧重：
  - 学术/工具型：更关注精确率、NDCG
  - 内容/娱乐型：更关注召回率、多样性


> **思考题**
> 1. 为什么精确率和召回率往往难以兼得？
> 2. NDCG相比于MAP，有哪些优势？
> 3. 在实际业务中，如何平衡离线指标和用户体验？

::: tip 🎉 章节小结
搜索评价指标是"让好有据可依"的科学工具。它们帮助我们量化算法的优劣，指导系统优化方向。理解每个指标的含义和适用场景，是成为搜索算法专家的必修课。
:::

> **评价指标就像搜索的"体检报告"——只有定期体检，才能发现问题、持续进步。**






