{"content":"<p>想象一下，你是一个大型视频网站的算法工程师，你的面前是数亿的视频库存和上亿的用户。当一个用户打开APP时，你需要在毫秒之内，从这片视频的“汪洋大海”中，为他挑选出他最可能感兴趣的几百个视频。</p>\n<p>这就是 <strong>召回（Recall）</strong> 阶段的核心挑战。</p>\n<p>为什么我们不能直接用一个精细的排序模型（比如DeepFM）给所有视频都打个分呢？答案是：<strong>算不动！</strong> 对亿万视频逐一打分，耗时将是灾难性的。</p>\n<p>因此，推荐系统被设计为两个核心阶段：</p>\n<ol>\n<li><strong>召回阶段</strong>：快！准！目标是从海量物料库中，快速、批量地筛选出一个较小的候选集（比如几百到几千个），保证用户可能感兴趣的内容基本都在这个池子里。</li>\n<li><strong>排序阶段</strong>：精！细！对召回的候选集使用复杂模型进行精准排序，决定最终的呈现顺序。</li>\n</ol>\n<p>召回，就是这场“大海捞针”艺术的第一步，也是决定整个推荐系统天花板的关键一步。</p>\n<h2 id=\"💡-核心思想-双塔模型-一场高效的-相亲大会\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#💡-核心思想-双塔模型-一场高效的-相亲大会\"><span>💡 核心思想：双塔模型，一场高效的“相亲大会”</span></a></h2>\n<p>为了解决召回的效率问题，<strong>双塔模型（Two-Tower Model）</strong> 应运而生，它已成为深度召回的业界标准范式。</p>\n<p>我们可以把它比作一场大型的“线上相亲大会”：</p>\n<ul>\n<li><strong>物品塔 (Item Tower)</strong>：相当于“女生信息库”。我们提前把所有女生的信息（物品特征）输入物品塔，精心计算并生成每个女生的专属“魅力向量”（Item Embedding）。这项工作可以离线完成，并存入一个可被快速检索的向量数据库（如Faiss）。</li>\n<li><strong>用户塔 (User Tower)</strong>：相当于“男生信息处理器”。当一位男生（用户）来到会场，我们迅速将他的信息（用户特征、历史行为）输入用户塔，实时计算出他的“择偶标准向量”（User Embedding）。</li>\n</ul>\n<p><strong>匹配过程</strong>：拿着这个新鲜出炉的“男生标准向量”，去庞大的“女生魅力向量库”中进行光速检索，找出匹配度最高的Top-K个女生。</p>\n<Mermaid id=\"mermaid-51\" code=\"eJxLL0osyFAIceFSAILi0iQIX+n5st3Pd+1/uqTl+YQ2BQ3/tLSczLxUTSWwKhBIySxKTS7JzM9T8AmCC3pGKz3buv1le//zzpVPJzc+3TVZKVZBV9dOwTMkWgkqtnCKTVKRvp1nSWquQkh+eWqRUixCfwhEdRhMtWtuUmpKSmZe+tMJE4HGAg1EaIbLKbg4KWi4JWYWF+t7+AWHa0INTM1L4ULz1NM5K4Ceejan92nXQqCn8ojxUyjQLVNWPOvY/mL99mcbm6AeCgV5CCwM81BocWoRhodCIR4KdYWphjsayZEgGkyEuoJU1yhBPPtsccPzLYsUNBz9/BSCUxOLkjM0lWqAYQNW6hkGURqSX6DrrfB89+Rn8+YAZYOilZ72r3k6e97TjukvFq4AWsIFAKsfseg=\"></Mermaid><p>这个架构的精髓在于<strong>将用户和物品的复杂交互，解耦为两个独立塔的向量表示</strong>，从而将排序阶段昂贵的在线计算，转化为召回阶段高效的向量相似度搜索。</p>\n<h2 id=\"🏛️-模型演进之路-从奠基到成熟\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#🏛️-模型演进之路-从奠基到成熟\"><span>🏛️ 模型演进之路：从奠基到成熟</span></a></h2>\n<h3 id=\"dssm-双塔模型的-开山鼻祖\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#dssm-双塔模型的-开山鼻祖\"><span>DSSM：双塔模型的“开山鼻祖”</span></a></h3>\n<p>DSSM (Deep Structured Semantic Model) 最初用于解决搜索引擎中查询（Query）和文档（Document）的语义匹配问题，其思想被完美迁移到推荐领域，奠定了双塔模型的基础。</p>\n<ul>\n<li><strong>核心思想</strong>：用两个结构相同（但参数不共享）的DNN，分别将用户特征和物品特征映射到同一个低维语义空间，然后通过计算余弦相似度来衡量匹配程度。</li>\n<li><strong>训练目标</strong>：最大化用户与正样本（点击过的物品）的相似度，同时最小化与负样本的相似度。</li>\n</ul>\n<details class=\"hint-container details\"><summary>💻 DSSM 模型实现 (参考 torch-rechub)</summary>\n<div class=\"language-python line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"python\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code class=\"language-python\"><span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">import</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">import</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">as</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> nn</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">from</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch_rechub</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">models</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">layers </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">import</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> MLP</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">class</span><span style=\"--shiki-light:#2E8F82;--shiki-dark:#5DA994\"> DSSM</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">Module</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">    Deep Structured Semantic Model</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">    </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">    Args:</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        user_features (list): 用户侧特征列表.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        item_features (list): 物品侧特征列表.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        user_mlp_params (dict): 用户塔MLP的参数.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        item_mlp_params (dict): 物品塔MLP的参数.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        temperature (float): 温度系数，用于调整softmax输出.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\"> __init__</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> user_features</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> item_features</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> user_mlp_params</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> item_mlp_params</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> temperature</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1.0</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">        super</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">().</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">__init__</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 用户塔：特征处理层 + MLP</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">user_tower </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Sequential</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">            MLP</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">input_dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">sum</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">f</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">embed_dim </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">for</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> f </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">in</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> user_features</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">),</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\"> **</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">user_mlp_params</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">        )</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 物品塔：特征处理层 + MLP</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">item_tower </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Sequential</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">            MLP</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">input_dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">sum</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">f</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">embed_dim </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">for</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> f </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">in</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> item_features</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">),</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\"> **</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">item_mlp_params</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">        )</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">temperature </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> temperature</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # torch-rechub中特征处理由专门的feature_layer完成，这里为简化展示，假定输入已是拼接好的特征</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\"> user_embedding</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> x</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">        \"\"\"</span><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">获取用户embedding</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">        return</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">user_tower</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">x</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\"> item_embedding</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> x</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">        \"\"\"</span><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">获取物品embedding</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">        return</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">item_tower</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">x</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\"> forward</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> x_user</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> x_item</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        计算用户和物品的匹配分数</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        Args:</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">            x_user (torch.Tensor): 用户侧的输入特征.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">            x_item (torch.Tensor): 物品侧的输入特征.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        Returns:</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">            torch.Tensor: 匹配分数 (logits).</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        user_embedding </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">user_tower</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">x_user</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        item_embedding </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">item_tower</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">x_item</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 计算余弦相似度，并用温度系数调整</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        y </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">mul</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">user_embedding</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> item_embedding</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">).</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">sum</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        y </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> y </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">/</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">temperature</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">        return</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> y</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div></details>\n<h3 id=\"youtubednn-工业界的-集大成者\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#youtubednn-工业界的-集大成者\"><span>YouTubeDNN：工业界的“集大成者”</span></a></h3>\n<p>Google 的 YouTubeDNN 模型是深度召回在工业界成功应用的典范。它极大地丰富了用户塔的内涵，使其能更精准地刻画用户的瞬时兴趣。</p>\n<ul>\n<li><strong>核心思想</strong>：用户的兴趣可以通过他<strong>最近观看过的视频序列</strong>来表达。</li>\n<li><strong>用户塔构建</strong>：\n<ol>\n<li>将用户最近观看过的N个视频的Embedding取出。</li>\n<li>对这些Embedding做<strong>加权平均</strong>，得到一个代表用户历史兴趣的向量。</li>\n<li>再拼接上用户的人口统计学特征、搜索历史等其他特征。</li>\n<li>最后将拼接好的大向量输入一个DNN，生成最终的User Embedding。</li>\n</ol>\n</li>\n<li><strong>创新点</strong>：\n<ul>\n<li><strong>Example Age</strong>：引入“样本年龄”作为特征，帮助模型感知时间的流逝，修正对老旧视频的流行度偏见。</li>\n<li><strong>负采样</strong>：采用基于物品流行度的负采样策略，高效地进行模型训练。</li>\n</ul>\n</li>\n</ul>\n<details class=\"hint-container details\"><summary>💻 YouTubeDNN 模型实现 (参考 torch-rechub)</summary>\n<div class=\"language-python line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"python\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code class=\"language-python\"><span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">import</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">import</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">as</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> nn</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">from</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch_rechub</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">models</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">layers </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">import</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> MLP</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> SequencePoolingLayer</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">class</span><span style=\"--shiki-light:#2E8F82;--shiki-dark:#5DA994\"> YouTubeDNN</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">Module</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">    YouTube Deep Neural Networks for Recommendations</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">    </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">    Args:</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        user_features (list): 用户侧特征列表.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        item_features (list): 物品侧特征列表 (用于负采样).</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        neg_item_feature (str): 负采样物品的特征名.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        user_params (dict): 用户塔MLP的参数.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        temperature (float): 温度系数.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\"> __init__</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> user_features</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> item_features</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> neg_item_feature</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> user_params</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> temperature</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1.0</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">        super</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">().</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">__init__</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">user_features </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> user_features</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">item_features </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> item_features</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">neg_item_feature </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> neg_item_feature</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">temperature </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> temperature</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 物品的Embedding层是共享的</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 在torch-rechub中，这通常通过共享embedding_layer的名称实现</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 此处为简化，假定有一个共享的embedding_layer</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">embedding_layer </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">get_shared_embedding_layer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 用户塔</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 序列特征的池化层</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">seq_pooling_layer </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> SequencePoolingLayer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">pooling_type</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"</span><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">mean</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 用户塔的MLP</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">user_tower </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> MLP</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">            input_dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">get_user_input_dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(),</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">            **</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">user_params</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"</span><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">mlp_params</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">]</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">        )</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\"> forward</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> x</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        此模型在torch-rechub中通常用于训练，直接输出loss</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        这里为了展示，我们分解其核心逻辑</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 1. 获取所有物品的Embedding</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 在实际训练中，通过负采样得到一个batch的物品</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        item_embs </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">embedding_layer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">x</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">neg_item_feature</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">])</span><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"> # (batch_size, n_neg+1, emb_dim)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 2. 构建用户塔输入</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # a. 聚合用户历史行为序列</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        watch_history_emb </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">seq_pooling_layer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">embedding_layer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">x</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"</span><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">watch_history</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">]))</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # b. 获取其他用户特征 (如年龄、性别)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        user_other_features_emb </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">get_user_other_features</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">x</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # c. 拼接所有用户侧特征</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        user_tower_input </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">cat</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">([</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">watch_history_emb</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> user_other_features_emb</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">],</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 3. 计算用户Embedding</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        user_embedding </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">user_tower</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">user_tower_input</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"> # (batch_size, emb_dim)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 4. 计算用户与所有采样物品的相似度 (内积)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # user_embedding需要扩展维度以进行批次矩阵乘法</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        logits </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">bmm</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">item_embs</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> user_embedding</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">unsqueeze</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">-</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)).</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">squeeze</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">-</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"> # (batch_size, n_neg+1)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 训练时，这里的logits会直接送入交叉熵损失函数</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">        return</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> logits</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div></details>\n<h3 id=\"mind-洞悉用户的-多面人生\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#mind-洞悉用户的-多面人生\"><span>MIND：洞悉用户的“多面人生”</span></a></h3>\n<p>一个用户可能既喜欢看烧菜视频，又喜欢看篮球集锦。用单一的向量来概括他的全部兴趣，显然是有局限的。MIND (Multi-Interest Network with Dynamic Routing) 模型应运而生。</p>\n<ul>\n<li><strong>核心思想</strong>：为每个用户生成<strong>多个兴趣向量</strong>，每个向量代表用户的一个特定兴趣簇。</li>\n<li><strong>动态路由 (Dynamic Routing)</strong>：通过<strong>胶囊网络 (Capsule Network)</strong> 的思想，将用户的历史行为Embedding进行动态聚类，自适应地生成K个兴趣中心（K个兴趣向量）。</li>\n<li><strong>匹配过程</strong>：当一个候选物品（如一个篮球视频）过来时，模型会智能地计算该物品与用户的哪个兴趣向量（篮球兴趣）最匹配，并用这个最匹配的兴趣向量来计算最终的相似度。</li>\n</ul>\n<p>这使得召回模型从“一对一”的匹配，升级为更灵活、更精准的“一对多”匹配。</p>\n<h2 id=\"⚙️-工业部署-从模型到服务\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#⚙️-工业部署-从模型到服务\"><span>⚙️ 工业部署：从模型到服务</span></a></h2>\n<p>一个深度召回模型要真正上线发挥作用，还需要一整套强大的工程体系支撑。</p>\n<ol>\n<li>\n<p><strong>离线流程 (Offline)</strong></p>\n<ul>\n<li><strong>模型训练</strong>：使用海量用户行为日志，训练双塔模型。</li>\n<li><strong>向量产出</strong>：训练完成后，将<strong>物品塔</strong>单独拿出来，对全量物品进行推理，产出所有物品的Embedding向量。</li>\n<li><strong>索引构建</strong>：将全量物品向量灌入<strong>ANN检索引擎</strong>（如Faiss、HNSW），构建高效的向量索引文件，并推送到线上。</li>\n</ul>\n</li>\n<li>\n<p><strong>在线流程 (Online)</strong></p>\n<ul>\n<li><strong>实时特征</strong>：当用户请求到达时，实时获取用户的基本特征和短期行为序列。</li>\n<li><strong>实时推理</strong>：将特征输入到线上的<strong>用户塔</strong>模型中，实时计算出用户当前的Embedding向量。</li>\n<li><strong>实时检索</strong>：用新鲜出炉的用户Embedding，去ANN引擎中进行检索，拉取最相似的Top-K个物品ID。</li>\n<li><strong>物料补充</strong>：将检索到的物品ID，去缓存（如Redis）中补全物品的标题、封面图等信息，返回给下游的排序服务。</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"📖-延伸阅读\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#📖-延伸阅读\"><span>📖 <strong>延伸阅读</strong></span></a></h2>\n<ol>\n<li><a href=\"https://research.google/pubs/pub45530/\" target=\"_blank\" rel=\"noopener noreferrer\">Deep Neural Networks for YouTube Recommendations</a> - YouTubeDNN的经典论文，工业界深度召回的必读文献。</li>\n<li><a href=\"https://dl.acm.org/doi/10.1145/3298687.3306678\" target=\"_blank\" rel=\"noopener noreferrer\">Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations</a> - 深入探讨YouTube召回中负采样偏差问题的论文。</li>\n<li><a href=\"https://arxiv.org/abs/1904.08030\" target=\"_blank\" rel=\"noopener noreferrer\">Multi-Interest Network with Dynamic Routing for Recommendation at Tmall</a> - 阿里巴巴提出的MIND模型，开启多兴趣召回的先河。</li>\n<li><a href=\"https://engineering.fb.com/2017/03/29/faiss-a-library-for-efficient-similarity-search/\" target=\"_blank\" rel=\"noopener noreferrer\">Faiss: A library for efficient similarity search</a> - Facebook关于其ANN引擎Faiss的介绍，了解向量检索背后的工程。</li>\n<li><a href=\"https://github.com/datawhalechina/torch-rechub/tree/main/torch_rechub/models/matching\" target=\"_blank\" rel=\"noopener noreferrer\">Torch-RecHub Matching Models</a> - Datawhale开源的torch-rechub项目中，包含了多种经典召回模型的PyTorch实现。</li>\n</ol>\n<div class=\"hint-container tip\">\n<p class=\"hint-container-title\">🎉 章节小结</p>\n<p>深度召回模型以双塔架构为核心，巧妙地将复杂的用户-物品交互解耦为高效的向量检索问题。从DSSM的语义匹配思想，到YouTubeDNN的工业化实践，再到MIND的多兴趣建模，召回模型在&quot;大海捞针&quot;的效率与效果之间找到了完美平衡。它不仅是推荐系统的第一道关卡，更是决定整个系统天花板的关键环节。掌握深度召回，就是掌握了在海量数据中快速定位用户兴趣的核心能力。</p>\n</div>\n<hr>\n<blockquote>\n<p>&quot;The art of being wise is knowing what to overlook.&quot; —— William James<br>\n在召回的世界里，智慧不在于看到所有，而在于知道什么值得被发现。</p>\n</blockquote>\n","env":{"base":"/search-rec-ads-cosmos-explorer/","filePath":"D:/softwore/user/git/work_code/WeBotDoc/docs/zh/3.第三章：推荐算法--比你更懂你的贴心小棉袄/2.深度学习文艺复兴/4.recall_models.md","filePathRelative":"zh/3.第三章：推荐算法--比你更懂你的贴心小棉袄/2.深度学习文艺复兴/4.recall_models.md","frontmatter":{"title":"深度召回：从亿万\"人海\"中找到你的\"知音\"","createTime":"2025/06/12 10:00:00"},"sfcBlocks":{"template":{"type":"template","content":"<template><p>想象一下，你是一个大型视频网站的算法工程师，你的面前是数亿的视频库存和上亿的用户。当一个用户打开APP时，你需要在毫秒之内，从这片视频的“汪洋大海”中，为他挑选出他最可能感兴趣的几百个视频。</p>\n<p>这就是 <strong>召回（Recall）</strong> 阶段的核心挑战。</p>\n<p>为什么我们不能直接用一个精细的排序模型（比如DeepFM）给所有视频都打个分呢？答案是：<strong>算不动！</strong> 对亿万视频逐一打分，耗时将是灾难性的。</p>\n<p>因此，推荐系统被设计为两个核心阶段：</p>\n<ol>\n<li><strong>召回阶段</strong>：快！准！目标是从海量物料库中，快速、批量地筛选出一个较小的候选集（比如几百到几千个），保证用户可能感兴趣的内容基本都在这个池子里。</li>\n<li><strong>排序阶段</strong>：精！细！对召回的候选集使用复杂模型进行精准排序，决定最终的呈现顺序。</li>\n</ol>\n<p>召回，就是这场“大海捞针”艺术的第一步，也是决定整个推荐系统天花板的关键一步。</p>\n<h2 id=\"💡-核心思想-双塔模型-一场高效的-相亲大会\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#💡-核心思想-双塔模型-一场高效的-相亲大会\"><span>💡 核心思想：双塔模型，一场高效的“相亲大会”</span></a></h2>\n<p>为了解决召回的效率问题，<strong>双塔模型（Two-Tower Model）</strong> 应运而生，它已成为深度召回的业界标准范式。</p>\n<p>我们可以把它比作一场大型的“线上相亲大会”：</p>\n<ul>\n<li><strong>物品塔 (Item Tower)</strong>：相当于“女生信息库”。我们提前把所有女生的信息（物品特征）输入物品塔，精心计算并生成每个女生的专属“魅力向量”（Item Embedding）。这项工作可以离线完成，并存入一个可被快速检索的向量数据库（如Faiss）。</li>\n<li><strong>用户塔 (User Tower)</strong>：相当于“男生信息处理器”。当一位男生（用户）来到会场，我们迅速将他的信息（用户特征、历史行为）输入用户塔，实时计算出他的“择偶标准向量”（User Embedding）。</li>\n</ul>\n<p><strong>匹配过程</strong>：拿着这个新鲜出炉的“男生标准向量”，去庞大的“女生魅力向量库”中进行光速检索，找出匹配度最高的Top-K个女生。</p>\n<Mermaid id=\"mermaid-51\" code=\"eJxLL0osyFAIceFSAILi0iQIX+n5st3Pd+1/uqTl+YQ2BQ3/tLSczLxUTSWwKhBIySxKTS7JzM9T8AmCC3pGKz3buv1le//zzpVPJzc+3TVZKVZBV9dOwTMkWgkqtnCKTVKRvp1nSWquQkh+eWqRUixCfwhEdRhMtWtuUmpKSmZe+tMJE4HGAg1EaIbLKbg4KWi4JWYWF+t7+AWHa0INTM1L4ULz1NM5K4Ceejan92nXQqCn8ojxUyjQLVNWPOvY/mL99mcbm6AeCgV5CCwM81BocWoRhodCIR4KdYWphjsayZEgGkyEuoJU1yhBPPtsccPzLYsUNBz9/BSCUxOLkjM0lWqAYQNW6hkGURqSX6DrrfB89+Rn8+YAZYOilZ72r3k6e97TjukvFq4AWsIFAKsfseg=\"></Mermaid><p>这个架构的精髓在于<strong>将用户和物品的复杂交互，解耦为两个独立塔的向量表示</strong>，从而将排序阶段昂贵的在线计算，转化为召回阶段高效的向量相似度搜索。</p>\n<h2 id=\"🏛️-模型演进之路-从奠基到成熟\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#🏛️-模型演进之路-从奠基到成熟\"><span>🏛️ 模型演进之路：从奠基到成熟</span></a></h2>\n<h3 id=\"dssm-双塔模型的-开山鼻祖\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#dssm-双塔模型的-开山鼻祖\"><span>DSSM：双塔模型的“开山鼻祖”</span></a></h3>\n<p>DSSM (Deep Structured Semantic Model) 最初用于解决搜索引擎中查询（Query）和文档（Document）的语义匹配问题，其思想被完美迁移到推荐领域，奠定了双塔模型的基础。</p>\n<ul>\n<li><strong>核心思想</strong>：用两个结构相同（但参数不共享）的DNN，分别将用户特征和物品特征映射到同一个低维语义空间，然后通过计算余弦相似度来衡量匹配程度。</li>\n<li><strong>训练目标</strong>：最大化用户与正样本（点击过的物品）的相似度，同时最小化与负样本的相似度。</li>\n</ul>\n<details class=\"hint-container details\"><summary>💻 DSSM 模型实现 (参考 torch-rechub)</summary>\n<div class=\"language-python line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"python\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code class=\"language-python\"><span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">import</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">import</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">as</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> nn</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">from</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch_rechub</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">models</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">layers </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">import</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> MLP</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">class</span><span style=\"--shiki-light:#2E8F82;--shiki-dark:#5DA994\"> DSSM</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">Module</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">    Deep Structured Semantic Model</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">    </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">    Args:</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        user_features (list): 用户侧特征列表.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        item_features (list): 物品侧特征列表.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        user_mlp_params (dict): 用户塔MLP的参数.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        item_mlp_params (dict): 物品塔MLP的参数.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        temperature (float): 温度系数，用于调整softmax输出.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\"> __init__</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> user_features</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> item_features</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> user_mlp_params</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> item_mlp_params</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> temperature</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1.0</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">        super</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">().</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">__init__</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 用户塔：特征处理层 + MLP</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">user_tower </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Sequential</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">            MLP</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">input_dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">sum</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">f</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">embed_dim </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">for</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> f </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">in</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> user_features</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">),</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\"> **</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">user_mlp_params</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">        )</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 物品塔：特征处理层 + MLP</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">item_tower </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Sequential</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">            MLP</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">input_dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">sum</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">f</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">embed_dim </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">for</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> f </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">in</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> item_features</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">),</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\"> **</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">item_mlp_params</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">        )</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">temperature </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> temperature</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # torch-rechub中特征处理由专门的feature_layer完成，这里为简化展示，假定输入已是拼接好的特征</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\"> user_embedding</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> x</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">        \"\"\"</span><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">获取用户embedding</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">        return</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">user_tower</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">x</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\"> item_embedding</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> x</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">        \"\"\"</span><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">获取物品embedding</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">        return</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">item_tower</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">x</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\"> forward</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> x_user</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> x_item</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        计算用户和物品的匹配分数</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        Args:</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">            x_user (torch.Tensor): 用户侧的输入特征.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">            x_item (torch.Tensor): 物品侧的输入特征.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        Returns:</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">            torch.Tensor: 匹配分数 (logits).</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        user_embedding </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">user_tower</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">x_user</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        item_embedding </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">item_tower</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">x_item</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 计算余弦相似度，并用温度系数调整</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        y </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">mul</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">user_embedding</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> item_embedding</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">).</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">sum</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        y </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> y </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">/</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">temperature</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">        return</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> y</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div></details>\n<h3 id=\"youtubednn-工业界的-集大成者\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#youtubednn-工业界的-集大成者\"><span>YouTubeDNN：工业界的“集大成者”</span></a></h3>\n<p>Google 的 YouTubeDNN 模型是深度召回在工业界成功应用的典范。它极大地丰富了用户塔的内涵，使其能更精准地刻画用户的瞬时兴趣。</p>\n<ul>\n<li><strong>核心思想</strong>：用户的兴趣可以通过他<strong>最近观看过的视频序列</strong>来表达。</li>\n<li><strong>用户塔构建</strong>：\n<ol>\n<li>将用户最近观看过的N个视频的Embedding取出。</li>\n<li>对这些Embedding做<strong>加权平均</strong>，得到一个代表用户历史兴趣的向量。</li>\n<li>再拼接上用户的人口统计学特征、搜索历史等其他特征。</li>\n<li>最后将拼接好的大向量输入一个DNN，生成最终的User Embedding。</li>\n</ol>\n</li>\n<li><strong>创新点</strong>：\n<ul>\n<li><strong>Example Age</strong>：引入“样本年龄”作为特征，帮助模型感知时间的流逝，修正对老旧视频的流行度偏见。</li>\n<li><strong>负采样</strong>：采用基于物品流行度的负采样策略，高效地进行模型训练。</li>\n</ul>\n</li>\n</ul>\n<details class=\"hint-container details\"><summary>💻 YouTubeDNN 模型实现 (参考 torch-rechub)</summary>\n<div class=\"language-python line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"python\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code class=\"language-python\"><span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">import</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">import</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">as</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> nn</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">from</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch_rechub</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">models</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">layers </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">import</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> MLP</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> SequencePoolingLayer</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">class</span><span style=\"--shiki-light:#2E8F82;--shiki-dark:#5DA994\"> YouTubeDNN</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">Module</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">    YouTube Deep Neural Networks for Recommendations</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">    </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">    Args:</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        user_features (list): 用户侧特征列表.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        item_features (list): 物品侧特征列表 (用于负采样).</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        neg_item_feature (str): 负采样物品的特征名.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        user_params (dict): 用户塔MLP的参数.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        temperature (float): 温度系数.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\"> __init__</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> user_features</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> item_features</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> neg_item_feature</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> user_params</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> temperature</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1.0</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">        super</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">().</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">__init__</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">user_features </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> user_features</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">item_features </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> item_features</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">neg_item_feature </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> neg_item_feature</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">temperature </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> temperature</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 物品的Embedding层是共享的</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 在torch-rechub中，这通常通过共享embedding_layer的名称实现</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 此处为简化，假定有一个共享的embedding_layer</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">embedding_layer </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">get_shared_embedding_layer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 用户塔</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 序列特征的池化层</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">seq_pooling_layer </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> SequencePoolingLayer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">pooling_type</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"</span><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">mean</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 用户塔的MLP</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">user_tower </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> MLP</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">            input_dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">get_user_input_dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(),</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">            **</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">user_params</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"</span><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">mlp_params</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">]</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">        )</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\"> forward</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> x</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        此模型在torch-rechub中通常用于训练，直接输出loss</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        这里为了展示，我们分解其核心逻辑</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 1. 获取所有物品的Embedding</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 在实际训练中，通过负采样得到一个batch的物品</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        item_embs </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">embedding_layer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">x</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">neg_item_feature</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">])</span><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"> # (batch_size, n_neg+1, emb_dim)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 2. 构建用户塔输入</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # a. 聚合用户历史行为序列</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        watch_history_emb </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">seq_pooling_layer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">embedding_layer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">x</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"</span><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">watch_history</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">]))</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # b. 获取其他用户特征 (如年龄、性别)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        user_other_features_emb </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">get_user_other_features</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">x</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # c. 拼接所有用户侧特征</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        user_tower_input </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">cat</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">([</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">watch_history_emb</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> user_other_features_emb</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">],</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 3. 计算用户Embedding</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        user_embedding </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">user_tower</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">user_tower_input</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"> # (batch_size, emb_dim)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 4. 计算用户与所有采样物品的相似度 (内积)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # user_embedding需要扩展维度以进行批次矩阵乘法</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        logits </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">bmm</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">item_embs</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> user_embedding</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">unsqueeze</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">-</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)).</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">squeeze</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">-</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"> # (batch_size, n_neg+1)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 训练时，这里的logits会直接送入交叉熵损失函数</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">        return</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> logits</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div></details>\n<h3 id=\"mind-洞悉用户的-多面人生\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#mind-洞悉用户的-多面人生\"><span>MIND：洞悉用户的“多面人生”</span></a></h3>\n<p>一个用户可能既喜欢看烧菜视频，又喜欢看篮球集锦。用单一的向量来概括他的全部兴趣，显然是有局限的。MIND (Multi-Interest Network with Dynamic Routing) 模型应运而生。</p>\n<ul>\n<li><strong>核心思想</strong>：为每个用户生成<strong>多个兴趣向量</strong>，每个向量代表用户的一个特定兴趣簇。</li>\n<li><strong>动态路由 (Dynamic Routing)</strong>：通过<strong>胶囊网络 (Capsule Network)</strong> 的思想，将用户的历史行为Embedding进行动态聚类，自适应地生成K个兴趣中心（K个兴趣向量）。</li>\n<li><strong>匹配过程</strong>：当一个候选物品（如一个篮球视频）过来时，模型会智能地计算该物品与用户的哪个兴趣向量（篮球兴趣）最匹配，并用这个最匹配的兴趣向量来计算最终的相似度。</li>\n</ul>\n<p>这使得召回模型从“一对一”的匹配，升级为更灵活、更精准的“一对多”匹配。</p>\n<h2 id=\"⚙️-工业部署-从模型到服务\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#⚙️-工业部署-从模型到服务\"><span>⚙️ 工业部署：从模型到服务</span></a></h2>\n<p>一个深度召回模型要真正上线发挥作用，还需要一整套强大的工程体系支撑。</p>\n<ol>\n<li>\n<p><strong>离线流程 (Offline)</strong></p>\n<ul>\n<li><strong>模型训练</strong>：使用海量用户行为日志，训练双塔模型。</li>\n<li><strong>向量产出</strong>：训练完成后，将<strong>物品塔</strong>单独拿出来，对全量物品进行推理，产出所有物品的Embedding向量。</li>\n<li><strong>索引构建</strong>：将全量物品向量灌入<strong>ANN检索引擎</strong>（如Faiss、HNSW），构建高效的向量索引文件，并推送到线上。</li>\n</ul>\n</li>\n<li>\n<p><strong>在线流程 (Online)</strong></p>\n<ul>\n<li><strong>实时特征</strong>：当用户请求到达时，实时获取用户的基本特征和短期行为序列。</li>\n<li><strong>实时推理</strong>：将特征输入到线上的<strong>用户塔</strong>模型中，实时计算出用户当前的Embedding向量。</li>\n<li><strong>实时检索</strong>：用新鲜出炉的用户Embedding，去ANN引擎中进行检索，拉取最相似的Top-K个物品ID。</li>\n<li><strong>物料补充</strong>：将检索到的物品ID，去缓存（如Redis）中补全物品的标题、封面图等信息，返回给下游的排序服务。</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"📖-延伸阅读\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#📖-延伸阅读\"><span>📖 <strong>延伸阅读</strong></span></a></h2>\n<ol>\n<li><a href=\"https://research.google/pubs/pub45530/\" target=\"_blank\" rel=\"noopener noreferrer\">Deep Neural Networks for YouTube Recommendations</a> - YouTubeDNN的经典论文，工业界深度召回的必读文献。</li>\n<li><a href=\"https://dl.acm.org/doi/10.1145/3298687.3306678\" target=\"_blank\" rel=\"noopener noreferrer\">Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations</a> - 深入探讨YouTube召回中负采样偏差问题的论文。</li>\n<li><a href=\"https://arxiv.org/abs/1904.08030\" target=\"_blank\" rel=\"noopener noreferrer\">Multi-Interest Network with Dynamic Routing for Recommendation at Tmall</a> - 阿里巴巴提出的MIND模型，开启多兴趣召回的先河。</li>\n<li><a href=\"https://engineering.fb.com/2017/03/29/faiss-a-library-for-efficient-similarity-search/\" target=\"_blank\" rel=\"noopener noreferrer\">Faiss: A library for efficient similarity search</a> - Facebook关于其ANN引擎Faiss的介绍，了解向量检索背后的工程。</li>\n<li><a href=\"https://github.com/datawhalechina/torch-rechub/tree/main/torch_rechub/models/matching\" target=\"_blank\" rel=\"noopener noreferrer\">Torch-RecHub Matching Models</a> - Datawhale开源的torch-rechub项目中，包含了多种经典召回模型的PyTorch实现。</li>\n</ol>\n<div class=\"hint-container tip\">\n<p class=\"hint-container-title\">🎉 章节小结</p>\n<p>深度召回模型以双塔架构为核心，巧妙地将复杂的用户-物品交互解耦为高效的向量检索问题。从DSSM的语义匹配思想，到YouTubeDNN的工业化实践，再到MIND的多兴趣建模，召回模型在&quot;大海捞针&quot;的效率与效果之间找到了完美平衡。它不仅是推荐系统的第一道关卡，更是决定整个系统天花板的关键环节。掌握深度召回，就是掌握了在海量数据中快速定位用户兴趣的核心能力。</p>\n</div>\n<hr>\n<blockquote>\n<p>&quot;The art of being wise is knowing what to overlook.&quot; —— William James<br>\n在召回的世界里，智慧不在于看到所有，而在于知道什么值得被发现。</p>\n</blockquote>\n</template>","contentStripped":"<p>想象一下，你是一个大型视频网站的算法工程师，你的面前是数亿的视频库存和上亿的用户。当一个用户打开APP时，你需要在毫秒之内，从这片视频的“汪洋大海”中，为他挑选出他最可能感兴趣的几百个视频。</p>\n<p>这就是 <strong>召回（Recall）</strong> 阶段的核心挑战。</p>\n<p>为什么我们不能直接用一个精细的排序模型（比如DeepFM）给所有视频都打个分呢？答案是：<strong>算不动！</strong> 对亿万视频逐一打分，耗时将是灾难性的。</p>\n<p>因此，推荐系统被设计为两个核心阶段：</p>\n<ol>\n<li><strong>召回阶段</strong>：快！准！目标是从海量物料库中，快速、批量地筛选出一个较小的候选集（比如几百到几千个），保证用户可能感兴趣的内容基本都在这个池子里。</li>\n<li><strong>排序阶段</strong>：精！细！对召回的候选集使用复杂模型进行精准排序，决定最终的呈现顺序。</li>\n</ol>\n<p>召回，就是这场“大海捞针”艺术的第一步，也是决定整个推荐系统天花板的关键一步。</p>\n<h2 id=\"💡-核心思想-双塔模型-一场高效的-相亲大会\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#💡-核心思想-双塔模型-一场高效的-相亲大会\"><span>💡 核心思想：双塔模型，一场高效的“相亲大会”</span></a></h2>\n<p>为了解决召回的效率问题，<strong>双塔模型（Two-Tower Model）</strong> 应运而生，它已成为深度召回的业界标准范式。</p>\n<p>我们可以把它比作一场大型的“线上相亲大会”：</p>\n<ul>\n<li><strong>物品塔 (Item Tower)</strong>：相当于“女生信息库”。我们提前把所有女生的信息（物品特征）输入物品塔，精心计算并生成每个女生的专属“魅力向量”（Item Embedding）。这项工作可以离线完成，并存入一个可被快速检索的向量数据库（如Faiss）。</li>\n<li><strong>用户塔 (User Tower)</strong>：相当于“男生信息处理器”。当一位男生（用户）来到会场，我们迅速将他的信息（用户特征、历史行为）输入用户塔，实时计算出他的“择偶标准向量”（User Embedding）。</li>\n</ul>\n<p><strong>匹配过程</strong>：拿着这个新鲜出炉的“男生标准向量”，去庞大的“女生魅力向量库”中进行光速检索，找出匹配度最高的Top-K个女生。</p>\n<Mermaid id=\"mermaid-51\" code=\"eJxLL0osyFAIceFSAILi0iQIX+n5st3Pd+1/uqTl+YQ2BQ3/tLSczLxUTSWwKhBIySxKTS7JzM9T8AmCC3pGKz3buv1le//zzpVPJzc+3TVZKVZBV9dOwTMkWgkqtnCKTVKRvp1nSWquQkh+eWqRUixCfwhEdRhMtWtuUmpKSmZe+tMJE4HGAg1EaIbLKbg4KWi4JWYWF+t7+AWHa0INTM1L4ULz1NM5K4Ceejan92nXQqCn8ojxUyjQLVNWPOvY/mL99mcbm6AeCgV5CCwM81BocWoRhodCIR4KdYWphjsayZEgGkyEuoJU1yhBPPtsccPzLYsUNBz9/BSCUxOLkjM0lWqAYQNW6hkGURqSX6DrrfB89+Rn8+YAZYOilZ72r3k6e97TjukvFq4AWsIFAKsfseg=\"></Mermaid><p>这个架构的精髓在于<strong>将用户和物品的复杂交互，解耦为两个独立塔的向量表示</strong>，从而将排序阶段昂贵的在线计算，转化为召回阶段高效的向量相似度搜索。</p>\n<h2 id=\"🏛️-模型演进之路-从奠基到成熟\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#🏛️-模型演进之路-从奠基到成熟\"><span>🏛️ 模型演进之路：从奠基到成熟</span></a></h2>\n<h3 id=\"dssm-双塔模型的-开山鼻祖\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#dssm-双塔模型的-开山鼻祖\"><span>DSSM：双塔模型的“开山鼻祖”</span></a></h3>\n<p>DSSM (Deep Structured Semantic Model) 最初用于解决搜索引擎中查询（Query）和文档（Document）的语义匹配问题，其思想被完美迁移到推荐领域，奠定了双塔模型的基础。</p>\n<ul>\n<li><strong>核心思想</strong>：用两个结构相同（但参数不共享）的DNN，分别将用户特征和物品特征映射到同一个低维语义空间，然后通过计算余弦相似度来衡量匹配程度。</li>\n<li><strong>训练目标</strong>：最大化用户与正样本（点击过的物品）的相似度，同时最小化与负样本的相似度。</li>\n</ul>\n<details class=\"hint-container details\"><summary>💻 DSSM 模型实现 (参考 torch-rechub)</summary>\n<div class=\"language-python line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"python\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code class=\"language-python\"><span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">import</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">import</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">as</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> nn</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">from</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch_rechub</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">models</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">layers </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">import</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> MLP</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">class</span><span style=\"--shiki-light:#2E8F82;--shiki-dark:#5DA994\"> DSSM</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">Module</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">    Deep Structured Semantic Model</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">    </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">    Args:</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        user_features (list): 用户侧特征列表.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        item_features (list): 物品侧特征列表.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        user_mlp_params (dict): 用户塔MLP的参数.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        item_mlp_params (dict): 物品塔MLP的参数.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        temperature (float): 温度系数，用于调整softmax输出.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\"> __init__</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> user_features</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> item_features</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> user_mlp_params</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> item_mlp_params</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> temperature</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1.0</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">        super</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">().</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">__init__</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 用户塔：特征处理层 + MLP</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">user_tower </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Sequential</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">            MLP</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">input_dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">sum</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">f</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">embed_dim </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">for</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> f </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">in</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> user_features</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">),</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\"> **</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">user_mlp_params</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">        )</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 物品塔：特征处理层 + MLP</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">item_tower </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Sequential</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">            MLP</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">input_dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">sum</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">f</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">embed_dim </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">for</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> f </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">in</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> item_features</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">),</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\"> **</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">item_mlp_params</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">        )</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">temperature </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> temperature</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # torch-rechub中特征处理由专门的feature_layer完成，这里为简化展示，假定输入已是拼接好的特征</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\"> user_embedding</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> x</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">        \"\"\"</span><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">获取用户embedding</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">        return</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">user_tower</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">x</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\"> item_embedding</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> x</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">        \"\"\"</span><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">获取物品embedding</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">        return</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">item_tower</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">x</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\"> forward</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> x_user</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> x_item</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        计算用户和物品的匹配分数</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        Args:</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">            x_user (torch.Tensor): 用户侧的输入特征.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">            x_item (torch.Tensor): 物品侧的输入特征.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        Returns:</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">            torch.Tensor: 匹配分数 (logits).</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        user_embedding </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">user_tower</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">x_user</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        item_embedding </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">item_tower</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">x_item</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 计算余弦相似度，并用温度系数调整</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        y </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">mul</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">user_embedding</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> item_embedding</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">).</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">sum</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        y </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> y </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">/</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">temperature</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">        return</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> y</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div></details>\n<h3 id=\"youtubednn-工业界的-集大成者\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#youtubednn-工业界的-集大成者\"><span>YouTubeDNN：工业界的“集大成者”</span></a></h3>\n<p>Google 的 YouTubeDNN 模型是深度召回在工业界成功应用的典范。它极大地丰富了用户塔的内涵，使其能更精准地刻画用户的瞬时兴趣。</p>\n<ul>\n<li><strong>核心思想</strong>：用户的兴趣可以通过他<strong>最近观看过的视频序列</strong>来表达。</li>\n<li><strong>用户塔构建</strong>：\n<ol>\n<li>将用户最近观看过的N个视频的Embedding取出。</li>\n<li>对这些Embedding做<strong>加权平均</strong>，得到一个代表用户历史兴趣的向量。</li>\n<li>再拼接上用户的人口统计学特征、搜索历史等其他特征。</li>\n<li>最后将拼接好的大向量输入一个DNN，生成最终的User Embedding。</li>\n</ol>\n</li>\n<li><strong>创新点</strong>：\n<ul>\n<li><strong>Example Age</strong>：引入“样本年龄”作为特征，帮助模型感知时间的流逝，修正对老旧视频的流行度偏见。</li>\n<li><strong>负采样</strong>：采用基于物品流行度的负采样策略，高效地进行模型训练。</li>\n</ul>\n</li>\n</ul>\n<details class=\"hint-container details\"><summary>💻 YouTubeDNN 模型实现 (参考 torch-rechub)</summary>\n<div class=\"language-python line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"python\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code class=\"language-python\"><span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">import</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">import</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">as</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> nn</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">from</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch_rechub</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">models</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">layers </span><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">import</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> MLP</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> SequencePoolingLayer</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">class</span><span style=\"--shiki-light:#2E8F82;--shiki-dark:#5DA994\"> YouTubeDNN</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">Module</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">    YouTube Deep Neural Networks for Recommendations</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">    </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">    Args:</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        user_features (list): 用户侧特征列表.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        item_features (list): 物品侧特征列表 (用于负采样).</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        neg_item_feature (str): 负采样物品的特征名.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        user_params (dict): 用户塔MLP的参数.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        temperature (float): 温度系数.</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">    \"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\"> __init__</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> user_features</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> item_features</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> neg_item_feature</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> user_params</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> temperature</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1.0</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">        super</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">().</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">__init__</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">user_features </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> user_features</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">item_features </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> item_features</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">neg_item_feature </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> neg_item_feature</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">temperature </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> temperature</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 物品的Embedding层是共享的</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 在torch-rechub中，这通常通过共享embedding_layer的名称实现</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 此处为简化，假定有一个共享的embedding_layer</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">embedding_layer </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">get_shared_embedding_layer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 用户塔</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 序列特征的池化层</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">seq_pooling_layer </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> SequencePoolingLayer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">pooling_type</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"</span><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">mean</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 用户塔的MLP</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">user_tower </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> MLP</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">            input_dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">get_user_input_dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(),</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">            **</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">user_params</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"</span><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">mlp_params</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">]</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">        )</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\"> forward</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> x</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        此模型在torch-rechub中通常用于训练，直接输出loss</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">        这里为了展示，我们分解其核心逻辑</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">        \"\"\"</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 1. 获取所有物品的Embedding</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 在实际训练中，通过负采样得到一个batch的物品</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        item_embs </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">embedding_layer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">x</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">neg_item_feature</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">])</span><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"> # (batch_size, n_neg+1, emb_dim)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 2. 构建用户塔输入</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # a. 聚合用户历史行为序列</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        watch_history_emb </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">seq_pooling_layer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">embedding_layer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">x</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"</span><span style=\"--shiki-light:#B56959;--shiki-dark:#C98A7D\">watch_history</span><span style=\"--shiki-light:#B5695977;--shiki-dark:#C98A7D77\">\"</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">]))</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # b. 获取其他用户特征 (如年龄、性别)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        user_other_features_emb </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">get_user_other_features</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">x</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # c. 拼接所有用户侧特征</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        user_tower_input </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">cat</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">([</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">watch_history_emb</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> user_other_features_emb</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">],</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> dim</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 3. 计算用户Embedding</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        user_embedding </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">user_tower</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">user_tower_input</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"> # (batch_size, emb_dim)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 4. 计算用户与所有采样物品的相似度 (内积)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # user_embedding需要扩展维度以进行批次矩阵乘法</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        logits </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">bmm</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">item_embs</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> user_embedding</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">unsqueeze</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">-</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)).</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">squeeze</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">-</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"> # (batch_size, n_neg+1)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 训练时，这里的logits会直接送入交叉熵损失函数</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">        return</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> logits</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div></details>\n<h3 id=\"mind-洞悉用户的-多面人生\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#mind-洞悉用户的-多面人生\"><span>MIND：洞悉用户的“多面人生”</span></a></h3>\n<p>一个用户可能既喜欢看烧菜视频，又喜欢看篮球集锦。用单一的向量来概括他的全部兴趣，显然是有局限的。MIND (Multi-Interest Network with Dynamic Routing) 模型应运而生。</p>\n<ul>\n<li><strong>核心思想</strong>：为每个用户生成<strong>多个兴趣向量</strong>，每个向量代表用户的一个特定兴趣簇。</li>\n<li><strong>动态路由 (Dynamic Routing)</strong>：通过<strong>胶囊网络 (Capsule Network)</strong> 的思想，将用户的历史行为Embedding进行动态聚类，自适应地生成K个兴趣中心（K个兴趣向量）。</li>\n<li><strong>匹配过程</strong>：当一个候选物品（如一个篮球视频）过来时，模型会智能地计算该物品与用户的哪个兴趣向量（篮球兴趣）最匹配，并用这个最匹配的兴趣向量来计算最终的相似度。</li>\n</ul>\n<p>这使得召回模型从“一对一”的匹配，升级为更灵活、更精准的“一对多”匹配。</p>\n<h2 id=\"⚙️-工业部署-从模型到服务\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#⚙️-工业部署-从模型到服务\"><span>⚙️ 工业部署：从模型到服务</span></a></h2>\n<p>一个深度召回模型要真正上线发挥作用，还需要一整套强大的工程体系支撑。</p>\n<ol>\n<li>\n<p><strong>离线流程 (Offline)</strong></p>\n<ul>\n<li><strong>模型训练</strong>：使用海量用户行为日志，训练双塔模型。</li>\n<li><strong>向量产出</strong>：训练完成后，将<strong>物品塔</strong>单独拿出来，对全量物品进行推理，产出所有物品的Embedding向量。</li>\n<li><strong>索引构建</strong>：将全量物品向量灌入<strong>ANN检索引擎</strong>（如Faiss、HNSW），构建高效的向量索引文件，并推送到线上。</li>\n</ul>\n</li>\n<li>\n<p><strong>在线流程 (Online)</strong></p>\n<ul>\n<li><strong>实时特征</strong>：当用户请求到达时，实时获取用户的基本特征和短期行为序列。</li>\n<li><strong>实时推理</strong>：将特征输入到线上的<strong>用户塔</strong>模型中，实时计算出用户当前的Embedding向量。</li>\n<li><strong>实时检索</strong>：用新鲜出炉的用户Embedding，去ANN引擎中进行检索，拉取最相似的Top-K个物品ID。</li>\n<li><strong>物料补充</strong>：将检索到的物品ID，去缓存（如Redis）中补全物品的标题、封面图等信息，返回给下游的排序服务。</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"📖-延伸阅读\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#📖-延伸阅读\"><span>📖 <strong>延伸阅读</strong></span></a></h2>\n<ol>\n<li><a href=\"https://research.google/pubs/pub45530/\" target=\"_blank\" rel=\"noopener noreferrer\">Deep Neural Networks for YouTube Recommendations</a> - YouTubeDNN的经典论文，工业界深度召回的必读文献。</li>\n<li><a href=\"https://dl.acm.org/doi/10.1145/3298687.3306678\" target=\"_blank\" rel=\"noopener noreferrer\">Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations</a> - 深入探讨YouTube召回中负采样偏差问题的论文。</li>\n<li><a href=\"https://arxiv.org/abs/1904.08030\" target=\"_blank\" rel=\"noopener noreferrer\">Multi-Interest Network with Dynamic Routing for Recommendation at Tmall</a> - 阿里巴巴提出的MIND模型，开启多兴趣召回的先河。</li>\n<li><a href=\"https://engineering.fb.com/2017/03/29/faiss-a-library-for-efficient-similarity-search/\" target=\"_blank\" rel=\"noopener noreferrer\">Faiss: A library for efficient similarity search</a> - Facebook关于其ANN引擎Faiss的介绍，了解向量检索背后的工程。</li>\n<li><a href=\"https://github.com/datawhalechina/torch-rechub/tree/main/torch_rechub/models/matching\" target=\"_blank\" rel=\"noopener noreferrer\">Torch-RecHub Matching Models</a> - Datawhale开源的torch-rechub项目中，包含了多种经典召回模型的PyTorch实现。</li>\n</ol>\n<div class=\"hint-container tip\">\n<p class=\"hint-container-title\">🎉 章节小结</p>\n<p>深度召回模型以双塔架构为核心，巧妙地将复杂的用户-物品交互解耦为高效的向量检索问题。从DSSM的语义匹配思想，到YouTubeDNN的工业化实践，再到MIND的多兴趣建模，召回模型在&quot;大海捞针&quot;的效率与效果之间找到了完美平衡。它不仅是推荐系统的第一道关卡，更是决定整个系统天花板的关键环节。掌握深度召回，就是掌握了在海量数据中快速定位用户兴趣的核心能力。</p>\n</div>\n<hr>\n<blockquote>\n<p>&quot;The art of being wise is knowing what to overlook.&quot; —— William James<br>\n在召回的世界里，智慧不在于看到所有，而在于知道什么值得被发现。</p>\n</blockquote>\n","tagOpen":"<template>","tagClose":"</template>"},"script":null,"scriptSetup":null,"scripts":[],"styles":[],"customBlocks":[]},"content":"想象一下，你是一个大型视频网站的算法工程师，你的面前是数亿的视频库存和上亿的用户。当一个用户打开APP时，你需要在毫秒之内，从这片视频的“汪洋大海”中，为他挑选出他最可能感兴趣的几百个视频。\n\n这就是 **召回（Recall）** 阶段的核心挑战。\n\n为什么我们不能直接用一个精细的排序模型（比如DeepFM）给所有视频都打个分呢？答案是：**算不动！** 对亿万视频逐一打分，耗时将是灾难性的。\n\n因此，推荐系统被设计为两个核心阶段：\n1.  **召回阶段**：快！准！目标是从海量物料库中，快速、批量地筛选出一个较小的候选集（比如几百到几千个），保证用户可能感兴趣的内容基本都在这个池子里。\n2.  **排序阶段**：精！细！对召回的候选集使用复杂模型进行精准排序，决定最终的呈现顺序。\n\n召回，就是这场“大海捞针”艺术的第一步，也是决定整个推荐系统天花板的关键一步。\n\n## 💡 核心思想：双塔模型，一场高效的“相亲大会”\n\n为了解决召回的效率问题，**双塔模型（Two-Tower Model）** 应运而生，它已成为深度召回的业界标准范式。\n\n我们可以把它比作一场大型的“线上相亲大会”：\n- **物品塔 (Item Tower)**：相当于“女生信息库”。我们提前把所有女生的信息（物品特征）输入物品塔，精心计算并生成每个女生的专属“魅力向量”（Item Embedding）。这项工作可以离线完成，并存入一个可被快速检索的向量数据库（如Faiss）。\n- **用户塔 (User Tower)**：相当于“男生信息处理器”。当一位男生（用户）来到会场，我们迅速将他的信息（用户特征、历史行为）输入用户塔，实时计算出他的“择偶标准向量”（User Embedding）。\n\n**匹配过程**：拿着这个新鲜出炉的“男生标准向量”，去庞大的“女生魅力向量库”中进行光速检索，找出匹配度最高的Top-K个女生。\n\n```mermaid\ngraph TD\n    subgraph \"离线处理 (Offline)\"\n        direction LR\n        I[\"海量物品库\"] --> IT[\"物品塔<br/>Item Tower\"]\n        IT --> IV[\"物品Embedding向量库<br/>Item Embedding DB (Faiss/HNSW)\"]\n    end\n\n    subgraph \"在线服务 (Online)\"\n        direction LR\n        U[\"用户请求\"] --> UT[\"用户塔<br/>User Tower\"]\n        UT --> UE[\"用户Embedding\"]\n    end\n    \n    UE -->|\"向量检索 (ANN Search)\"| IV\n    IV -->|\"Top-K 结果\"| R[\"召回列表\"]\n\n```\n\n这个架构的精髓在于**将用户和物品的复杂交互，解耦为两个独立塔的向量表示**，从而将排序阶段昂贵的在线计算，转化为召回阶段高效的向量相似度搜索。\n\n## 🏛️ 模型演进之路：从奠基到成熟\n\n### DSSM：双塔模型的“开山鼻祖”\n\nDSSM (Deep Structured Semantic Model) 最初用于解决搜索引擎中查询（Query）和文档（Document）的语义匹配问题，其思想被完美迁移到推荐领域，奠定了双塔模型的基础。\n\n- **核心思想**：用两个结构相同（但参数不共享）的DNN，分别将用户特征和物品特征映射到同一个低维语义空间，然后通过计算余弦相似度来衡量匹配程度。\n- **训练目标**：最大化用户与正样本（点击过的物品）的相似度，同时最小化与负样本的相似度。\n\n::: details 💻 DSSM 模型实现 (参考 torch-rechub)\n```python\nimport torch\nimport torch.nn as nn\nfrom torch_rechub.models.layers import MLP\n\nclass DSSM(nn.Module):\n    \"\"\"\n    Deep Structured Semantic Model\n    \n    Args:\n        user_features (list): 用户侧特征列表.\n        item_features (list): 物品侧特征列表.\n        user_mlp_params (dict): 用户塔MLP的参数.\n        item_mlp_params (dict): 物品塔MLP的参数.\n        temperature (float): 温度系数，用于调整softmax输出.\n    \"\"\"\n    def __init__(self, user_features, item_features, user_mlp_params, item_mlp_params, temperature=1.0):\n        super().__init__()\n        # 用户塔：特征处理层 + MLP\n        self.user_tower = nn.Sequential(\n            MLP(input_dim=sum(f.embed_dim for f in user_features), **user_mlp_params)\n        )\n        # 物品塔：特征处理层 + MLP\n        self.item_tower = nn.Sequential(\n            MLP(input_dim=sum(f.embed_dim for f in item_features), **item_mlp_params)\n        )\n        self.temperature = temperature\n        \n        # torch-rechub中特征处理由专门的feature_layer完成，这里为简化展示，假定输入已是拼接好的特征\n\n    def user_embedding(self, x):\n        \"\"\"获取用户embedding\"\"\"\n        return self.user_tower(x)\n        \n    def item_embedding(self, x):\n        \"\"\"获取物品embedding\"\"\"\n        return self.item_tower(x)\n\n    def forward(self, x_user, x_item):\n        \"\"\"\n        计算用户和物品的匹配分数\n        Args:\n            x_user (torch.Tensor): 用户侧的输入特征.\n            x_item (torch.Tensor): 物品侧的输入特征.\n        Returns:\n            torch.Tensor: 匹配分数 (logits).\n        \"\"\"\n        user_embedding = self.user_tower(x_user)\n        item_embedding = self.item_tower(x_item)\n        \n        # 计算余弦相似度，并用温度系数调整\n        y = torch.mul(user_embedding, item_embedding).sum(dim=1)\n        y = y / self.temperature\n        return y\n```\n:::\n\n### YouTubeDNN：工业界的“集大成者”\n\nGoogle 的 YouTubeDNN 模型是深度召回在工业界成功应用的典范。它极大地丰富了用户塔的内涵，使其能更精准地刻画用户的瞬时兴趣。\n\n- **核心思想**：用户的兴趣可以通过他**最近观看过的视频序列**来表达。\n- **用户塔构建**：\n    1.  将用户最近观看过的N个视频的Embedding取出。\n    2.  对这些Embedding做**加权平均**，得到一个代表用户历史兴趣的向量。\n    3.  再拼接上用户的人口统计学特征、搜索历史等其他特征。\n    4.  最后将拼接好的大向量输入一个DNN，生成最终的User Embedding。\n- **创新点**：\n    - **Example Age**：引入“样本年龄”作为特征，帮助模型感知时间的流逝，修正对老旧视频的流行度偏见。\n    - **负采样**：采用基于物品流行度的负采样策略，高效地进行模型训练。\n\n::: details 💻 YouTubeDNN 模型实现 (参考 torch-rechub)\n```python\nimport torch\nimport torch.nn as nn\nfrom torch_rechub.models.layers import MLP, SequencePoolingLayer\n\nclass YouTubeDNN(nn.Module):\n    \"\"\"\n    YouTube Deep Neural Networks for Recommendations\n    \n    Args:\n        user_features (list): 用户侧特征列表.\n        item_features (list): 物品侧特征列表 (用于负采样).\n        neg_item_feature (str): 负采样物品的特征名.\n        user_params (dict): 用户塔MLP的参数.\n        temperature (float): 温度系数.\n    \"\"\"\n    def __init__(self, user_features, item_features, neg_item_feature, user_params, temperature=1.0):\n        super().__init__()\n        self.user_features = user_features\n        self.item_features = item_features\n        self.neg_item_feature = neg_item_feature\n        self.temperature = temperature\n        \n        # 物品的Embedding层是共享的\n        # 在torch-rechub中，这通常通过共享embedding_layer的名称实现\n        # 此处为简化，假定有一个共享的embedding_layer\n        self.embedding_layer = self.get_shared_embedding_layer()\n        \n        # 用户塔\n        # 序列特征的池化层\n        self.seq_pooling_layer = SequencePoolingLayer(pooling_type=\"mean\") \n        # 用户塔的MLP\n        self.user_tower = MLP(\n            input_dim=self.get_user_input_dim(), \n            **user_params[\"mlp_params\"]\n        )\n        \n    def forward(self, x):\n        \"\"\"\n        此模型在torch-rechub中通常用于训练，直接输出loss\n        这里为了展示，我们分解其核心逻辑\n        \"\"\"\n        # 1. 获取所有物品的Embedding\n        # 在实际训练中，通过负采样得到一个batch的物品\n        item_embs = self.embedding_layer(x[self.neg_item_feature]) # (batch_size, n_neg+1, emb_dim)\n        \n        # 2. 构建用户塔输入\n        # a. 聚合用户历史行为序列\n        watch_history_emb = self.seq_pooling_layer(self.embedding_layer(x[\"watch_history\"]))\n        # b. 获取其他用户特征 (如年龄、性别)\n        user_other_features_emb = self.get_user_other_features(x)\n        # c. 拼接所有用户侧特征\n        user_tower_input = torch.cat([watch_history_emb, user_other_features_emb], dim=1)\n        \n        # 3. 计算用户Embedding\n        user_embedding = self.user_tower(user_tower_input) # (batch_size, emb_dim)\n        \n        # 4. 计算用户与所有采样物品的相似度 (内积)\n        # user_embedding需要扩展维度以进行批次矩阵乘法\n        logits = torch.bmm(item_embs, user_embedding.unsqueeze(-1)).squeeze(-1) # (batch_size, n_neg+1)\n        \n        # 训练时，这里的logits会直接送入交叉熵损失函数\n        return logits\n```\n:::\n\n### MIND：洞悉用户的“多面人生”\n\n一个用户可能既喜欢看烧菜视频，又喜欢看篮球集锦。用单一的向量来概括他的全部兴趣，显然是有局限的。MIND (Multi-Interest Network with Dynamic Routing) 模型应运而生。\n\n- **核心思想**：为每个用户生成**多个兴趣向量**，每个向量代表用户的一个特定兴趣簇。\n- **动态路由 (Dynamic Routing)**：通过**胶囊网络 (Capsule Network)** 的思想，将用户的历史行为Embedding进行动态聚类，自适应地生成K个兴趣中心（K个兴趣向量）。\n- **匹配过程**：当一个候选物品（如一个篮球视频）过来时，模型会智能地计算该物品与用户的哪个兴趣向量（篮球兴趣）最匹配，并用这个最匹配的兴趣向量来计算最终的相似度。\n\n这使得召回模型从“一对一”的匹配，升级为更灵活、更精准的“一对多”匹配。\n\n## ⚙️ 工业部署：从模型到服务\n\n一个深度召回模型要真正上线发挥作用，还需要一整套强大的工程体系支撑。\n\n1.  **离线流程 (Offline)**\n    - **模型训练**：使用海量用户行为日志，训练双塔模型。\n    - **向量产出**：训练完成后，将**物品塔**单独拿出来，对全量物品进行推理，产出所有物品的Embedding向量。\n    - **索引构建**：将全量物品向量灌入**ANN检索引擎**（如Faiss、HNSW），构建高效的向量索引文件，并推送到线上。\n\n2.  **在线流程 (Online)**\n    - **实时特征**：当用户请求到达时，实时获取用户的基本特征和短期行为序列。\n    - **实时推理**：将特征输入到线上的**用户塔**模型中，实时计算出用户当前的Embedding向量。\n    - **实时检索**：用新鲜出炉的用户Embedding，去ANN引擎中进行检索，拉取最相似的Top-K个物品ID。\n    - **物料补充**：将检索到的物品ID，去缓存（如Redis）中补全物品的标题、封面图等信息，返回给下游的排序服务。\n\n\n## 📖 **延伸阅读**\n1. [Deep Neural Networks for YouTube Recommendations](https://research.google/pubs/pub45530/) - YouTubeDNN的经典论文，工业界深度召回的必读文献。\n2. [Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations](https://dl.acm.org/doi/10.1145/3298687.3306678) - 深入探讨YouTube召回中负采样偏差问题的论文。\n3. [Multi-Interest Network with Dynamic Routing for Recommendation at Tmall](https://arxiv.org/abs/1904.08030) - 阿里巴巴提出的MIND模型，开启多兴趣召回的先河。\n4. [Faiss: A library for efficient similarity search](https://engineering.fb.com/2017/03/29/faiss-a-library-for-efficient-similarity-search/) - Facebook关于其ANN引擎Faiss的介绍，了解向量检索背后的工程。\n5. [Torch-RecHub Matching Models](https://github.com/datawhalechina/torch-rechub/tree/main/torch_rechub/models/matching) - Datawhale开源的torch-rechub项目中，包含了多种经典召回模型的PyTorch实现。\n\n::: tip 🎉 章节小结\n深度召回模型以双塔架构为核心，巧妙地将复杂的用户-物品交互解耦为高效的向量检索问题。从DSSM的语义匹配思想，到YouTubeDNN的工业化实践，再到MIND的多兴趣建模，召回模型在\"大海捞针\"的效率与效果之间找到了完美平衡。它不仅是推荐系统的第一道关卡，更是决定整个系统天花板的关键环节。掌握深度召回，就是掌握了在海量数据中快速定位用户兴趣的核心能力。\n:::\n\n---\n\n> \"The art of being wise is knowing what to overlook.\" —— William James  \n> 在召回的世界里，智慧不在于看到所有，而在于知道什么值得被发现。","excerpt":"","includedFiles":[],"tasklistId":0,"title":"","headers":[{"level":2,"title":"💡 核心思想：双塔模型，一场高效的“相亲大会”","slug":"💡-核心思想-双塔模型-一场高效的-相亲大会","link":"#💡-核心思想-双塔模型-一场高效的-相亲大会","children":[]},{"level":2,"title":"🏛️ 模型演进之路：从奠基到成熟","slug":"🏛️-模型演进之路-从奠基到成熟","link":"#🏛️-模型演进之路-从奠基到成熟","children":[{"level":3,"title":"DSSM：双塔模型的“开山鼻祖”","slug":"dssm-双塔模型的-开山鼻祖","link":"#dssm-双塔模型的-开山鼻祖","children":[]},{"level":3,"title":"YouTubeDNN：工业界的“集大成者”","slug":"youtubednn-工业界的-集大成者","link":"#youtubednn-工业界的-集大成者","children":[]},{"level":3,"title":"MIND：洞悉用户的“多面人生”","slug":"mind-洞悉用户的-多面人生","link":"#mind-洞悉用户的-多面人生","children":[]}]},{"level":2,"title":"⚙️ 工业部署：从模型到服务","slug":"⚙️-工业部署-从模型到服务","link":"#⚙️-工业部署-从模型到服务","children":[]},{"level":2,"title":"📖 延伸阅读","slug":"📖-延伸阅读","link":"#📖-延伸阅读","children":[]}]}}
