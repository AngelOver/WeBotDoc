{"content":"<h2 id=\"🎭-范式一-llm-嵌入-推荐系统-llm-embeddings-rs\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#🎭-范式一-llm-嵌入-推荐系统-llm-embeddings-rs\"><span>🎭 范式一：LLM 嵌入 + 推荐系统 (LLM Embeddings + RS)</span></a></h2>\n<p>在这种模式下，大型语言模型（LLM）扮演着一个 <strong>&quot;幕后英雄&quot;</strong> 的角色。它不直接面对用户给出推荐，而是作为推荐系统中一个强大的<strong>特征工程组件</strong>，专注于将非结构化的文本信息转化为高质量的数字特征，即<strong>嵌入（Embeddings）</strong>。这些嵌入随后被送入传统的推荐模型，极大地提升了模型对用户和物品的理解深度。</p>\n<h3 id=\"核心思想-万物皆可-embedding\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#核心思想-万物皆可-embedding\"><span>核心思想：万物皆可 Embedding</span></a></h3>\n<p>该范式的核心在于利用 LLM 强大的文本理解能力，为推荐系统中的用户（User）和物品（Item）生成富有语义的向量表示。这套思想的本质，是<strong>将推荐问题中的元素（用户、物品）与自然语言中的元素（单词、句子）进行类比，从而借助在自然语言领域被验证成功的强大模型（如BERT）来解决推荐问题</strong>。</p>\n<ul>\n<li><strong>对于物品（Item）</strong>：LLM 可以读取物品的标题、描述、属性、甚至是用户评论，然后输出一个能够代表该物品核心特性的向量。这个向量捕捉了文字背后的深层含义，使得语义上相近但用词不同的物品（例如，&quot;适合程序员的机械键盘&quot;和&quot;高键程、反馈明确的打字键盘&quot;）在向量空间中也能彼此靠近。</li>\n<li><strong>对于用户（User）</strong>：同理，LLM 可以分析用户的历史行为记录，如看过的文章标题、搜索过的关键词、发表过的评论等，从而为用户生成一个动态的、能够反映其当前兴趣和偏好和价值观的向量表示。</li>\n</ul>\n<h3 id=\"工作流程\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#工作流程\"><span>工作流程</span></a></h3>\n<p>其典型工作流程可以分为两步：</p>\n<ol>\n<li><strong>特征编码阶段（离线）</strong>：\n<ul>\n<li>收集用户和物品的原始文本数据（或其他可序列化的行为数据）。</li>\n<li>利用预训练好的 LLM（特别是像 BERT 这样的判别式模型）对这些数据进行编码，生成对应的嵌入向量。</li>\n<li>将这些嵌入向量存储起来，作为用户和物品的增强特征。</li>\n</ul>\n</li>\n<li><strong>推荐模型训练/预测阶段（在线/离线）</strong>：\n<ul>\n<li>在训练传统推荐模型（如矩阵分解、DSSM、基于Transformer的模型等）时，将 LLM 生成的嵌入向量作为额外的输入特征，与其他特征（如用户ID、物品ID、上下文特征等）拼接或通过注意力机制进行融合。</li>\n<li>模型通过学习，将文本语义信息与用户的行为模式关联起来，从而做出更精准的推荐。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"经典案例剖析\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#经典案例剖析\"><span>经典案例剖析</span></a></h3>\n<p>这一范式是 LLM 在推荐领域应用得最早、最成熟的方向，涌现了许多经典的研究。</p>\n<ul>\n<li>\n<h4 id=\"bert4rec-cikm-2019-序列推荐的里程碑\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#bert4rec-cikm-2019-序列推荐的里程碑\"><span><code v-pre>BERT4Rec</code> (CIKM 2019) - 序列推荐的里程碑</span></a></h4>\n<p><strong><code v-pre>BERT4Rec</code></strong> 是将 BERT 思想应用于序列推荐的开创性工作。它巧妙地将推荐问题与自然语言处理中的&quot;完形填空&quot;（Cloze Task）任务进行了类比，彻底改变了以往序列推荐模型的建模方式。</p>\n<ul>\n<li>\n<p><strong>核心创新</strong>：</p>\n<ol>\n<li><strong>双向上下文感知</strong>：此前的序列推荐模型（如 GRU4Rec）大多采用循环神经网络（RNN），只能单向地（从左到右）处理用户的行为序列，无法充分利用未来的行为信息来理解当前时刻的兴趣。<code v-pre>BERT4Rec</code> 借鉴了 BERT 的双向 Transformer 架构，能够<strong>同时利用一个物品之前和之后的行为信息</strong>来理解用户的真实意图。这就像我们在阅读句子时，需要结合上下文才能准确理解一个词的含义一样。</li>\n<li><strong>Cloze 任务范式</strong>：它不再像传统模型那样预测序列的&quot;下一个&quot;物品，而是随机地&quot;遮盖&quot;（Mask）掉用户行为序列中的一或多个物品，然后强制模型根据序列的其余部分，来预测被遮盖的物品是什么。这种 <code v-pre>Masked Item Prediction</code> 的训练方式，使得模型能够学习到物品之间更深层次的、非连续的依赖关系。</li>\n</ol>\n</li>\n<li>\n<p><strong>一句话总结</strong>：<code v-pre>BERT4Rec</code> 首次证明了双向的深度上下文信息对于理解用户行为序列至关重要，将序列推荐带入了&quot;预训练-微调&quot;的新时代。</p>\n</li>\n</ul>\n<details class=\"hint-container details\"><summary>📖 <code v-pre>BERT4Rec</code> 模型架构</summary>\n<div class=\"language-python line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"python\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code class=\"language-python\"><span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># 这不是可运行的代码，仅为帮助理解的伪代码结构</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">class</span><span style=\"--shiki-light:#2E8F82;--shiki-dark:#5DA994\"> BERT4Rec</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">Module</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\"> __init__</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> item_count</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> hidden_size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> num_layers</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> num_heads</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">        super</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">().</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">__init__</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">item_embeddings </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Embedding</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">item_count </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">+</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\"> 1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> hidden_size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> padding_idx</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">0</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"> # +1 for [MASK] token</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">position_embeddings </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Embedding</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">max_sequence_length</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> hidden_size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 使用标准的Transformer编码器层</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">transformer_encoder </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">TransformerEncoder</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">            encoder_layer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">TransformerEncoderLayer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">                d_model</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">hidden_size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">                nhead</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">num_heads</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">            ),</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">            num_layers</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">num_layers</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">        )</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">output_layer </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Linear</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">hidden_size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> item_count </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">+</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\"> 1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\"> forward</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> input_ids</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> masked_positions</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 1. 获取物品和位置的嵌入</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        item_embeds </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">item_embeddings</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">input_ids</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        pos_embeds </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">position_embeddings</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">arange</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">input_ids</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)))</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 2. 输入表示 = 物品嵌入 + 位置嵌入</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        input_representation </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> item_embeds </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">+</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> pos_embeds</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 3. 通过Transformer Encoder进行双向编码</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        encoded_sequence </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">transformer_encoder</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">input_representation</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 4. 提取被Mask位置的输出，并预测原始物品</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        masked_outputs </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> encoded_sequence</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">masked_positions</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">]</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        predictions </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">output_layer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">masked_outputs</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"> # [batch_size, num_masked, item_vocab_size]</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">        return</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> predictions</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div></details>\n</li>\n<li>\n<h4 id=\"u-bert-aaai-2021-从文本中学习用户深度表示\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#u-bert-aaai-2021-从文本中学习用户深度表示\"><span><code v-pre>U-BERT</code> (AAAI 2021) - 从文本中学习用户深度表示</span></a></h4>\n<p>如果说 <code v-pre>BERT4Rec</code> 关注的是行为序列，那么 <strong><code v-pre>U-BERT</code></strong> 则将目光投向了信息量更丰富的<strong>用户评论文本</strong>，旨在学习到更深层次的用户表示。</p>\n<ul>\n<li>\n<p><strong>核心创新</strong>：</p>\n<ol>\n<li><strong>双塔式文本编码</strong>：<code v-pre>U-BERT</code> 构建了一个双塔 BERT 结构，一个塔负责编码<strong>用户自己发表过的所有评论</strong>，生成用户的&quot;表达偏好&quot;向量；另一个塔负责编码<strong>目标物品收到的所有评论</strong>，生成物品的&quot;口碑&quot;向量。</li>\n<li><strong>评论协同匹配 (Review Co-Matching)</strong>：该模型的精髓在于，它不只是孤立地看用户或物品，而是通过一个**协同匹配层（Co-Matching Layer）**来捕捉用户&quot;表达偏好&quot;与物品&quot;口碑&quot;之间的细微语义关联。例如，一个用户总是在评论中抱怨&quot;性价比不高&quot;，而一个物品的评论区充满了&quot;物超所值&quot;的赞誉，模型就能通过语义匹配捕捉到这种深度的契合。</li>\n</ol>\n</li>\n<li>\n<p><strong>一句话总结</strong>：<code v-pre>U-BERT</code> 证明了通过深度匹配用户侧和物品侧的UGC文本，能够挖掘出远比行为序列更丰富、更具解释性的用户兴趣。</p>\n</li>\n</ul>\n</li>\n<li>\n<h4 id=\"unisrec-kdd-2022-迈向可迁移的通用推荐模型\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#unisrec-kdd-2022-迈向可迁移的通用推荐模型\"><span><code v-pre>UniSRec</code> (KDD 2022) - 迈向可迁移的通用推荐模型</span></a></h4>\n<p><strong><code v-pre>UniSRec</code></strong> 旨在解决一个长期困扰推荐系统的难题：如何将在一个领域（如新闻App）学到的知识，<strong>迁移</strong>到另一个完全不同的领域（如图书App）？</p>\n<ul>\n<li>\n<p><strong>核心创新</strong>：</p>\n<ol>\n<li><strong>放弃物品ID，拥抱文本</strong>：传统模型严重依赖物品ID，但不同领域的物品ID是完全不通用的，这导致模型无法迁移。<code v-pre>UniSRec</code> 提出，物品的<strong>文本描述</strong>（如标题、摘要）是跨领域通用的。它利用 BERT 对所有物品的文本进行编码，从而获得一个<strong>统一的、跨领域的物品语义表示空间</strong>。</li>\n<li><strong>通用序列表示</strong>：模型的核心任务，是学习一个能够将任何领域的行为序列，都映射到这个统一物品语义空间的用户表示。这样，即使用户在图书领域没有任何行为，只要他在新闻领域有阅读历史，模型也能为其生成一个有意义的用户表示，并在这个统一空间中找到他可能喜欢的图书。</li>\n</ol>\n</li>\n<li>\n<p><strong>一句话总结</strong>：<code v-pre>UniSRec</code> 通过将物品表示锚定在可跨领域迁移的文本语义上，为构建<strong>通用推荐基础模型</strong>迈出了关键的一步，是解决跨领域推荐和冷启动问题的典范之作。</p>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"优势与局限\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#优势与局限\"><span>优势与局限</span></a></h3>\n<ul>\n<li>\n<p><strong>显著优势</strong>：</p>\n<ul>\n<li><strong>解决数据稀疏和冷启动</strong>：对于新物品或新用户，只要有文本描述，就能立即生成有意义的特征向量，极大地缓解了冷启动问题。</li>\n<li><strong>提升推荐精度</strong>：引入了丰富的语义信息，让模型能够理解&quot;为什么&quot;推荐，而不仅仅是基于历史行为的&quot;模式匹配&quot;。</li>\n<li><strong>技术成熟，易于落地</strong>：该范式可以作为现有推荐系统的一个&quot;插件&quot;，无须对主体架构做颠覆性改造，方便与现有工程体系结合。</li>\n</ul>\n</li>\n<li>\n<p><strong>主要局限</strong>：</p>\n<ul>\n<li><strong>两阶段分离</strong>：特征提取（LLM 编码）和推荐模型训练是分离的，这可能导致次优解（sub-optimal）。因为 LLM 在编码文本时，并不知道下游推荐任务的具体目标是什么，它提取的通用语义特征未必是推荐任务最需要的。</li>\n<li><strong>忽略生成能力</strong>：此范式主要利用 LLM 的&quot;理解&quot;能力，其强大的&quot;生成&quot;能力（如生成解释、与用户对话）则被忽略了。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"📖-延伸阅读\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#📖-延伸阅读\"><span>📖 延伸阅读</span></a></h2>\n<ul>\n<li><a href=\"https://arxiv.org/abs/1904.06690\" target=\"_blank\" rel=\"noopener noreferrer\">BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer</a></li>\n<li><a href=\"https://arxiv.org/abs/2109.01255\" target=\"_blank\" rel=\"noopener noreferrer\">U-BERT: Pre-training User Representations for Improved Recommendation</a></li>\n<li><a href=\"https://arxiv.org/abs/2206.05941\" target=\"_blank\" rel=\"noopener noreferrer\">Towards Universal Sequence Representation Learning for Recommender Systems (UniSRec)</a></li>\n</ul>\n<blockquote>\n<p><strong>思考题</strong></p>\n<ol>\n<li>在你的理解中，&quot;LLM嵌入&quot;与传统的&quot;物品画像&quot;（Item Profile，通常指基于规则或简单模型提取的标签式特征）最大的区别是什么？</li>\n<li>如果让你设计一个利用 LLM 嵌入来改进电商场景中&quot;商品详情页&quot;推荐效果的方案，你会如何设计？你会选择哪些文本信息来喂给 LLM？</li>\n</ol>\n</blockquote>\n<div class=\"hint-container tip\">\n<p class=\"hint-container-title\">🎉 章节小结</p>\n<p>范式一&quot;LLM 嵌入 + 推荐系统&quot;是 LLM 在推荐领域最成熟、最务实的落地方式。它将 LLM 定位为一个强大的<strong>语义编码器</strong>，通过将用户和物品的文本信息（或可被类比为文本的行为序列）转化为高质量的嵌入向量，为传统推荐模型注入了前所未有的深度语义理解能力。这种方式尤其擅长解决物品冷启动和数据稀疏问题，并且能与现有系统平滑集成，是提升推荐效果的&quot;即插即用&quot;利器。</p>\n</div>\n<blockquote>\n<p><strong>LLM 嵌入 + 推荐系统</strong>，就像是给只会按图索骥的老牌侦探（传统推荐模型），配备了一位精通多国语言和微表情心理学的顶尖专家（LLM）。专家不直接破案，但他能将一堆看似无用的杂乱线索（文本信息），瞬间解读成指向真凶的关键情报（嵌入向量），让老侦探的破案率飙升。</p>\n</blockquote>\n","env":{"base":"/search-rec-ads-cosmos-explorer/","filePath":"D:/softwore/user/git/work_code/WeBotDoc/docs/zh/6.第六章：LLM时代下的搜广推新范式/3.LLM迈向更懂你的个性化/1.paradigm_llm_embeddings_rs.md","filePathRelative":"zh/6.第六章：LLM时代下的搜广推新范式/3.LLM迈向更懂你的个性化/1.paradigm_llm_embeddings_rs.md","frontmatter":{"title":"范式一：LLM 嵌入 + 推荐系统","createTime":"2025/07/22 17:30:00"},"sfcBlocks":{"template":{"type":"template","content":"<template><h2 id=\"🎭-范式一-llm-嵌入-推荐系统-llm-embeddings-rs\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#🎭-范式一-llm-嵌入-推荐系统-llm-embeddings-rs\"><span>🎭 范式一：LLM 嵌入 + 推荐系统 (LLM Embeddings + RS)</span></a></h2>\n<p>在这种模式下，大型语言模型（LLM）扮演着一个 <strong>&quot;幕后英雄&quot;</strong> 的角色。它不直接面对用户给出推荐，而是作为推荐系统中一个强大的<strong>特征工程组件</strong>，专注于将非结构化的文本信息转化为高质量的数字特征，即<strong>嵌入（Embeddings）</strong>。这些嵌入随后被送入传统的推荐模型，极大地提升了模型对用户和物品的理解深度。</p>\n<h3 id=\"核心思想-万物皆可-embedding\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#核心思想-万物皆可-embedding\"><span>核心思想：万物皆可 Embedding</span></a></h3>\n<p>该范式的核心在于利用 LLM 强大的文本理解能力，为推荐系统中的用户（User）和物品（Item）生成富有语义的向量表示。这套思想的本质，是<strong>将推荐问题中的元素（用户、物品）与自然语言中的元素（单词、句子）进行类比，从而借助在自然语言领域被验证成功的强大模型（如BERT）来解决推荐问题</strong>。</p>\n<ul>\n<li><strong>对于物品（Item）</strong>：LLM 可以读取物品的标题、描述、属性、甚至是用户评论，然后输出一个能够代表该物品核心特性的向量。这个向量捕捉了文字背后的深层含义，使得语义上相近但用词不同的物品（例如，&quot;适合程序员的机械键盘&quot;和&quot;高键程、反馈明确的打字键盘&quot;）在向量空间中也能彼此靠近。</li>\n<li><strong>对于用户（User）</strong>：同理，LLM 可以分析用户的历史行为记录，如看过的文章标题、搜索过的关键词、发表过的评论等，从而为用户生成一个动态的、能够反映其当前兴趣和偏好和价值观的向量表示。</li>\n</ul>\n<h3 id=\"工作流程\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#工作流程\"><span>工作流程</span></a></h3>\n<p>其典型工作流程可以分为两步：</p>\n<ol>\n<li><strong>特征编码阶段（离线）</strong>：\n<ul>\n<li>收集用户和物品的原始文本数据（或其他可序列化的行为数据）。</li>\n<li>利用预训练好的 LLM（特别是像 BERT 这样的判别式模型）对这些数据进行编码，生成对应的嵌入向量。</li>\n<li>将这些嵌入向量存储起来，作为用户和物品的增强特征。</li>\n</ul>\n</li>\n<li><strong>推荐模型训练/预测阶段（在线/离线）</strong>：\n<ul>\n<li>在训练传统推荐模型（如矩阵分解、DSSM、基于Transformer的模型等）时，将 LLM 生成的嵌入向量作为额外的输入特征，与其他特征（如用户ID、物品ID、上下文特征等）拼接或通过注意力机制进行融合。</li>\n<li>模型通过学习，将文本语义信息与用户的行为模式关联起来，从而做出更精准的推荐。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"经典案例剖析\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#经典案例剖析\"><span>经典案例剖析</span></a></h3>\n<p>这一范式是 LLM 在推荐领域应用得最早、最成熟的方向，涌现了许多经典的研究。</p>\n<ul>\n<li>\n<h4 id=\"bert4rec-cikm-2019-序列推荐的里程碑\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#bert4rec-cikm-2019-序列推荐的里程碑\"><span><code v-pre>BERT4Rec</code> (CIKM 2019) - 序列推荐的里程碑</span></a></h4>\n<p><strong><code v-pre>BERT4Rec</code></strong> 是将 BERT 思想应用于序列推荐的开创性工作。它巧妙地将推荐问题与自然语言处理中的&quot;完形填空&quot;（Cloze Task）任务进行了类比，彻底改变了以往序列推荐模型的建模方式。</p>\n<ul>\n<li>\n<p><strong>核心创新</strong>：</p>\n<ol>\n<li><strong>双向上下文感知</strong>：此前的序列推荐模型（如 GRU4Rec）大多采用循环神经网络（RNN），只能单向地（从左到右）处理用户的行为序列，无法充分利用未来的行为信息来理解当前时刻的兴趣。<code v-pre>BERT4Rec</code> 借鉴了 BERT 的双向 Transformer 架构，能够<strong>同时利用一个物品之前和之后的行为信息</strong>来理解用户的真实意图。这就像我们在阅读句子时，需要结合上下文才能准确理解一个词的含义一样。</li>\n<li><strong>Cloze 任务范式</strong>：它不再像传统模型那样预测序列的&quot;下一个&quot;物品，而是随机地&quot;遮盖&quot;（Mask）掉用户行为序列中的一或多个物品，然后强制模型根据序列的其余部分，来预测被遮盖的物品是什么。这种 <code v-pre>Masked Item Prediction</code> 的训练方式，使得模型能够学习到物品之间更深层次的、非连续的依赖关系。</li>\n</ol>\n</li>\n<li>\n<p><strong>一句话总结</strong>：<code v-pre>BERT4Rec</code> 首次证明了双向的深度上下文信息对于理解用户行为序列至关重要，将序列推荐带入了&quot;预训练-微调&quot;的新时代。</p>\n</li>\n</ul>\n<details class=\"hint-container details\"><summary>📖 <code v-pre>BERT4Rec</code> 模型架构</summary>\n<div class=\"language-python line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"python\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code class=\"language-python\"><span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># 这不是可运行的代码，仅为帮助理解的伪代码结构</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">class</span><span style=\"--shiki-light:#2E8F82;--shiki-dark:#5DA994\"> BERT4Rec</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">Module</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\"> __init__</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> item_count</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> hidden_size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> num_layers</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> num_heads</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">        super</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">().</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">__init__</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">item_embeddings </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Embedding</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">item_count </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">+</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\"> 1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> hidden_size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> padding_idx</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">0</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"> # +1 for [MASK] token</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">position_embeddings </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Embedding</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">max_sequence_length</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> hidden_size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 使用标准的Transformer编码器层</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">transformer_encoder </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">TransformerEncoder</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">            encoder_layer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">TransformerEncoderLayer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">                d_model</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">hidden_size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">                nhead</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">num_heads</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">            ),</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">            num_layers</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">num_layers</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">        )</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">output_layer </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Linear</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">hidden_size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> item_count </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">+</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\"> 1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\"> forward</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> input_ids</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> masked_positions</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 1. 获取物品和位置的嵌入</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        item_embeds </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">item_embeddings</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">input_ids</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        pos_embeds </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">position_embeddings</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">arange</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">input_ids</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)))</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 2. 输入表示 = 物品嵌入 + 位置嵌入</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        input_representation </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> item_embeds </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">+</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> pos_embeds</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 3. 通过Transformer Encoder进行双向编码</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        encoded_sequence </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">transformer_encoder</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">input_representation</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 4. 提取被Mask位置的输出，并预测原始物品</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        masked_outputs </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> encoded_sequence</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">masked_positions</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">]</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        predictions </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">output_layer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">masked_outputs</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"> # [batch_size, num_masked, item_vocab_size]</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">        return</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> predictions</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div></details>\n</li>\n<li>\n<h4 id=\"u-bert-aaai-2021-从文本中学习用户深度表示\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#u-bert-aaai-2021-从文本中学习用户深度表示\"><span><code v-pre>U-BERT</code> (AAAI 2021) - 从文本中学习用户深度表示</span></a></h4>\n<p>如果说 <code v-pre>BERT4Rec</code> 关注的是行为序列，那么 <strong><code v-pre>U-BERT</code></strong> 则将目光投向了信息量更丰富的<strong>用户评论文本</strong>，旨在学习到更深层次的用户表示。</p>\n<ul>\n<li>\n<p><strong>核心创新</strong>：</p>\n<ol>\n<li><strong>双塔式文本编码</strong>：<code v-pre>U-BERT</code> 构建了一个双塔 BERT 结构，一个塔负责编码<strong>用户自己发表过的所有评论</strong>，生成用户的&quot;表达偏好&quot;向量；另一个塔负责编码<strong>目标物品收到的所有评论</strong>，生成物品的&quot;口碑&quot;向量。</li>\n<li><strong>评论协同匹配 (Review Co-Matching)</strong>：该模型的精髓在于，它不只是孤立地看用户或物品，而是通过一个**协同匹配层（Co-Matching Layer）**来捕捉用户&quot;表达偏好&quot;与物品&quot;口碑&quot;之间的细微语义关联。例如，一个用户总是在评论中抱怨&quot;性价比不高&quot;，而一个物品的评论区充满了&quot;物超所值&quot;的赞誉，模型就能通过语义匹配捕捉到这种深度的契合。</li>\n</ol>\n</li>\n<li>\n<p><strong>一句话总结</strong>：<code v-pre>U-BERT</code> 证明了通过深度匹配用户侧和物品侧的UGC文本，能够挖掘出远比行为序列更丰富、更具解释性的用户兴趣。</p>\n</li>\n</ul>\n</li>\n<li>\n<h4 id=\"unisrec-kdd-2022-迈向可迁移的通用推荐模型\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#unisrec-kdd-2022-迈向可迁移的通用推荐模型\"><span><code v-pre>UniSRec</code> (KDD 2022) - 迈向可迁移的通用推荐模型</span></a></h4>\n<p><strong><code v-pre>UniSRec</code></strong> 旨在解决一个长期困扰推荐系统的难题：如何将在一个领域（如新闻App）学到的知识，<strong>迁移</strong>到另一个完全不同的领域（如图书App）？</p>\n<ul>\n<li>\n<p><strong>核心创新</strong>：</p>\n<ol>\n<li><strong>放弃物品ID，拥抱文本</strong>：传统模型严重依赖物品ID，但不同领域的物品ID是完全不通用的，这导致模型无法迁移。<code v-pre>UniSRec</code> 提出，物品的<strong>文本描述</strong>（如标题、摘要）是跨领域通用的。它利用 BERT 对所有物品的文本进行编码，从而获得一个<strong>统一的、跨领域的物品语义表示空间</strong>。</li>\n<li><strong>通用序列表示</strong>：模型的核心任务，是学习一个能够将任何领域的行为序列，都映射到这个统一物品语义空间的用户表示。这样，即使用户在图书领域没有任何行为，只要他在新闻领域有阅读历史，模型也能为其生成一个有意义的用户表示，并在这个统一空间中找到他可能喜欢的图书。</li>\n</ol>\n</li>\n<li>\n<p><strong>一句话总结</strong>：<code v-pre>UniSRec</code> 通过将物品表示锚定在可跨领域迁移的文本语义上，为构建<strong>通用推荐基础模型</strong>迈出了关键的一步，是解决跨领域推荐和冷启动问题的典范之作。</p>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"优势与局限\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#优势与局限\"><span>优势与局限</span></a></h3>\n<ul>\n<li>\n<p><strong>显著优势</strong>：</p>\n<ul>\n<li><strong>解决数据稀疏和冷启动</strong>：对于新物品或新用户，只要有文本描述，就能立即生成有意义的特征向量，极大地缓解了冷启动问题。</li>\n<li><strong>提升推荐精度</strong>：引入了丰富的语义信息，让模型能够理解&quot;为什么&quot;推荐，而不仅仅是基于历史行为的&quot;模式匹配&quot;。</li>\n<li><strong>技术成熟，易于落地</strong>：该范式可以作为现有推荐系统的一个&quot;插件&quot;，无须对主体架构做颠覆性改造，方便与现有工程体系结合。</li>\n</ul>\n</li>\n<li>\n<p><strong>主要局限</strong>：</p>\n<ul>\n<li><strong>两阶段分离</strong>：特征提取（LLM 编码）和推荐模型训练是分离的，这可能导致次优解（sub-optimal）。因为 LLM 在编码文本时，并不知道下游推荐任务的具体目标是什么，它提取的通用语义特征未必是推荐任务最需要的。</li>\n<li><strong>忽略生成能力</strong>：此范式主要利用 LLM 的&quot;理解&quot;能力，其强大的&quot;生成&quot;能力（如生成解释、与用户对话）则被忽略了。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"📖-延伸阅读\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#📖-延伸阅读\"><span>📖 延伸阅读</span></a></h2>\n<ul>\n<li><a href=\"https://arxiv.org/abs/1904.06690\" target=\"_blank\" rel=\"noopener noreferrer\">BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer</a></li>\n<li><a href=\"https://arxiv.org/abs/2109.01255\" target=\"_blank\" rel=\"noopener noreferrer\">U-BERT: Pre-training User Representations for Improved Recommendation</a></li>\n<li><a href=\"https://arxiv.org/abs/2206.05941\" target=\"_blank\" rel=\"noopener noreferrer\">Towards Universal Sequence Representation Learning for Recommender Systems (UniSRec)</a></li>\n</ul>\n<blockquote>\n<p><strong>思考题</strong></p>\n<ol>\n<li>在你的理解中，&quot;LLM嵌入&quot;与传统的&quot;物品画像&quot;（Item Profile，通常指基于规则或简单模型提取的标签式特征）最大的区别是什么？</li>\n<li>如果让你设计一个利用 LLM 嵌入来改进电商场景中&quot;商品详情页&quot;推荐效果的方案，你会如何设计？你会选择哪些文本信息来喂给 LLM？</li>\n</ol>\n</blockquote>\n<div class=\"hint-container tip\">\n<p class=\"hint-container-title\">🎉 章节小结</p>\n<p>范式一&quot;LLM 嵌入 + 推荐系统&quot;是 LLM 在推荐领域最成熟、最务实的落地方式。它将 LLM 定位为一个强大的<strong>语义编码器</strong>，通过将用户和物品的文本信息（或可被类比为文本的行为序列）转化为高质量的嵌入向量，为传统推荐模型注入了前所未有的深度语义理解能力。这种方式尤其擅长解决物品冷启动和数据稀疏问题，并且能与现有系统平滑集成，是提升推荐效果的&quot;即插即用&quot;利器。</p>\n</div>\n<blockquote>\n<p><strong>LLM 嵌入 + 推荐系统</strong>，就像是给只会按图索骥的老牌侦探（传统推荐模型），配备了一位精通多国语言和微表情心理学的顶尖专家（LLM）。专家不直接破案，但他能将一堆看似无用的杂乱线索（文本信息），瞬间解读成指向真凶的关键情报（嵌入向量），让老侦探的破案率飙升。</p>\n</blockquote>\n</template>","contentStripped":"<h2 id=\"🎭-范式一-llm-嵌入-推荐系统-llm-embeddings-rs\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#🎭-范式一-llm-嵌入-推荐系统-llm-embeddings-rs\"><span>🎭 范式一：LLM 嵌入 + 推荐系统 (LLM Embeddings + RS)</span></a></h2>\n<p>在这种模式下，大型语言模型（LLM）扮演着一个 <strong>&quot;幕后英雄&quot;</strong> 的角色。它不直接面对用户给出推荐，而是作为推荐系统中一个强大的<strong>特征工程组件</strong>，专注于将非结构化的文本信息转化为高质量的数字特征，即<strong>嵌入（Embeddings）</strong>。这些嵌入随后被送入传统的推荐模型，极大地提升了模型对用户和物品的理解深度。</p>\n<h3 id=\"核心思想-万物皆可-embedding\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#核心思想-万物皆可-embedding\"><span>核心思想：万物皆可 Embedding</span></a></h3>\n<p>该范式的核心在于利用 LLM 强大的文本理解能力，为推荐系统中的用户（User）和物品（Item）生成富有语义的向量表示。这套思想的本质，是<strong>将推荐问题中的元素（用户、物品）与自然语言中的元素（单词、句子）进行类比，从而借助在自然语言领域被验证成功的强大模型（如BERT）来解决推荐问题</strong>。</p>\n<ul>\n<li><strong>对于物品（Item）</strong>：LLM 可以读取物品的标题、描述、属性、甚至是用户评论，然后输出一个能够代表该物品核心特性的向量。这个向量捕捉了文字背后的深层含义，使得语义上相近但用词不同的物品（例如，&quot;适合程序员的机械键盘&quot;和&quot;高键程、反馈明确的打字键盘&quot;）在向量空间中也能彼此靠近。</li>\n<li><strong>对于用户（User）</strong>：同理，LLM 可以分析用户的历史行为记录，如看过的文章标题、搜索过的关键词、发表过的评论等，从而为用户生成一个动态的、能够反映其当前兴趣和偏好和价值观的向量表示。</li>\n</ul>\n<h3 id=\"工作流程\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#工作流程\"><span>工作流程</span></a></h3>\n<p>其典型工作流程可以分为两步：</p>\n<ol>\n<li><strong>特征编码阶段（离线）</strong>：\n<ul>\n<li>收集用户和物品的原始文本数据（或其他可序列化的行为数据）。</li>\n<li>利用预训练好的 LLM（特别是像 BERT 这样的判别式模型）对这些数据进行编码，生成对应的嵌入向量。</li>\n<li>将这些嵌入向量存储起来，作为用户和物品的增强特征。</li>\n</ul>\n</li>\n<li><strong>推荐模型训练/预测阶段（在线/离线）</strong>：\n<ul>\n<li>在训练传统推荐模型（如矩阵分解、DSSM、基于Transformer的模型等）时，将 LLM 生成的嵌入向量作为额外的输入特征，与其他特征（如用户ID、物品ID、上下文特征等）拼接或通过注意力机制进行融合。</li>\n<li>模型通过学习，将文本语义信息与用户的行为模式关联起来，从而做出更精准的推荐。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"经典案例剖析\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#经典案例剖析\"><span>经典案例剖析</span></a></h3>\n<p>这一范式是 LLM 在推荐领域应用得最早、最成熟的方向，涌现了许多经典的研究。</p>\n<ul>\n<li>\n<h4 id=\"bert4rec-cikm-2019-序列推荐的里程碑\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#bert4rec-cikm-2019-序列推荐的里程碑\"><span><code v-pre>BERT4Rec</code> (CIKM 2019) - 序列推荐的里程碑</span></a></h4>\n<p><strong><code v-pre>BERT4Rec</code></strong> 是将 BERT 思想应用于序列推荐的开创性工作。它巧妙地将推荐问题与自然语言处理中的&quot;完形填空&quot;（Cloze Task）任务进行了类比，彻底改变了以往序列推荐模型的建模方式。</p>\n<ul>\n<li>\n<p><strong>核心创新</strong>：</p>\n<ol>\n<li><strong>双向上下文感知</strong>：此前的序列推荐模型（如 GRU4Rec）大多采用循环神经网络（RNN），只能单向地（从左到右）处理用户的行为序列，无法充分利用未来的行为信息来理解当前时刻的兴趣。<code v-pre>BERT4Rec</code> 借鉴了 BERT 的双向 Transformer 架构，能够<strong>同时利用一个物品之前和之后的行为信息</strong>来理解用户的真实意图。这就像我们在阅读句子时，需要结合上下文才能准确理解一个词的含义一样。</li>\n<li><strong>Cloze 任务范式</strong>：它不再像传统模型那样预测序列的&quot;下一个&quot;物品，而是随机地&quot;遮盖&quot;（Mask）掉用户行为序列中的一或多个物品，然后强制模型根据序列的其余部分，来预测被遮盖的物品是什么。这种 <code v-pre>Masked Item Prediction</code> 的训练方式，使得模型能够学习到物品之间更深层次的、非连续的依赖关系。</li>\n</ol>\n</li>\n<li>\n<p><strong>一句话总结</strong>：<code v-pre>BERT4Rec</code> 首次证明了双向的深度上下文信息对于理解用户行为序列至关重要，将序列推荐带入了&quot;预训练-微调&quot;的新时代。</p>\n</li>\n</ul>\n<details class=\"hint-container details\"><summary>📖 <code v-pre>BERT4Rec</code> 模型架构</summary>\n<div class=\"language-python line-numbers-mode\" data-highlighter=\"shiki\" data-ext=\"python\" style=\"--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212\"><pre class=\"shiki shiki-themes vitesse-light vitesse-dark vp-code\" v-pre=\"\"><code class=\"language-python\"><span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"># 这不是可运行的代码，仅为帮助理解的伪代码结构</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">class</span><span style=\"--shiki-light:#2E8F82;--shiki-dark:#5DA994\"> BERT4Rec</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\">Module</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\"> __init__</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> item_count</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> hidden_size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> num_layers</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> num_heads</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">        super</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">().</span><span style=\"--shiki-light:#998418;--shiki-dark:#B8A965\">__init__</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">()</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">item_embeddings </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Embedding</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">item_count </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">+</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\"> 1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> hidden_size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\"> padding_idx</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">0</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"> # +1 for [MASK] token</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">position_embeddings </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Embedding</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">max_sequence_length</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> hidden_size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 使用标准的Transformer编码器层</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">transformer_encoder </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">TransformerEncoder</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">            encoder_layer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">TransformerEncoderLayer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">                d_model</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">hidden_size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">                nhead</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">num_heads</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">            ),</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#B07D48;--shiki-dark:#BD976A\">            num_layers</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">num_layers</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">        )</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\">        self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">output_layer </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">nn</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">Linear</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">hidden_size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> item_count </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">+</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\"> 1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"></span>\n<span class=\"line\"><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">    def</span><span style=\"--shiki-light:#59873A;--shiki-dark:#80A665\"> forward</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> input_ids</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">,</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> masked_positions</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">):</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 1. 获取物品和位置的嵌入</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        item_embeds </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">item_embeddings</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">input_ids</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        pos_embeds </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">position_embeddings</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">torch</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">arange</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">input_ids</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">size</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#2F798A;--shiki-dark:#4C9A91\">1</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)))</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 2. 输入表示 = 物品嵌入 + 位置嵌入</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        input_representation </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> item_embeds </span><span style=\"--shiki-light:#AB5959;--shiki-dark:#CB7676\">+</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> pos_embeds</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 3. 通过Transformer Encoder进行双向编码</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        encoded_sequence </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">transformer_encoder</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">input_representation</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\">        # 4. 提取被Mask位置的输出，并预测原始物品</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        masked_outputs </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> encoded_sequence</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">[</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">masked_positions</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">]</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        predictions </span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">=</span><span style=\"--shiki-light:#A65E2B;--shiki-dark:#C99076\"> self</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">.</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">output_layer</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">(</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">masked_outputs</span><span style=\"--shiki-light:#999999;--shiki-dark:#666666\">)</span><span style=\"--shiki-light:#A0ADA0;--shiki-dark:#758575DD\"> # [batch_size, num_masked, item_vocab_size]</span></span>\n<span class=\"line\"><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\">        </span></span>\n<span class=\"line\"><span style=\"--shiki-light:#1E754F;--shiki-dark:#4D9375\">        return</span><span style=\"--shiki-light:#393A34;--shiki-dark:#DBD7CAEE\"> predictions</span></span></code></pre>\n<div class=\"line-numbers\" aria-hidden=\"true\" style=\"counter-reset:line-number 0\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div></details>\n</li>\n<li>\n<h4 id=\"u-bert-aaai-2021-从文本中学习用户深度表示\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#u-bert-aaai-2021-从文本中学习用户深度表示\"><span><code v-pre>U-BERT</code> (AAAI 2021) - 从文本中学习用户深度表示</span></a></h4>\n<p>如果说 <code v-pre>BERT4Rec</code> 关注的是行为序列，那么 <strong><code v-pre>U-BERT</code></strong> 则将目光投向了信息量更丰富的<strong>用户评论文本</strong>，旨在学习到更深层次的用户表示。</p>\n<ul>\n<li>\n<p><strong>核心创新</strong>：</p>\n<ol>\n<li><strong>双塔式文本编码</strong>：<code v-pre>U-BERT</code> 构建了一个双塔 BERT 结构，一个塔负责编码<strong>用户自己发表过的所有评论</strong>，生成用户的&quot;表达偏好&quot;向量；另一个塔负责编码<strong>目标物品收到的所有评论</strong>，生成物品的&quot;口碑&quot;向量。</li>\n<li><strong>评论协同匹配 (Review Co-Matching)</strong>：该模型的精髓在于，它不只是孤立地看用户或物品，而是通过一个**协同匹配层（Co-Matching Layer）**来捕捉用户&quot;表达偏好&quot;与物品&quot;口碑&quot;之间的细微语义关联。例如，一个用户总是在评论中抱怨&quot;性价比不高&quot;，而一个物品的评论区充满了&quot;物超所值&quot;的赞誉，模型就能通过语义匹配捕捉到这种深度的契合。</li>\n</ol>\n</li>\n<li>\n<p><strong>一句话总结</strong>：<code v-pre>U-BERT</code> 证明了通过深度匹配用户侧和物品侧的UGC文本，能够挖掘出远比行为序列更丰富、更具解释性的用户兴趣。</p>\n</li>\n</ul>\n</li>\n<li>\n<h4 id=\"unisrec-kdd-2022-迈向可迁移的通用推荐模型\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#unisrec-kdd-2022-迈向可迁移的通用推荐模型\"><span><code v-pre>UniSRec</code> (KDD 2022) - 迈向可迁移的通用推荐模型</span></a></h4>\n<p><strong><code v-pre>UniSRec</code></strong> 旨在解决一个长期困扰推荐系统的难题：如何将在一个领域（如新闻App）学到的知识，<strong>迁移</strong>到另一个完全不同的领域（如图书App）？</p>\n<ul>\n<li>\n<p><strong>核心创新</strong>：</p>\n<ol>\n<li><strong>放弃物品ID，拥抱文本</strong>：传统模型严重依赖物品ID，但不同领域的物品ID是完全不通用的，这导致模型无法迁移。<code v-pre>UniSRec</code> 提出，物品的<strong>文本描述</strong>（如标题、摘要）是跨领域通用的。它利用 BERT 对所有物品的文本进行编码，从而获得一个<strong>统一的、跨领域的物品语义表示空间</strong>。</li>\n<li><strong>通用序列表示</strong>：模型的核心任务，是学习一个能够将任何领域的行为序列，都映射到这个统一物品语义空间的用户表示。这样，即使用户在图书领域没有任何行为，只要他在新闻领域有阅读历史，模型也能为其生成一个有意义的用户表示，并在这个统一空间中找到他可能喜欢的图书。</li>\n</ol>\n</li>\n<li>\n<p><strong>一句话总结</strong>：<code v-pre>UniSRec</code> 通过将物品表示锚定在可跨领域迁移的文本语义上，为构建<strong>通用推荐基础模型</strong>迈出了关键的一步，是解决跨领域推荐和冷启动问题的典范之作。</p>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"优势与局限\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#优势与局限\"><span>优势与局限</span></a></h3>\n<ul>\n<li>\n<p><strong>显著优势</strong>：</p>\n<ul>\n<li><strong>解决数据稀疏和冷启动</strong>：对于新物品或新用户，只要有文本描述，就能立即生成有意义的特征向量，极大地缓解了冷启动问题。</li>\n<li><strong>提升推荐精度</strong>：引入了丰富的语义信息，让模型能够理解&quot;为什么&quot;推荐，而不仅仅是基于历史行为的&quot;模式匹配&quot;。</li>\n<li><strong>技术成熟，易于落地</strong>：该范式可以作为现有推荐系统的一个&quot;插件&quot;，无须对主体架构做颠覆性改造，方便与现有工程体系结合。</li>\n</ul>\n</li>\n<li>\n<p><strong>主要局限</strong>：</p>\n<ul>\n<li><strong>两阶段分离</strong>：特征提取（LLM 编码）和推荐模型训练是分离的，这可能导致次优解（sub-optimal）。因为 LLM 在编码文本时，并不知道下游推荐任务的具体目标是什么，它提取的通用语义特征未必是推荐任务最需要的。</li>\n<li><strong>忽略生成能力</strong>：此范式主要利用 LLM 的&quot;理解&quot;能力，其强大的&quot;生成&quot;能力（如生成解释、与用户对话）则被忽略了。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"📖-延伸阅读\" tabindex=\"-1\"><a class=\"header-anchor\" href=\"#📖-延伸阅读\"><span>📖 延伸阅读</span></a></h2>\n<ul>\n<li><a href=\"https://arxiv.org/abs/1904.06690\" target=\"_blank\" rel=\"noopener noreferrer\">BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer</a></li>\n<li><a href=\"https://arxiv.org/abs/2109.01255\" target=\"_blank\" rel=\"noopener noreferrer\">U-BERT: Pre-training User Representations for Improved Recommendation</a></li>\n<li><a href=\"https://arxiv.org/abs/2206.05941\" target=\"_blank\" rel=\"noopener noreferrer\">Towards Universal Sequence Representation Learning for Recommender Systems (UniSRec)</a></li>\n</ul>\n<blockquote>\n<p><strong>思考题</strong></p>\n<ol>\n<li>在你的理解中，&quot;LLM嵌入&quot;与传统的&quot;物品画像&quot;（Item Profile，通常指基于规则或简单模型提取的标签式特征）最大的区别是什么？</li>\n<li>如果让你设计一个利用 LLM 嵌入来改进电商场景中&quot;商品详情页&quot;推荐效果的方案，你会如何设计？你会选择哪些文本信息来喂给 LLM？</li>\n</ol>\n</blockquote>\n<div class=\"hint-container tip\">\n<p class=\"hint-container-title\">🎉 章节小结</p>\n<p>范式一&quot;LLM 嵌入 + 推荐系统&quot;是 LLM 在推荐领域最成熟、最务实的落地方式。它将 LLM 定位为一个强大的<strong>语义编码器</strong>，通过将用户和物品的文本信息（或可被类比为文本的行为序列）转化为高质量的嵌入向量，为传统推荐模型注入了前所未有的深度语义理解能力。这种方式尤其擅长解决物品冷启动和数据稀疏问题，并且能与现有系统平滑集成，是提升推荐效果的&quot;即插即用&quot;利器。</p>\n</div>\n<blockquote>\n<p><strong>LLM 嵌入 + 推荐系统</strong>，就像是给只会按图索骥的老牌侦探（传统推荐模型），配备了一位精通多国语言和微表情心理学的顶尖专家（LLM）。专家不直接破案，但他能将一堆看似无用的杂乱线索（文本信息），瞬间解读成指向真凶的关键情报（嵌入向量），让老侦探的破案率飙升。</p>\n</blockquote>\n","tagOpen":"<template>","tagClose":"</template>"},"script":null,"scriptSetup":null,"scripts":[],"styles":[],"customBlocks":[]},"content":"## 🎭 范式一：LLM 嵌入 + 推荐系统 (LLM Embeddings + RS)\n\n在这种模式下，大型语言模型（LLM）扮演着一个 **\"幕后英雄\"** 的角色。它不直接面对用户给出推荐，而是作为推荐系统中一个强大的**特征工程组件**，专注于将非结构化的文本信息转化为高质量的数字特征，即**嵌入（Embeddings）**。这些嵌入随后被送入传统的推荐模型，极大地提升了模型对用户和物品的理解深度。\n\n### 核心思想：万物皆可 Embedding\n\n该范式的核心在于利用 LLM 强大的文本理解能力，为推荐系统中的用户（User）和物品（Item）生成富有语义的向量表示。这套思想的本质，是**将推荐问题中的元素（用户、物品）与自然语言中的元素（单词、句子）进行类比，从而借助在自然语言领域被验证成功的强大模型（如BERT）来解决推荐问题**。\n\n-   **对于物品（Item）**：LLM 可以读取物品的标题、描述、属性、甚至是用户评论，然后输出一个能够代表该物品核心特性的向量。这个向量捕捉了文字背后的深层含义，使得语义上相近但用词不同的物品（例如，\"适合程序员的机械键盘\"和\"高键程、反馈明确的打字键盘\"）在向量空间中也能彼此靠近。\n-   **对于用户（User）**：同理，LLM 可以分析用户的历史行为记录，如看过的文章标题、搜索过的关键词、发表过的评论等，从而为用户生成一个动态的、能够反映其当前兴趣和偏好和价值观的向量表示。\n\n### 工作流程\n\n其典型工作流程可以分为两步：\n\n1.  **特征编码阶段（离线）**：\n    *   收集用户和物品的原始文本数据（或其他可序列化的行为数据）。\n    *   利用预训练好的 LLM（特别是像 BERT 这样的判别式模型）对这些数据进行编码，生成对应的嵌入向量。\n    *   将这些嵌入向量存储起来，作为用户和物品的增强特征。\n2.  **推荐模型训练/预测阶段（在线/离线）**：\n    *   在训练传统推荐模型（如矩阵分解、DSSM、基于Transformer的模型等）时，将 LLM 生成的嵌入向量作为额外的输入特征，与其他特征（如用户ID、物品ID、上下文特征等）拼接或通过注意力机制进行融合。\n    *   模型通过学习，将文本语义信息与用户的行为模式关联起来，从而做出更精准的推荐。\n\n### 经典案例剖析\n\n这一范式是 LLM 在推荐领域应用得最早、最成熟的方向，涌现了许多经典的研究。\n\n*   #### `BERT4Rec` (CIKM 2019) - 序列推荐的里程碑\n\n    **`BERT4Rec`** 是将 BERT 思想应用于序列推荐的开创性工作。它巧妙地将推荐问题与自然语言处理中的\"完形填空\"（Cloze Task）任务进行了类比，彻底改变了以往序列推荐模型的建模方式。\n\n    *   **核心创新**：\n        1.  **双向上下文感知**：此前的序列推荐模型（如 GRU4Rec）大多采用循环神经网络（RNN），只能单向地（从左到右）处理用户的行为序列，无法充分利用未来的行为信息来理解当前时刻的兴趣。`BERT4Rec` 借鉴了 BERT 的双向 Transformer 架构，能够**同时利用一个物品之前和之后的行为信息**来理解用户的真实意图。这就像我们在阅读句子时，需要结合上下文才能准确理解一个词的含义一样。\n        2.  **Cloze 任务范式**：它不再像传统模型那样预测序列的\"下一个\"物品，而是随机地\"遮盖\"（Mask）掉用户行为序列中的一或多个物品，然后强制模型根据序列的其余部分，来预测被遮盖的物品是什么。这种 `Masked Item Prediction` 的训练方式，使得模型能够学习到物品之间更深层次的、非连续的依赖关系。\n\n    *   **一句话总结**：`BERT4Rec` 首次证明了双向的深度上下文信息对于理解用户行为序列至关重要，将序列推荐带入了\"预训练-微调\"的新时代。\n\n    ::: details 📖 `BERT4Rec` 模型架构\n    ```python\n    # 这不是可运行的代码，仅为帮助理解的伪代码结构\n    class BERT4Rec(torch.nn.Module):\n        def __init__(self, item_count, hidden_size, num_layers, num_heads):\n            super().__init__()\n            self.item_embeddings = torch.nn.Embedding(item_count + 1, hidden_size, padding_idx=0) # +1 for [MASK] token\n            self.position_embeddings = torch.nn.Embedding(max_sequence_length, hidden_size)\n            \n            # 使用标准的Transformer编码器层\n            self.transformer_encoder = torch.nn.TransformerEncoder(\n                encoder_layer=torch.nn.TransformerEncoderLayer(\n                    d_model=hidden_size, \n                    nhead=num_heads\n                ),\n                num_layers=num_layers\n            )\n            self.output_layer = torch.nn.Linear(hidden_size, item_count + 1)\n\n        def forward(self, input_ids, masked_positions):\n            # 1. 获取物品和位置的嵌入\n            item_embeds = self.item_embeddings(input_ids)\n            pos_embeds = self.position_embeddings(torch.arange(input_ids.size(1)))\n            \n            # 2. 输入表示 = 物品嵌入 + 位置嵌入\n            input_representation = item_embeds + pos_embeds\n            \n            # 3. 通过Transformer Encoder进行双向编码\n            encoded_sequence = self.transformer_encoder(input_representation)\n            \n            # 4. 提取被Mask位置的输出，并预测原始物品\n            masked_outputs = encoded_sequence[masked_positions]\n            predictions = self.output_layer(masked_outputs) # [batch_size, num_masked, item_vocab_size]\n            \n            return predictions\n    ```\n    :::\n\n*   #### `U-BERT` (AAAI 2021) - 从文本中学习用户深度表示\n\n    如果说 `BERT4Rec` 关注的是行为序列，那么 **`U-BERT`** 则将目光投向了信息量更丰富的**用户评论文本**，旨在学习到更深层次的用户表示。\n\n    *   **核心创新**：\n        1.  **双塔式文本编码**：`U-BERT` 构建了一个双塔 BERT 结构，一个塔负责编码**用户自己发表过的所有评论**，生成用户的\"表达偏好\"向量；另一个塔负责编码**目标物品收到的所有评论**，生成物品的\"口碑\"向量。\n        2.  **评论协同匹配 (Review Co-Matching)**：该模型的精髓在于，它不只是孤立地看用户或物品，而是通过一个**协同匹配层（Co-Matching Layer）**来捕捉用户\"表达偏好\"与物品\"口碑\"之间的细微语义关联。例如，一个用户总是在评论中抱怨\"性价比不高\"，而一个物品的评论区充满了\"物超所值\"的赞誉，模型就能通过语义匹配捕捉到这种深度的契合。\n\n    *   **一句话总结**：`U-BERT` 证明了通过深度匹配用户侧和物品侧的UGC文本，能够挖掘出远比行为序列更丰富、更具解释性的用户兴趣。\n\n*   #### `UniSRec` (KDD 2022) - 迈向可迁移的通用推荐模型\n\n    **`UniSRec`** 旨在解决一个长期困扰推荐系统的难题：如何将在一个领域（如新闻App）学到的知识，**迁移**到另一个完全不同的领域（如图书App）？\n\n    *   **核心创新**：\n        1.  **放弃物品ID，拥抱文本**：传统模型严重依赖物品ID，但不同领域的物品ID是完全不通用的，这导致模型无法迁移。`UniSRec` 提出，物品的**文本描述**（如标题、摘要）是跨领域通用的。它利用 BERT 对所有物品的文本进行编码，从而获得一个**统一的、跨领域的物品语义表示空间**。\n        2.  **通用序列表示**：模型的核心任务，是学习一个能够将任何领域的行为序列，都映射到这个统一物品语义空间的用户表示。这样，即使用户在图书领域没有任何行为，只要他在新闻领域有阅读历史，模型也能为其生成一个有意义的用户表示，并在这个统一空间中找到他可能喜欢的图书。\n\n    *   **一句话总结**：`UniSRec` 通过将物品表示锚定在可跨领域迁移的文本语义上，为构建**通用推荐基础模型**迈出了关键的一步，是解决跨领域推荐和冷启动问题的典范之作。\n\n### 优势与局限\n\n*   **显著优势**：\n    *   **解决数据稀疏和冷启动**：对于新物品或新用户，只要有文本描述，就能立即生成有意义的特征向量，极大地缓解了冷启动问题。\n    *   **提升推荐精度**：引入了丰富的语义信息，让模型能够理解\"为什么\"推荐，而不仅仅是基于历史行为的\"模式匹配\"。\n    *   **技术成熟，易于落地**：该范式可以作为现有推荐系统的一个\"插件\"，无须对主体架构做颠覆性改造，方便与现有工程体系结合。\n\n*   **主要局限**：\n    *   **两阶段分离**：特征提取（LLM 编码）和推荐模型训练是分离的，这可能导致次优解（sub-optimal）。因为 LLM 在编码文本时，并不知道下游推荐任务的具体目标是什么，它提取的通用语义特征未必是推荐任务最需要的。\n    *   **忽略生成能力**：此范式主要利用 LLM 的\"理解\"能力，其强大的\"生成\"能力（如生成解释、与用户对话）则被忽略了。\n\n## 📖 延伸阅读\n\n*   [BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer](https://arxiv.org/abs/1904.06690)\n*   [U-BERT: Pre-training User Representations for Improved Recommendation](https://arxiv.org/abs/2109.01255)\n*   [Towards Universal Sequence Representation Learning for Recommender Systems (UniSRec)](https://arxiv.org/abs/2206.05941)\n\n> **思考题**\n> 1.   在你的理解中，\"LLM嵌入\"与传统的\"物品画像\"（Item Profile，通常指基于规则或简单模型提取的标签式特征）最大的区别是什么？\n> 2.   如果让你设计一个利用 LLM 嵌入来改进电商场景中\"商品详情页\"推荐效果的方案，你会如何设计？你会选择哪些文本信息来喂给 LLM？\n\n::: tip 🎉 章节小结\n范式一\"LLM 嵌入 + 推荐系统\"是 LLM 在推荐领域最成熟、最务实的落地方式。它将 LLM 定位为一个强大的**语义编码器**，通过将用户和物品的文本信息（或可被类比为文本的行为序列）转化为高质量的嵌入向量，为传统推荐模型注入了前所未有的深度语义理解能力。这种方式尤其擅长解决物品冷启动和数据稀疏问题，并且能与现有系统平滑集成，是提升推荐效果的\"即插即用\"利器。\n:::\n\n> **LLM 嵌入 + 推荐系统**，就像是给只会按图索骥的老牌侦探（传统推荐模型），配备了一位精通多国语言和微表情心理学的顶尖专家（LLM）。专家不直接破案，但他能将一堆看似无用的杂乱线索（文本信息），瞬间解读成指向真凶的关键情报（嵌入向量），让老侦探的破案率飙升。","excerpt":"","includedFiles":[],"tasklistId":0,"title":"","headers":[{"level":2,"title":"🎭 范式一：LLM 嵌入 + 推荐系统 (LLM Embeddings + RS)","slug":"🎭-范式一-llm-嵌入-推荐系统-llm-embeddings-rs","link":"#🎭-范式一-llm-嵌入-推荐系统-llm-embeddings-rs","children":[{"level":3,"title":"核心思想：万物皆可 Embedding","slug":"核心思想-万物皆可-embedding","link":"#核心思想-万物皆可-embedding","children":[]},{"level":3,"title":"工作流程","slug":"工作流程","link":"#工作流程","children":[]},{"level":3,"title":"经典案例剖析","slug":"经典案例剖析","link":"#经典案例剖析","children":[]},{"level":3,"title":"优势与局限","slug":"优势与局限","link":"#优势与局限","children":[]}]},{"level":2,"title":"📖 延伸阅读","slug":"📖-延伸阅读","link":"#📖-延伸阅读","children":[]}]}}
